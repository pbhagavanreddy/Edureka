{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "id": "IP8Cl3HRGNd4",
    "outputId": "fdd51a4f-a549-4830-ed43-90457cc315fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.13.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/d3/651f95288a6cd9094f7411cdd90ef12a3d01a268009e0e3cd66b5c8d65bd/tensorflow-1.13.2-cp36-cp36m-manylinux1_x86_64.whl (92.6MB)\n",
      "\u001b[K     |████████████████████████████████| 92.6MB 48kB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.30.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.18.5)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 48.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (3.12.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 51.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (49.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n",
      "Collecting mock>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.1.0)\n",
      "Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "w31SCR6DG-iR",
    "outputId": "841ff8e2-eeef-46ee-c359-f5f82e51cc07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtulowmiGQMt"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tq88HkekGSYd"
   },
   "outputs": [],
   "source": [
    "def elapsed(sec):\n",
    "    if sec < 60:\n",
    "        return str(sec) + \" sec\"\n",
    "    elif sec < (60 * 60):\n",
    "        return str(sec / 60) + \" min\"\n",
    "    else:\n",
    "        return str(sec / (60 * 60)) + \" hr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaKpRVk8JFqB"
   },
   "outputs": [],
   "source": [
    "# Target log path\n",
    "logs_path = '/tmp/tensorflow/rnn_words'\n",
    "writer = tf.summary.FileWriter(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmQZkjJtJOZi"
   },
   "outputs": [],
   "source": [
    "# Text file containing words for training\n",
    "training_file = 'harry_porter.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YW5Mug2mJS1l"
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "def reading_text(fname):\n",
    "    with open(fname) as f:\n",
    "        text = f.readlines()\n",
    "\n",
    "    print(text)\n",
    "\n",
    "    text = [x.strip() for x in text]\n",
    "    text = [text[i].split() for i in range(len(text))]\n",
    "    text = np.array(text)\n",
    "    text = np.reshape(text, [-1, ])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "u7nzm2TkJZNe",
    "outputId": "e823f7d4-47bb-41af-a3f5-1d1af7c6b3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Harry had never been inside Filch's office before; it was a place most students avoided. The room was dingy and windowless, lit by a single oil lamp dangling from the low ceiling. A faint smell of fried fish lingered about the place. Wooden filing cabinets stood around the walls; from their labels, Harry could see that they contained details of every pupil Filch had ever punished. Fred and George Weasley had an entire drawer to themselves. A highly polished collection of chains and manacles hung on the wall behind Filch's desk. It was common knowledge that he was always begging Dumbledore to let him suspend students by their ankles from the ceiling.\"]\n",
      "Training Data Loaded\n"
     ]
    }
   ],
   "source": [
    "training_data = reading_text(training_file)\n",
    "print(\"Training Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "id": "LpX2omDjKMKc",
    "outputId": "8f307869-ce26-4643-ebaa-36e3e33c4632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harry' 'had' 'never' 'been' 'inside' \"Filch's\" 'office' 'before;' 'it'\n",
      " 'was' 'a' 'place' 'most' 'students' 'avoided.' 'The' 'room' 'was' 'dingy'\n",
      " 'and' 'windowless,' 'lit' 'by' 'a' 'single' 'oil' 'lamp' 'dangling'\n",
      " 'from' 'the' 'low' 'ceiling.' 'A' 'faint' 'smell' 'of' 'fried' 'fish'\n",
      " 'lingered' 'about' 'the' 'place.' 'Wooden' 'filing' 'cabinets' 'stood'\n",
      " 'around' 'the' 'walls;' 'from' 'their' 'labels,' 'Harry' 'could' 'see'\n",
      " 'that' 'they' 'contained' 'details' 'of' 'every' 'pupil' 'Filch' 'had'\n",
      " 'ever' 'punished.' 'Fred' 'and' 'George' 'Weasley' 'had' 'an' 'entire'\n",
      " 'drawer' 'to' 'themselves.' 'A' 'highly' 'polished' 'collection' 'of'\n",
      " 'chains' 'and' 'manacles' 'hung' 'on' 'the' 'wall' 'behind' \"Filch's\"\n",
      " 'desk.' 'It' 'was' 'common' 'knowledge' 'that' 'he' 'was' 'always'\n",
      " 'begging' 'Dumbledore' 'to' 'let' 'him' 'suspend' 'students' 'by' 'their'\n",
      " 'ankles' 'from' 'the' 'ceiling.']\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVKZ3UYtJcUc"
   },
   "outputs": [],
   "source": [
    "# Building the dictionary and  reverse dictionary\n",
    "def build_dataset_dictionary(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHxnlZUpKx6K"
   },
   "outputs": [],
   "source": [
    "dictionary, reverse_dictionary = build_dataset_dictionary(training_data)\n",
    "vocabulary_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "K4pGXqNPK4LP",
    "outputId": "a4df343b-b410-4a63-dae6-3f356060c3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "{'the': 0, 'was': 1, 'had': 2, 'and': 3, 'from': 4, 'of': 5, 'Harry': 6, \"Filch's\": 7, 'a': 8, 'students': 9, 'by': 10, 'ceiling.': 11, 'A': 12, 'their': 13, 'that': 14, 'to': 15, 'never': 16, 'been': 17, 'inside': 18, 'office': 19, 'before;': 20, 'it': 21, 'place': 22, 'most': 23, 'avoided.': 24, 'The': 25, 'room': 26, 'dingy': 27, 'windowless,': 28, 'lit': 29, 'single': 30, 'oil': 31, 'lamp': 32, 'dangling': 33, 'low': 34, 'faint': 35, 'smell': 36, 'fried': 37, 'fish': 38, 'lingered': 39, 'about': 40, 'place.': 41, 'Wooden': 42, 'filing': 43, 'cabinets': 44, 'stood': 45, 'around': 46, 'walls;': 47, 'labels,': 48, 'could': 49, 'see': 50, 'they': 51, 'contained': 52, 'details': 53, 'every': 54, 'pupil': 55, 'Filch': 56, 'ever': 57, 'punished.': 58, 'Fred': 59, 'George': 60, 'Weasley': 61, 'an': 62, 'entire': 63, 'drawer': 64, 'themselves.': 65, 'highly': 66, 'polished': 67, 'collection': 68, 'chains': 69, 'manacles': 70, 'hung': 71, 'on': 72, 'wall': 73, 'behind': 74, 'desk.': 75, 'It': 76, 'common': 77, 'knowledge': 78, 'he': 79, 'always': 80, 'begging': 81, 'Dumbledore': 82, 'let': 83, 'him': 84, 'suspend': 85, 'ankles': 86}\n",
      "{0: 'the', 1: 'was', 2: 'had', 3: 'and', 4: 'from', 5: 'of', 6: 'Harry', 7: \"Filch's\", 8: 'a', 9: 'students', 10: 'by', 11: 'ceiling.', 12: 'A', 13: 'their', 14: 'that', 15: 'to', 16: 'never', 17: 'been', 18: 'inside', 19: 'office', 20: 'before;', 21: 'it', 22: 'place', 23: 'most', 24: 'avoided.', 25: 'The', 26: 'room', 27: 'dingy', 28: 'windowless,', 29: 'lit', 30: 'single', 31: 'oil', 32: 'lamp', 33: 'dangling', 34: 'low', 35: 'faint', 36: 'smell', 37: 'fried', 38: 'fish', 39: 'lingered', 40: 'about', 41: 'place.', 42: 'Wooden', 43: 'filing', 44: 'cabinets', 45: 'stood', 46: 'around', 47: 'walls;', 48: 'labels,', 49: 'could', 50: 'see', 51: 'they', 52: 'contained', 53: 'details', 54: 'every', 55: 'pupil', 56: 'Filch', 57: 'ever', 58: 'punished.', 59: 'Fred', 60: 'George', 61: 'Weasley', 62: 'an', 63: 'entire', 64: 'drawer', 65: 'themselves.', 66: 'highly', 67: 'polished', 68: 'collection', 69: 'chains', 70: 'manacles', 71: 'hung', 72: 'on', 73: 'wall', 74: 'behind', 75: 'desk.', 76: 'It', 77: 'common', 78: 'knowledge', 79: 'he', 80: 'always', 81: 'begging', 82: 'Dumbledore', 83: 'let', 84: 'him', 85: 'suspend', 86: 'ankles'}\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary_size)\n",
    "print(dictionary)\n",
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7eK8Ow7K70s"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 20000\n",
    "display_step = 1000\n",
    "n_input = 3\n",
    "# number of units in RNN cell\n",
    "n_hidden = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFFbxjFuLlWo"
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocabulary_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "LXHhGL_fLoGt",
    "outputId": "18b3430c-753f-4986-8386-5ebc7abe5ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocabulary_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocabulary_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVciSkW5Lw54"
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "    # reshape to [1, n_input]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x, n_input, 1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    # Average Accuracy= 95.20% at 50k iter\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden), rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Average Accuracy= 90.60% 50k iter\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "pp1cpyc4MAzv",
    "outputId": "5a7fa5dd-b7f0-452d-8a07-0500be248205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-6ca347694303>:11: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-16-6ca347694303>:11: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-16-6ca347694303>:19: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "pred = RNN(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "x_6rg2KZMLFZ",
    "outputId": "8a19aea1-3572-4843-efb0-014220d068da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-7fd138551f7e>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0JgedORMY8h"
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Wd-jI0lMomU"
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BRwvjiwHMqUt",
    "outputId": "ae8086ad-bd86-4e4a-e4ca-0c6cc8876abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 1000, Average Loss= 3.760081, Average Accuracy= 10.60%\n",
      "['chains', 'and', 'manacles'] - [hung] vs [entire]\n",
      "Iter= 2000, Average Loss= 2.002230, Average Accuracy= 38.90%\n",
      "['that', 'they', 'contained'] - [details] vs [details]\n",
      "Iter= 3000, Average Loss= 1.607819, Average Accuracy= 50.70%\n",
      "['low', 'ceiling.', 'A'] - [faint] vs [single]\n",
      "Iter= 4000, Average Loss= 1.356694, Average Accuracy= 59.10%\n",
      "['it', 'was', 'a'] - [place] vs [place]\n",
      "Iter= 5000, Average Loss= 1.209865, Average Accuracy= 63.40%\n",
      "['It', 'was', 'common'] - [knowledge] vs [knowledge]\n",
      "Iter= 6000, Average Loss= 1.082666, Average Accuracy= 69.60%\n",
      "['that', 'they', 'contained'] - [details] vs [suspend]\n",
      "Iter= 7000, Average Loss= 1.241427, Average Accuracy= 67.50%\n",
      "['from', 'the', 'low'] - [ceiling.] vs [ceiling.]\n",
      "Iter= 8000, Average Loss= 1.070594, Average Accuracy= 69.90%\n",
      "['a', 'place', 'most'] - [students] vs [room]\n",
      "Iter= 9000, Average Loss= 1.028867, Average Accuracy= 71.50%\n",
      "['knowledge', 'that', 'he'] - [was] vs [him]\n",
      "Iter= 10000, Average Loss= 0.976930, Average Accuracy= 71.60%\n",
      "['themselves.', 'A', 'highly'] - [polished] vs [polished]\n",
      "Iter= 11000, Average Loss= 1.014879, Average Accuracy= 72.50%\n",
      "['details', 'of', 'every'] - [pupil] vs [see]\n",
      "Iter= 12000, Average Loss= 0.887302, Average Accuracy= 73.30%\n",
      "['of', 'fried', 'fish'] - [lingered] vs [lingered]\n",
      "Iter= 13000, Average Loss= 0.847689, Average Accuracy= 75.50%\n",
      "['Dumbledore', 'to', 'let'] - [him] vs [A]\n",
      "Iter= 14000, Average Loss= 0.924233, Average Accuracy= 72.60%\n",
      "['behind', \"Filch's\", 'desk.'] - [It] vs [It]\n",
      "Iter= 15000, Average Loss= 0.853015, Average Accuracy= 75.20%\n",
      "['Harry', 'could', 'see'] - [that] vs [that]\n",
      "Iter= 16000, Average Loss= 0.838612, Average Accuracy= 77.20%\n",
      "['windowless,', 'lit', 'by'] - [a] vs [a]\n",
      "Iter= 17000, Average Loss= 0.681738, Average Accuracy= 80.30%\n",
      "['common', 'knowledge', 'that'] - [he] vs [let]\n",
      "Iter= 18000, Average Loss= 0.682792, Average Accuracy= 78.40%\n",
      "['George', 'Weasley', 'had'] - [an] vs [an]\n",
      "Iter= 19000, Average Loss= 0.656698, Average Accuracy= 81.00%\n",
      "['filing', 'cabinets', 'stood'] - [around] vs [stood]\n",
      "Iter= 20000, Average Loss= 0.598105, Average Accuracy= 82.00%\n",
      "['avoided.', 'The', 'room'] - [was] vs [was]\n",
      "Optimization Finished!\n",
      "Elapsed time:  6.0515447417895 min\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=/tmp/tensorflow/rnn_words\n",
      "Point your web browser to: http://localhost:6006/\n",
      "3 words: of chains and\n",
      "of chains and manacles Weasley had an punished. Fred and an Weasley had an punished. Fred and an Weasley had an punished. Fred and an Weasley had an punished. Fred and an Weasley had an\n",
      "3 words: ofcourse not able\n",
      "Word not in dictionary\n",
      "3 words: to do\n",
      "3 words: had never been\n",
      "had never been inside Filch's office before; it was a place most students avoided. The students a single oil lamp dangling dangling dangling dangling dangling dangling dangling dangling dangling dangling dangling dangling dangling dangling dangling\n",
      "3 words: STOP STOP STOP\n",
      "Word not in dictionary\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c9f8f1b8e44e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s words: \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    offset = random.randint(0, n_input + 1)\n",
    "    end_offset = n_input + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    writer.add_graph(session.graph)\n",
    "\n",
    "    while step < training_iters:\n",
    "        # Generate a minibatch. Add some randomness on selection process.\n",
    "        if offset > (len(training_data) - end_offset):\n",
    "            offset = random.randint(0, n_input + 1)\n",
    "\n",
    "        symbols_in_keys = [[dictionary[str(training_data[i])]] for i in range(offset, offset + n_input)]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "        symbols_out_onehot = np.zeros([vocabulary_size], dtype=float)\n",
    "        symbols_out_onehot[dictionary[str(training_data[offset + n_input])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot, [1, -1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost_function, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step + 1) % display_step == 0:\n",
    "            print(\"Iter= \" + str(step + 1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total / display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100 * acc_total / display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n",
    "            symbols_out = training_data[offset + n_input]\n",
    "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in, symbols_out, symbols_out_pred))\n",
    "        step += 1\n",
    "        offset += (n_input + 1)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")\n",
    "    while True:\n",
    "        prompt = \"%s words: \" % n_input\n",
    "        sentence = input(prompt)\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != n_input:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(32):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "                sentence = \"%s %s\" % (sentence, reverse_dictionary[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except:\n",
    "            print(\"Word not in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsvTTrr_UllK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_lstm_word_predic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
