{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "colab_type": "code",
    "id": "aVdxEoUWS7pL",
    "outputId": "f7741716-fa97-4be9-e26c-4140ea3e56cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.13.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/d3/651f95288a6cd9094f7411cdd90ef12a3d01a268009e0e3cd66b5c8d65bd/tensorflow-1.13.2-cp36-cp36m-manylinux1_x86_64.whl (92.6MB)\n",
      "\u001b[K     |████████████████████████████████| 92.6MB 49kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.18.5)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 42.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.9.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.34.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 39.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (3.12.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.30.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
      "Collecting mock>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (49.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.1.0)\n",
      "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tensorboard",
         "tensorflow"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow==1.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "rhVBQdBB5AX5",
    "outputId": "c664294c-ac8c-4d6e-9066-8ed7a6860a64"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FK_WIjg5f_a"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P05Fe8Hq5iNa"
   },
   "outputs": [],
   "source": [
    "def elapsed(sec):\n",
    "    if sec < 60:\n",
    "        return str(sec) + \" sec\"\n",
    "    elif sec < (60 * 60):\n",
    "        return str(sec / 60) + \" min\"\n",
    "    else:\n",
    "        return str(sec / (60 * 60)) + \" hr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_75Nr7W5j0t"
   },
   "outputs": [],
   "source": [
    "# Target log path\n",
    "logs_path = '/tmp/tensorflow/rnn_words'\n",
    "writer = tf.summary.FileWriter(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XyjkylYG5zx9"
   },
   "outputs": [],
   "source": [
    "# Text file containing words for training\n",
    "training_file = 'poem.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xm8M-ycb9nfN"
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "def reading_text(fname):\n",
    "    with open(fname) as f:\n",
    "        z = f.readlines()\n",
    "\n",
    "    text = [x.strip() for x in z]\n",
    "    text = [x.replace(\"\\n\", \" \") for x in z]\n",
    "    z = ''\n",
    "    for x in text:\n",
    "      z = z+x\n",
    "    \n",
    "    text2 = list()\n",
    "    text2.append(z)\n",
    "    print(text2)\n",
    "    print(type(text2))\n",
    "\n",
    "    text2 = [text2[i].split() for i in range(len(text2))]\n",
    "    text2 = np.array(text2)\n",
    "    text2 = np.reshape(text2, [-1, ])\n",
    "\n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "pij7AgGg_0Py",
    "outputId": "75af5ce5-7aec-412c-91b7-a78155f304fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"BEHOLD her, single in the field, Yon solitary Highland Lass! Reaping and singing by herself; Stop here, or gently pass! Alone she cuts and binds the grain, And sings a melancholy strain; O listen! for the Vale profound Is overflowing with the sound.  No Nightingale did ever chaunt More welcome notes to weary bands Of travellers in some shady haunt, Among Arabian sands: A voice so shrilling ne'er was heard In spring-time from the Cuckoo-bird, Breaking the silence of the seas Among the farthest Hebrides.  Will no one tell me what she sings?-- Perhaps the plaintive numbers flow For old, unhappy, far-off things, And battles long ago: Or is it some more humble lay, Familiar matter of to-day? Some natural sorrow, loss, or pain, That has been, and may be again?  Whate'er the theme, the Maiden sang As if her song could have no ending; I saw her singing at her work, And o'er the sickle bending;-- I listen'd, motionless and still; And, as I mounted up the hill, The music in my heart I bore, Long after it was heard no more.\"]\n",
      "<class 'list'>\n",
      "Training Data Loaded\n"
     ]
    }
   ],
   "source": [
    "training_data = reading_text(training_file)\n",
    "print(\"Training Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "ANf5DKsdkaj2",
    "outputId": "0435ce33-895c-42b8-f18c-705368521070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BEHOLD' 'her,' 'single' 'in' 'the' 'field,' 'Yon' 'solitary' 'Highland'\n",
      " 'Lass!' 'Reaping' 'and' 'singing' 'by' 'herself;' 'Stop' 'here,' 'or'\n",
      " 'gently' 'pass!' 'Alone' 'she' 'cuts' 'and' 'binds' 'the' 'grain,' 'And'\n",
      " 'sings' 'a' 'melancholy' 'strain;' 'O' 'listen!' 'for' 'the' 'Vale'\n",
      " 'profound' 'Is' 'overflowing' 'with' 'the' 'sound.' 'No' 'Nightingale'\n",
      " 'did' 'ever' 'chaunt' 'More' 'welcome' 'notes' 'to' 'weary' 'bands' 'Of'\n",
      " 'travellers' 'in' 'some' 'shady' 'haunt,' 'Among' 'Arabian' 'sands:' 'A'\n",
      " 'voice' 'so' 'shrilling' \"ne'er\" 'was' 'heard' 'In' 'spring-time' 'from'\n",
      " 'the' 'Cuckoo-bird,' 'Breaking' 'the' 'silence' 'of' 'the' 'seas' 'Among'\n",
      " 'the' 'farthest' 'Hebrides.' 'Will' 'no' 'one' 'tell' 'me' 'what' 'she'\n",
      " 'sings?--' 'Perhaps' 'the' 'plaintive' 'numbers' 'flow' 'For' 'old,'\n",
      " 'unhappy,' 'far-off' 'things,' 'And' 'battles' 'long' 'ago:' 'Or' 'is'\n",
      " 'it' 'some' 'more' 'humble' 'lay,' 'Familiar' 'matter' 'of' 'to-day?'\n",
      " 'Some' 'natural' 'sorrow,' 'loss,' 'or' 'pain,' 'That' 'has' 'been,'\n",
      " 'and' 'may' 'be' 'again?' \"Whate'er\" 'the' 'theme,' 'the' 'Maiden' 'sang'\n",
      " 'As' 'if' 'her' 'song' 'could' 'have' 'no' 'ending;' 'I' 'saw' 'her'\n",
      " 'singing' 'at' 'her' 'work,' 'And' \"o'er\" 'the' 'sickle' 'bending;--' 'I'\n",
      " \"listen'd,\" 'motionless' 'and' 'still;' 'And,' 'as' 'I' 'mounted' 'up'\n",
      " 'the' 'hill,' 'The' 'music' 'in' 'my' 'heart' 'I' 'bore,' 'Long' 'after'\n",
      " 'it' 'was' 'heard' 'no' 'more.']\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vg-as6x76S7E"
   },
   "outputs": [],
   "source": [
    "# Building the dictionary and  reverse dictionary\n",
    "def build_dataset_dictionary(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5zdy9Fjp23wJ"
   },
   "outputs": [],
   "source": [
    "dictionary, reverse_dictionary = build_dataset_dictionary(training_data)\n",
    "vocabulary_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "Gj_zvoWu24We",
    "outputId": "feb016f3-dadb-43b2-fc2f-e909c57db69d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "{'the': 0, 'and': 1, 'I': 2, 'in': 3, 'And': 4, 'no': 5, 'her': 6, 'singing': 7, 'or': 8, 'she': 9, 'some': 10, 'Among': 11, 'was': 12, 'heard': 13, 'of': 14, 'it': 15, 'BEHOLD': 16, 'her,': 17, 'single': 18, 'field,': 19, 'Yon': 20, 'solitary': 21, 'Highland': 22, 'Lass!': 23, 'Reaping': 24, 'by': 25, 'herself;': 26, 'Stop': 27, 'here,': 28, 'gently': 29, 'pass!': 30, 'Alone': 31, 'cuts': 32, 'binds': 33, 'grain,': 34, 'sings': 35, 'a': 36, 'melancholy': 37, 'strain;': 38, 'O': 39, 'listen!': 40, 'for': 41, 'Vale': 42, 'profound': 43, 'Is': 44, 'overflowing': 45, 'with': 46, 'sound.': 47, 'No': 48, 'Nightingale': 49, 'did': 50, 'ever': 51, 'chaunt': 52, 'More': 53, 'welcome': 54, 'notes': 55, 'to': 56, 'weary': 57, 'bands': 58, 'Of': 59, 'travellers': 60, 'shady': 61, 'haunt,': 62, 'Arabian': 63, 'sands:': 64, 'A': 65, 'voice': 66, 'so': 67, 'shrilling': 68, \"ne'er\": 69, 'In': 70, 'spring-time': 71, 'from': 72, 'Cuckoo-bird,': 73, 'Breaking': 74, 'silence': 75, 'seas': 76, 'farthest': 77, 'Hebrides.': 78, 'Will': 79, 'one': 80, 'tell': 81, 'me': 82, 'what': 83, 'sings?--': 84, 'Perhaps': 85, 'plaintive': 86, 'numbers': 87, 'flow': 88, 'For': 89, 'old,': 90, 'unhappy,': 91, 'far-off': 92, 'things,': 93, 'battles': 94, 'long': 95, 'ago:': 96, 'Or': 97, 'is': 98, 'more': 99, 'humble': 100, 'lay,': 101, 'Familiar': 102, 'matter': 103, 'to-day?': 104, 'Some': 105, 'natural': 106, 'sorrow,': 107, 'loss,': 108, 'pain,': 109, 'That': 110, 'has': 111, 'been,': 112, 'may': 113, 'be': 114, 'again?': 115, \"Whate'er\": 116, 'theme,': 117, 'Maiden': 118, 'sang': 119, 'As': 120, 'if': 121, 'song': 122, 'could': 123, 'have': 124, 'ending;': 125, 'saw': 126, 'at': 127, 'work,': 128, \"o'er\": 129, 'sickle': 130, 'bending;--': 131, \"listen'd,\": 132, 'motionless': 133, 'still;': 134, 'And,': 135, 'as': 136, 'mounted': 137, 'up': 138, 'hill,': 139, 'The': 140, 'music': 141, 'my': 142, 'heart': 143, 'bore,': 144, 'Long': 145, 'after': 146, 'more.': 147}\n",
      "{0: 'the', 1: 'and', 2: 'I', 3: 'in', 4: 'And', 5: 'no', 6: 'her', 7: 'singing', 8: 'or', 9: 'she', 10: 'some', 11: 'Among', 12: 'was', 13: 'heard', 14: 'of', 15: 'it', 16: 'BEHOLD', 17: 'her,', 18: 'single', 19: 'field,', 20: 'Yon', 21: 'solitary', 22: 'Highland', 23: 'Lass!', 24: 'Reaping', 25: 'by', 26: 'herself;', 27: 'Stop', 28: 'here,', 29: 'gently', 30: 'pass!', 31: 'Alone', 32: 'cuts', 33: 'binds', 34: 'grain,', 35: 'sings', 36: 'a', 37: 'melancholy', 38: 'strain;', 39: 'O', 40: 'listen!', 41: 'for', 42: 'Vale', 43: 'profound', 44: 'Is', 45: 'overflowing', 46: 'with', 47: 'sound.', 48: 'No', 49: 'Nightingale', 50: 'did', 51: 'ever', 52: 'chaunt', 53: 'More', 54: 'welcome', 55: 'notes', 56: 'to', 57: 'weary', 58: 'bands', 59: 'Of', 60: 'travellers', 61: 'shady', 62: 'haunt,', 63: 'Arabian', 64: 'sands:', 65: 'A', 66: 'voice', 67: 'so', 68: 'shrilling', 69: \"ne'er\", 70: 'In', 71: 'spring-time', 72: 'from', 73: 'Cuckoo-bird,', 74: 'Breaking', 75: 'silence', 76: 'seas', 77: 'farthest', 78: 'Hebrides.', 79: 'Will', 80: 'one', 81: 'tell', 82: 'me', 83: 'what', 84: 'sings?--', 85: 'Perhaps', 86: 'plaintive', 87: 'numbers', 88: 'flow', 89: 'For', 90: 'old,', 91: 'unhappy,', 92: 'far-off', 93: 'things,', 94: 'battles', 95: 'long', 96: 'ago:', 97: 'Or', 98: 'is', 99: 'more', 100: 'humble', 101: 'lay,', 102: 'Familiar', 103: 'matter', 104: 'to-day?', 105: 'Some', 106: 'natural', 107: 'sorrow,', 108: 'loss,', 109: 'pain,', 110: 'That', 111: 'has', 112: 'been,', 113: 'may', 114: 'be', 115: 'again?', 116: \"Whate'er\", 117: 'theme,', 118: 'Maiden', 119: 'sang', 120: 'As', 121: 'if', 122: 'song', 123: 'could', 124: 'have', 125: 'ending;', 126: 'saw', 127: 'at', 128: 'work,', 129: \"o'er\", 130: 'sickle', 131: 'bending;--', 132: \"listen'd,\", 133: 'motionless', 134: 'still;', 135: 'And,', 136: 'as', 137: 'mounted', 138: 'up', 139: 'hill,', 140: 'The', 141: 'music', 142: 'my', 143: 'heart', 144: 'bore,', 145: 'Long', 146: 'after', 147: 'more.'}\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary_size)\n",
    "print(dictionary)\n",
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wI4qBJLp26SG"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 80000\n",
    "display_step = 1000\n",
    "n_input = 3\n",
    "# number of units in RNN cell\n",
    "n_hidden = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRN3C32k3BhR"
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocabulary_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "k8L1zQp23CF0",
    "outputId": "69dc184f-5f5c-48a3-8ed6-4067e053e53f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BhagavanReddy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocabulary_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocabulary_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZoy2OoB3EXQ"
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "    # reshape to [1, n_input]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x, n_input, 1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    # Average Accuracy= 95.20% at 50k iter\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden), rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Average Accuracy= 90.60% 50k iter\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "Fy8zOcmm3Gr9",
    "outputId": "af4570d6-4ab1-4c2e-d530-933c84a79f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-6ca347694303>:11: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-15-6ca347694303>:11: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-15-6ca347694303>:19: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "pred = RNN(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "MU5derh23IsS",
    "outputId": "1ea46a67-0fb4-41d5-f0f3-0018a1a70fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-7fd138551f7e>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGcGkQEQ3KWt"
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyedXVH73MY8"
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "id": "gj3Cbk0Y3N1P",
    "outputId": "1604730b-2576-4130-888e-ff1f793cec5e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-65f4627178fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost_function, pred], \\\n\u001b[1;32m---> 25\u001b[1;33m                                                 feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mloss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0macc_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    offset = random.randint(0, n_input + 1)\n",
    "    end_offset = n_input + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    writer.add_graph(session.graph)\n",
    "\n",
    "    while step < training_iters:\n",
    "        # Generate a minibatch. Add some randomness on selection process.\n",
    "        if offset > (len(training_data) - end_offset):\n",
    "            offset = random.randint(0, n_input + 1)\n",
    "\n",
    "        symbols_in_keys = [[dictionary[str(training_data[i])]] for i in range(offset, offset + n_input)]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "        symbols_out_onehot = np.zeros([vocabulary_size], dtype=float)\n",
    "        symbols_out_onehot[dictionary[str(training_data[offset + n_input])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot, [1, -1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost_function, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step + 1) % display_step == 0:\n",
    "            print(\"Iter= \" + str(step + 1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total / display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100 * acc_total / display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n",
    "            symbols_out = training_data[offset + n_input]\n",
    "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in, symbols_out, symbols_out_pred))\n",
    "        step += 1\n",
    "        offset += (n_input + 1)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")\n",
    "    while True:\n",
    "        prompt = \"%s words: \" % n_input\n",
    "        sentence = input(prompt)\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != n_input:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(32):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "                sentence = \"%s %s\" % (sentence, reverse_dictionary[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except:\n",
    "            print(\"Word not in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0F90RVe03QtE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "6_RecurrentNeural Networks_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
