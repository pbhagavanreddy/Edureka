{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9_TFLearn_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "luVuIicX3sbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a20de07-3136-4873-a598-f1fb579f014b"
      },
      "source": [
        "!pip install tflearn\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.3.2-cp36-none-any.whl size=128208 sha256=1c070a87da79e9e6eb0e5207e494136c7f29c5b83fa02bf53357ab497b4fb6e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n",
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 25kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 38.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.30.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (49.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=4de4f9bd5a7cfca264a1b3a990c6ea7971041531b4ffb5b050194bc093e09baf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXcOV5cH4Jqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "53ec6827-3ed3-43dd-a7dc-c1fb77216042"
      },
      "source": [
        "from tflearn import DNN\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS9Pqo0O34Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[0,0], [0,1], [1,0], [1,1]]\n",
        "Y = [[0], [1], [1], [0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1T7G3Pa30yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "d1dd00de-289d-4df8-bbed-c57fa755141a"
      },
      "source": [
        "input_layer = input_data(shape=[None, 2]) #input layer of size 2\n",
        "hidden_layer = fully_connected(input_layer , 2, activation='tanh') #hidden layer of size 2\n",
        "output_layer = fully_connected(hidden_layer, 1, activation='tanh') #output layer of size 1\n",
        "\n",
        "regression = regression(output_layer , optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
        "model = DNN(regression)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:145: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/optimizers.py:135: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/estimator.py:189: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:571: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:115: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:164: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:165: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:166: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:167: The name tf.get_collection_ref is deprecated. Please use tf.compat.v1.get_collection_ref instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZlhX0cV379T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf240362-4bca-4a8f-85b5-344da23dd853"
      },
      "source": [
        "model.fit(X, Y, n_epoch=2000, show_metric=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "--\n",
            "Training Step: 1335  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1335 | loss: 0.69315 - binary_acc: 0.4913 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1336  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1336 | loss: 0.69315 - binary_acc: 0.4922 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1337  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1337 | loss: 0.69315 - binary_acc: 0.4929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1338  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1338 | loss: 0.69315 - binary_acc: 0.4936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1339  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1339 | loss: 0.69315 - binary_acc: 0.4943 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1340  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1340 | loss: 0.69315 - binary_acc: 0.4949 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1341  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1341 | loss: 0.69315 - binary_acc: 0.4954 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1342  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1342 | loss: 0.69315 - binary_acc: 0.4958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1343  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1343 | loss: 0.69315 - binary_acc: 0.4962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1344  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1344 | loss: 0.69315 - binary_acc: 0.4966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1345  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1345 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1346  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1346 | loss: 0.69315 - binary_acc: 0.4973 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1347  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1347 | loss: 0.69315 - binary_acc: 0.4975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1348  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1348 | loss: 0.69315 - binary_acc: 0.4978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1349  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1349 | loss: 0.69315 - binary_acc: 0.4980 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1350  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1350 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1351  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1351 | loss: 0.69315 - binary_acc: 0.4984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1352  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1352 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1353  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1353 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1354  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1354 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1355  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1355 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1356  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1356 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1357  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1357 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1358  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1358 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1359  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1359 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1360  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1360 | loss: 0.69314 - binary_acc: 0.4994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1361  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1361 | loss: 0.69315 - binary_acc: 0.5244 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1362  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1362 | loss: 0.69315 - binary_acc: 0.5220 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1363  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1363 | loss: 0.69315 - binary_acc: 0.5198 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1364  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1364 | loss: 0.69315 - binary_acc: 0.5178 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1365  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1365 | loss: 0.69315 - binary_acc: 0.5160 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1366  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1366 | loss: 0.69315 - binary_acc: 0.5144 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1367  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1367 | loss: 0.69315 - binary_acc: 0.5130 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1368  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1368 | loss: 0.69315 - binary_acc: 0.5117 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1369  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1369 | loss: 0.69315 - binary_acc: 0.5105 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1370  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1370 | loss: 0.69315 - binary_acc: 0.5095 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1371  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1371 | loss: 0.69315 - binary_acc: 0.5085 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1372  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1372 | loss: 0.69315 - binary_acc: 0.5077 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1373  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1373 | loss: 0.69315 - binary_acc: 0.5069 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1374  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1374 | loss: 0.69315 - binary_acc: 0.5062 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1375  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1375 | loss: 0.69315 - binary_acc: 0.5056 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1376  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1376 | loss: 0.69315 - binary_acc: 0.5050 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1377  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1377 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1378  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1378 | loss: 0.69315 - binary_acc: 0.5041 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1379  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1379 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1380  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1380 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1381  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1381 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1382  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1382 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1383  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1383 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1384  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1384 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1385  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1385 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1386  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1386 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1387  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1387 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1388  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1388 | loss: 0.69314 - binary_acc: 0.5514 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1389  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1389 | loss: 0.69314 - binary_acc: 0.5463 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1390  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1390 | loss: 0.69314 - binary_acc: 0.5417 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1391  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1391 | loss: 0.69314 - binary_acc: 0.5375 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1392  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1392 | loss: 0.69314 - binary_acc: 0.5337 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1393  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1393 | loss: 0.69314 - binary_acc: 0.5304 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1394  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1394 | loss: 0.69314 - binary_acc: 0.5273 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1395  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1395 | loss: 0.69314 - binary_acc: 0.5246 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1396  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1396 | loss: 0.69314 - binary_acc: 0.5221 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1397  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1397 | loss: 0.69314 - binary_acc: 0.5199 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1398  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1398 | loss: 0.69314 - binary_acc: 0.5179 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1399  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1399 | loss: 0.69314 - binary_acc: 0.5161 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1400  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1400 | loss: 0.69314 - binary_acc: 0.5145 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1401  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1401 | loss: 0.69314 - binary_acc: 0.5131 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1402  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1402 | loss: 0.69314 - binary_acc: 0.5118 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1403  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1403 | loss: 0.69315 - binary_acc: 0.5106 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1404  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1404 | loss: 0.69315 - binary_acc: 0.5095 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1405  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1405 | loss: 0.69315 - binary_acc: 0.5086 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1406  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1406 | loss: 0.69315 - binary_acc: 0.5077 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1407  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1407 | loss: 0.69315 - binary_acc: 0.5069 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1408 | loss: 0.69315 - binary_acc: 0.5063 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1409 | loss: 0.69315 - binary_acc: 0.5056 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1410 | loss: 0.69315 - binary_acc: 0.5051 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1411 | loss: 0.69315 - binary_acc: 0.5046 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1412  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1412 | loss: 0.69313 - binary_acc: 0.5041 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1413  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1413 | loss: 0.69314 - binary_acc: 0.4787 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1414  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1414 | loss: 0.69314 - binary_acc: 0.4808 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1415  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1415 | loss: 0.69314 - binary_acc: 0.4827 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1416  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1416 | loss: 0.69314 - binary_acc: 0.4845 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1417  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1417 | loss: 0.69314 - binary_acc: 0.4860 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1418  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1418 | loss: 0.69314 - binary_acc: 0.4874 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1419  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1419 | loss: 0.69314 - binary_acc: 0.4887 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1420  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1420 | loss: 0.69314 - binary_acc: 0.4898 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1421  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1421 | loss: 0.69314 - binary_acc: 0.4908 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1422  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1422 | loss: 0.69314 - binary_acc: 0.4917 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1423  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1423 | loss: 0.69314 - binary_acc: 0.4926 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1424  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1424 | loss: 0.69314 - binary_acc: 0.4933 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1425  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1425 | loss: 0.69314 - binary_acc: 0.4940 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1426  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1426 | loss: 0.69314 - binary_acc: 0.4946 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1427 | loss: 0.69315 - binary_acc: 0.4951 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1428 | loss: 0.69315 - binary_acc: 0.4956 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1429 | loss: 0.69315 - binary_acc: 0.4961 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1430 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1431 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1432 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1433 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1434 | loss: 0.69315 - binary_acc: 0.4977 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1435 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1436 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1437 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1438  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1438 | loss: 0.69306 - binary_acc: 0.5485 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1439  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1439 | loss: 0.69307 - binary_acc: 0.5436 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1440  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1440 | loss: 0.69308 - binary_acc: 0.5393 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1441  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1441 | loss: 0.69309 - binary_acc: 0.5353 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1442  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1442 | loss: 0.69352 - binary_acc: 0.4818 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1443  | total loss: \u001b[1m\u001b[32m0.69348\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1443 | loss: 0.69348 - binary_acc: 0.4836 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1444  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1444 | loss: 0.69345 - binary_acc: 0.5103 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1445  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1445 | loss: 0.69342 - binary_acc: 0.4842 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1446  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1446 | loss: 0.69342 - binary_acc: 0.4858 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1447  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1447 | loss: 0.69339 - binary_acc: 0.4872 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1448  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1448 | loss: 0.69337 - binary_acc: 0.4885 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1449  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1449 | loss: 0.69334 - binary_acc: 0.4897 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1450  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1450 | loss: 0.69332 - binary_acc: 0.4907 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1451  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1451 | loss: 0.69331 - binary_acc: 0.4916 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1452  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1452 | loss: 0.69329 - binary_acc: 0.4925 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1453  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1453 | loss: 0.69328 - binary_acc: 0.4932 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1454  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1454 | loss: 0.69326 - binary_acc: 0.4939 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1455  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1455 | loss: 0.69325 - binary_acc: 0.4945 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1456  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1456 | loss: 0.69324 - binary_acc: 0.4951 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1457  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1457 | loss: 0.69323 - binary_acc: 0.4955 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1458  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1458 | loss: 0.69322 - binary_acc: 0.4960 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1459  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1459 | loss: 0.69322 - binary_acc: 0.4964 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1460  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1460 | loss: 0.69321 - binary_acc: 0.4968 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1461  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1461 | loss: 0.69320 - binary_acc: 0.4971 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1462  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1462 | loss: 0.69320 - binary_acc: 0.4974 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1463  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1463 | loss: 0.69319 - binary_acc: 0.4976 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1464  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1464 | loss: 0.69319 - binary_acc: 0.4979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1465  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1465 | loss: 0.69318 - binary_acc: 0.4981 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1466  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1466 | loss: 0.69318 - binary_acc: 0.4983 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1467  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1467 | loss: 0.69318 - binary_acc: 0.4984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1468  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1468 | loss: 0.69317 - binary_acc: 0.4986 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1469  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1469 | loss: 0.69317 - binary_acc: 0.4987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1470  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1470 | loss: 0.69317 - binary_acc: 0.4989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1471  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1471 | loss: 0.69317 - binary_acc: 0.4990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1472  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1472 | loss: 0.69316 - binary_acc: 0.4991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1473  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1473 | loss: 0.69316 - binary_acc: 0.4992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1474  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1474 | loss: 0.69316 - binary_acc: 0.4993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1475  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1475 | loss: 0.69316 - binary_acc: 0.4993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1476  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1476 | loss: 0.69316 - binary_acc: 0.4994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1477  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1477 | loss: 0.69316 - binary_acc: 0.4995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1478  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1478 | loss: 0.69316 - binary_acc: 0.4995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1479  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1479 | loss: 0.69316 - binary_acc: 0.4996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1480  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1480 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1481  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1481 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1482  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1482 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1483  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1483 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1484  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1484 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1485  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1485 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1486  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1486 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1487  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1487 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1488  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1488 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1489  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1489 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1490  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1490 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1491  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1491 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1492  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1492 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1493  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1493 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1494  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1494 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1495  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1495 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1496  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1496 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1497  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1497 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1498  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1498 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1499  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1499 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1500  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1500 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1501  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1501 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1502  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1502 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1503  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1503 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1504  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1504 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1505  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1505 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1506  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1506 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1507  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1507 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1508  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1508 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1509  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1509 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1510  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1510 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1511  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
            "| SGD | epoch: 1511 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1512  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1512 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1513  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1513 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1514  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1514 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1515  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1515 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1516  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1516 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1517  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1517 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1518  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1518 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1519  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1519 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1520  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1520 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1521  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1521 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1522  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1522 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1523  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1523 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1524  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1524 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1525  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1525 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1526  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1526 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1527  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1527 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1528  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1528 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1529  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1529 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1530  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1530 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1531  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1531 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1532  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1532 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1533  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1533 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1534  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1534 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1535  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1535 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1536  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1536 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1537  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1537 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1538  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1538 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1539  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1539 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1540  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1540 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1541  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1541 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1542  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1542 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1543  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1543 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1544  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1544 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1545  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1545 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1546  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1546 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1547  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1547 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1548  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1548 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1549  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1549 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1550  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1550 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1551  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1551 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1552  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1552 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1553  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1553 | loss: 0.69315 - binary_acc: 0.5250 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1554  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1554 | loss: 0.69315 - binary_acc: 0.5225 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1555  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1555 | loss: 0.69315 - binary_acc: 0.5202 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1556  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1556 | loss: 0.69316 - binary_acc: 0.4682 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1557  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1557 | loss: 0.69316 - binary_acc: 0.4714 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1558  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1558 | loss: 0.69316 - binary_acc: 0.4993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1559  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1559 | loss: 0.69316 - binary_acc: 0.4993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1560  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1560 | loss: 0.69316 - binary_acc: 0.4994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1561  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1561 | loss: 0.69316 - binary_acc: 0.4995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1562  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1562 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1563  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1563 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1564  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1564 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1565  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1565 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1566  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1566 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1567  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1567 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1568  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1568 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1569  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1569 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1570  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1570 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1571  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1571 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1572  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1572 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1573  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1573 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1574  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1574 | loss: 0.69316 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1575  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1575 | loss: 0.69316 - binary_acc: 0.4999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1576  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1576 | loss: 0.69316 - binary_acc: 0.5249 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1577  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1577 | loss: 0.69316 - binary_acc: 0.5224 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1578  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1578 | loss: 0.69316 - binary_acc: 0.5202 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1579  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1579 | loss: 0.69316 - binary_acc: 0.5181 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1580  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1580 | loss: 0.69316 - binary_acc: 0.5163 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1581  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1581 | loss: 0.69315 - binary_acc: 0.5147 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1582  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1582 | loss: 0.69315 - binary_acc: 0.5132 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1583  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1583 | loss: 0.69315 - binary_acc: 0.5119 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1584  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1584 | loss: 0.69315 - binary_acc: 0.5107 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1585  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1585 | loss: 0.69315 - binary_acc: 0.5096 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1586  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1586 | loss: 0.69315 - binary_acc: 0.5087 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1587  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1587 | loss: 0.69315 - binary_acc: 0.5078 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1588  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1588 | loss: 0.69315 - binary_acc: 0.5070 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1589  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1589 | loss: 0.69315 - binary_acc: 0.5063 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1590  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1590 | loss: 0.69315 - binary_acc: 0.5057 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1591  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1591 | loss: 0.69315 - binary_acc: 0.5051 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1592  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1592 | loss: 0.69315 - binary_acc: 0.5046 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1593  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1593 | loss: 0.69315 - binary_acc: 0.5042 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1594  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1594 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1595  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1595 | loss: 0.69315 - binary_acc: 0.5034 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1596  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1596 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1597  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1597 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1598  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1598 | loss: 0.69315 - binary_acc: 0.5025 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1599  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1599 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1600  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1600 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1601  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1601 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1602  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1602 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1603  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1603 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1604  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1604 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1605  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1605 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1606  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1606 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1607  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1607 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1608  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1608 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1609  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1609 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1610  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1610 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1611  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1611 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1612  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1612 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1613  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1613 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1614  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1614 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1615  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1615 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1616  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1616 | loss: 0.69318 - binary_acc: 0.4504 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1617  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1617 | loss: 0.69317 - binary_acc: 0.4553 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1618  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1618 | loss: 0.69317 - binary_acc: 0.4598 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1619  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1619 | loss: 0.69317 - binary_acc: 0.4638 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1620  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1620 | loss: 0.69317 - binary_acc: 0.4674 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1621  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1621 | loss: 0.69316 - binary_acc: 0.4707 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1622  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1622 | loss: 0.69316 - binary_acc: 0.4736 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1623  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1623 | loss: 0.69316 - binary_acc: 0.4763 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1624  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1624 | loss: 0.69316 - binary_acc: 0.4786 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1625  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1625 | loss: 0.69316 - binary_acc: 0.4808 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1626  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1626 | loss: 0.69316 - binary_acc: 0.4827 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1627  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1627 | loss: 0.69316 - binary_acc: 0.4844 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1628  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1628 | loss: 0.69314 - binary_acc: 0.5360 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1629  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1629 | loss: 0.69314 - binary_acc: 0.5074 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1630  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1630 | loss: 0.69314 - binary_acc: 0.5066 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1631  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1631 | loss: 0.69314 - binary_acc: 0.5060 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1632  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1632 | loss: 0.69314 - binary_acc: 0.5054 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1633  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1633 | loss: 0.69314 - binary_acc: 0.5048 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1634  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1634 | loss: 0.69314 - binary_acc: 0.5044 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1635  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1635 | loss: 0.69314 - binary_acc: 0.5039 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1636  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1636 | loss: 0.69314 - binary_acc: 0.5035 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1637  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1637 | loss: 0.69314 - binary_acc: 0.5032 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1638  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1638 | loss: 0.69314 - binary_acc: 0.5029 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1639  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1639 | loss: 0.69314 - binary_acc: 0.5026 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1640  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1640 | loss: 0.69314 - binary_acc: 0.5023 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1641  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1641 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1642  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1642 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1643  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1643 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1644  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1644 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1645  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1645 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1646  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1646 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1647  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1647 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1648  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1648 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1649  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1649 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1650  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1650 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1651  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1651 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1652  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1652 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1653  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1653 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1654  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1654 | loss: 0.69306 - binary_acc: 0.5505 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1655  | total loss: \u001b[1m\u001b[32m0.69307\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1655 | loss: 0.69307 - binary_acc: 0.5455 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1656  | total loss: \u001b[1m\u001b[32m0.69308\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1656 | loss: 0.69308 - binary_acc: 0.5409 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1657  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1657 | loss: 0.69309 - binary_acc: 0.5368 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1658  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1658 | loss: 0.69310 - binary_acc: 0.5332 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1659  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1659 | loss: 0.69310 - binary_acc: 0.5298 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1660  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1660 | loss: 0.69311 - binary_acc: 0.5269 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1661  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1661 | loss: 0.69311 - binary_acc: 0.5242 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1662  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1662 | loss: 0.69310 - binary_acc: 0.5218 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1663  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1663 | loss: 0.69310 - binary_acc: 0.5446 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1664  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1664 | loss: 0.69310 - binary_acc: 0.5401 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1665  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1665 | loss: 0.69310 - binary_acc: 0.5611 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1666  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1666 | loss: 0.69310 - binary_acc: 0.5550 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1667  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1667 | loss: 0.69309 - binary_acc: 0.5495 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1668  | total loss: \u001b[1m\u001b[32m0.69357\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1668 | loss: 0.69357 - binary_acc: 0.5445 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1669  | total loss: \u001b[1m\u001b[32m0.69354\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1669 | loss: 0.69354 - binary_acc: 0.5401 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1670  | total loss: \u001b[1m\u001b[32m0.69352\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1670 | loss: 0.69352 - binary_acc: 0.5361 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1671  | total loss: \u001b[1m\u001b[32m0.69348\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1671 | loss: 0.69348 - binary_acc: 0.5325 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1672  | total loss: \u001b[1m\u001b[32m0.69345\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1672 | loss: 0.69345 - binary_acc: 0.5292 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1673  | total loss: \u001b[1m\u001b[32m0.69342\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1673 | loss: 0.69342 - binary_acc: 0.5263 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1674  | total loss: \u001b[1m\u001b[32m0.69339\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1674 | loss: 0.69339 - binary_acc: 0.5237 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1675  | total loss: \u001b[1m\u001b[32m0.69337\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1675 | loss: 0.69337 - binary_acc: 0.5213 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1676  | total loss: \u001b[1m\u001b[32m0.69334\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1676 | loss: 0.69334 - binary_acc: 0.5192 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1677  | total loss: \u001b[1m\u001b[32m0.69332\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1677 | loss: 0.69332 - binary_acc: 0.5173 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1678  | total loss: \u001b[1m\u001b[32m0.69331\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1678 | loss: 0.69331 - binary_acc: 0.5155 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1679  | total loss: \u001b[1m\u001b[32m0.69329\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1679 | loss: 0.69329 - binary_acc: 0.5140 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1680  | total loss: \u001b[1m\u001b[32m0.69328\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1680 | loss: 0.69328 - binary_acc: 0.5126 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1681  | total loss: \u001b[1m\u001b[32m0.69326\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1681 | loss: 0.69326 - binary_acc: 0.5113 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1682  | total loss: \u001b[1m\u001b[32m0.69325\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1682 | loss: 0.69325 - binary_acc: 0.5102 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1683  | total loss: \u001b[1m\u001b[32m0.69324\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1683 | loss: 0.69324 - binary_acc: 0.5092 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1684  | total loss: \u001b[1m\u001b[32m0.69323\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1684 | loss: 0.69323 - binary_acc: 0.5083 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1685  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1685 | loss: 0.69322 - binary_acc: 0.5074 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1686  | total loss: \u001b[1m\u001b[32m0.69322\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1686 | loss: 0.69322 - binary_acc: 0.5067 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1687  | total loss: \u001b[1m\u001b[32m0.69321\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1687 | loss: 0.69321 - binary_acc: 0.5060 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1688  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1688 | loss: 0.69320 - binary_acc: 0.5054 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1689  | total loss: \u001b[1m\u001b[32m0.69320\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1689 | loss: 0.69320 - binary_acc: 0.5049 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1690  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1690 | loss: 0.69319 - binary_acc: 0.5044 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1691  | total loss: \u001b[1m\u001b[32m0.69319\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1691 | loss: 0.69319 - binary_acc: 0.5039 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1692  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1692 | loss: 0.69318 - binary_acc: 0.5036 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1693  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1693 | loss: 0.69318 - binary_acc: 0.5032 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1694  | total loss: \u001b[1m\u001b[32m0.69318\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1694 | loss: 0.69318 - binary_acc: 0.5279 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1695  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1695 | loss: 0.69317 - binary_acc: 0.5501 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1696  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1696 | loss: 0.69317 - binary_acc: 0.5451 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1697  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1697 | loss: 0.69317 - binary_acc: 0.5156 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1698  | total loss: \u001b[1m\u001b[32m0.69317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1698 | loss: 0.69317 - binary_acc: 0.5140 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1699  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1699 | loss: 0.69316 - binary_acc: 0.5126 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1700  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1700 | loss: 0.69316 - binary_acc: 0.5114 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1701  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1701 | loss: 0.69316 - binary_acc: 0.5102 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1702  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1702 | loss: 0.69316 - binary_acc: 0.5092 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1703  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1703 | loss: 0.69316 - binary_acc: 0.5083 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1704  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1704 | loss: 0.69316 - binary_acc: 0.5074 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1705  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1705 | loss: 0.69316 - binary_acc: 0.5067 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1706  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1706 | loss: 0.69316 - binary_acc: 0.5060 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1707  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1707 | loss: 0.69316 - binary_acc: 0.5054 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1708  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1708 | loss: 0.69316 - binary_acc: 0.5049 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1709  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1709 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1710  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1710 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1711  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1711 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1712  | total loss: \u001b[1m\u001b[32m0.69306\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1712 | loss: 0.69306 - binary_acc: 0.5532 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1713  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1713 | loss: 0.69309 - binary_acc: 0.5479 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1714  | total loss: \u001b[1m\u001b[32m0.69310\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1714 | loss: 0.69310 - binary_acc: 0.5431 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1715  | total loss: \u001b[1m\u001b[32m0.69311\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1715 | loss: 0.69311 - binary_acc: 0.5388 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1716  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1716 | loss: 0.69312 - binary_acc: 0.5349 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1717  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1717 | loss: 0.69313 - binary_acc: 0.5314 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1718  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1718 | loss: 0.69313 - binary_acc: 0.5283 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1719  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1719 | loss: 0.69314 - binary_acc: 0.5254 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1720  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1720 | loss: 0.69315 - binary_acc: 0.5229 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1721  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1721 | loss: 0.69315 - binary_acc: 0.5206 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1722  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1722 | loss: 0.69315 - binary_acc: 0.5186 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1723  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1723 | loss: 0.69315 - binary_acc: 0.5167 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1724  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1724 | loss: 0.69315 - binary_acc: 0.5150 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1725  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1725 | loss: 0.69316 - binary_acc: 0.5135 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1726  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1726 | loss: 0.69316 - binary_acc: 0.5122 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1727  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1727 | loss: 0.69316 - binary_acc: 0.5110 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1728  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1728 | loss: 0.69316 - binary_acc: 0.5099 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1729  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1729 | loss: 0.69316 - binary_acc: 0.5089 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1730  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1730 | loss: 0.69316 - binary_acc: 0.5080 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1731  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1731 | loss: 0.69316 - binary_acc: 0.5072 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1732  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1732 | loss: 0.69316 - binary_acc: 0.5065 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1733  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1733 | loss: 0.69315 - binary_acc: 0.5058 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1734  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1734 | loss: 0.69315 - binary_acc: 0.5052 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1735  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1735 | loss: 0.69315 - binary_acc: 0.5047 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1736  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1736 | loss: 0.69315 - binary_acc: 0.5042 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1737  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1737 | loss: 0.69315 - binary_acc: 0.5038 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1738  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1738 | loss: 0.69316 - binary_acc: 0.5034 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1739  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1739 | loss: 0.69316 - binary_acc: 0.5031 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1740  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1740 | loss: 0.69316 - binary_acc: 0.5028 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1741  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1741 | loss: 0.69315 - binary_acc: 0.5025 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1742  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1742 | loss: 0.69315 - binary_acc: 0.5023 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1743  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1743 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1744  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1744 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1745  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1745 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1746  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1746 | loss: 0.69314 - binary_acc: 0.5015 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1747  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1747 | loss: 0.69314 - binary_acc: 0.5013 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1748  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1748 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1749  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1749 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1750  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1750 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1751  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1751 | loss: 0.69314 - binary_acc: 0.5009 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1752  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1752 | loss: 0.69314 - binary_acc: 0.5008 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1753  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1753 | loss: 0.69314 - binary_acc: 0.5007 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1754  | total loss: \u001b[1m\u001b[32m0.69282\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1754 | loss: 0.69282 - binary_acc: 0.5006 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1755  | total loss: \u001b[1m\u001b[32m0.69288\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1755 | loss: 0.69288 - binary_acc: 0.4756 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1756  | total loss: \u001b[1m\u001b[32m0.69292\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1756 | loss: 0.69292 - binary_acc: 0.5030 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1757  | total loss: \u001b[1m\u001b[32m0.69295\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1757 | loss: 0.69295 - binary_acc: 0.5027 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1758  | total loss: \u001b[1m\u001b[32m0.69296\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1758 | loss: 0.69296 - binary_acc: 0.5024 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1759  | total loss: \u001b[1m\u001b[32m0.69297\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1759 | loss: 0.69297 - binary_acc: 0.5022 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1760  | total loss: \u001b[1m\u001b[32m0.69297\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1760 | loss: 0.69297 - binary_acc: 0.5270 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1761  | total loss: \u001b[1m\u001b[32m0.69296\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1761 | loss: 0.69296 - binary_acc: 0.5493 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1762  | total loss: \u001b[1m\u001b[32m0.69305\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1762 | loss: 0.69305 - binary_acc: 0.5194 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1763  | total loss: \u001b[1m\u001b[32m0.69304\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1763 | loss: 0.69304 - binary_acc: 0.4924 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1764  | total loss: \u001b[1m\u001b[32m0.69302\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1764 | loss: 0.69302 - binary_acc: 0.5182 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1765  | total loss: \u001b[1m\u001b[32m0.69300\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1765 | loss: 0.69300 - binary_acc: 0.5414 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1766  | total loss: \u001b[1m\u001b[32m0.69296\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1766 | loss: 0.69296 - binary_acc: 0.5622 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1767  | total loss: \u001b[1m\u001b[32m0.69292\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1767 | loss: 0.69292 - binary_acc: 0.5810 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1768  | total loss: \u001b[1m\u001b[32m0.69287\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1768 | loss: 0.69287 - binary_acc: 0.5979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1769  | total loss: \u001b[1m\u001b[32m0.69281\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1769 | loss: 0.69281 - binary_acc: 0.6131 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1770  | total loss: \u001b[1m\u001b[32m0.69273\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1770 | loss: 0.69273 - binary_acc: 0.6268 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1771  | total loss: \u001b[1m\u001b[32m0.69262\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1771 | loss: 0.69262 - binary_acc: 0.6391 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1772  | total loss: \u001b[1m\u001b[32m0.69249\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1772 | loss: 0.69249 - binary_acc: 0.6502 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1773  | total loss: \u001b[1m\u001b[32m0.69232\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1773 | loss: 0.69232 - binary_acc: 0.6602 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1774  | total loss: \u001b[1m\u001b[32m0.69208\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1774 | loss: 0.69208 - binary_acc: 0.6692 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1775  | total loss: \u001b[1m\u001b[32m0.69175\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1775 | loss: 0.69175 - binary_acc: 0.6773 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1776  | total loss: \u001b[1m\u001b[32m0.69128\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1776 | loss: 0.69128 - binary_acc: 0.6845 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1777  | total loss: \u001b[1m\u001b[32m0.69059\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1777 | loss: 0.69059 - binary_acc: 0.6911 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1778  | total loss: \u001b[1m\u001b[32m0.68957\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1778 | loss: 0.68957 - binary_acc: 0.6970 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1779  | total loss: \u001b[1m\u001b[32m0.68804\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1779 | loss: 0.68804 - binary_acc: 0.7023 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1780  | total loss: \u001b[1m\u001b[32m0.68576\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1780 | loss: 0.68576 - binary_acc: 0.7070 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1781  | total loss: \u001b[1m\u001b[32m0.68243\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1781 | loss: 0.68243 - binary_acc: 0.7113 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1782  | total loss: \u001b[1m\u001b[32m0.69882\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1782 | loss: 0.69882 - binary_acc: 0.6652 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1783  | total loss: \u001b[1m\u001b[32m0.69871\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1783 | loss: 0.69871 - binary_acc: 0.6487 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1784  | total loss: \u001b[1m\u001b[32m0.69843\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1784 | loss: 0.69843 - binary_acc: 0.6338 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1785  | total loss: \u001b[1m\u001b[32m0.69770\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1785 | loss: 0.69770 - binary_acc: 0.6204 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1786  | total loss: \u001b[1m\u001b[32m0.69573\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1786 | loss: 0.69573 - binary_acc: 0.6084 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1787  | total loss: \u001b[1m\u001b[32m0.69264\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1787 | loss: 0.69264 - binary_acc: 0.5726 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1788  | total loss: \u001b[1m\u001b[32m0.68774\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1788 | loss: 0.68774 - binary_acc: 0.5903 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1789  | total loss: \u001b[1m\u001b[32m0.68502\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1789 | loss: 0.68502 - binary_acc: 0.6063 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1790  | total loss: \u001b[1m\u001b[32m0.68703\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1790 | loss: 0.68703 - binary_acc: 0.5956 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1791  | total loss: \u001b[1m\u001b[32m0.68264\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1791 | loss: 0.68264 - binary_acc: 0.5861 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1792  | total loss: \u001b[1m\u001b[32m0.67623\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1792 | loss: 0.67623 - binary_acc: 0.6025 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1793  | total loss: \u001b[1m\u001b[32m0.66956\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1793 | loss: 0.66956 - binary_acc: 0.6172 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1794  | total loss: \u001b[1m\u001b[32m0.66088\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1794 | loss: 0.66088 - binary_acc: 0.6305 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1795  | total loss: \u001b[1m\u001b[32m0.65217\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1795 | loss: 0.65217 - binary_acc: 0.6424 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1796  | total loss: \u001b[1m\u001b[32m0.64413\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1796 | loss: 0.64413 - binary_acc: 0.6532 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1797  | total loss: \u001b[1m\u001b[32m0.63677\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1797 | loss: 0.63677 - binary_acc: 0.6629 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1798  | total loss: \u001b[1m\u001b[32m0.63003\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1798 | loss: 0.63003 - binary_acc: 0.6716 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1799  | total loss: \u001b[1m\u001b[32m0.62386\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1799 | loss: 0.62386 - binary_acc: 0.6794 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1800  | total loss: \u001b[1m\u001b[32m0.61822\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1800 | loss: 0.61822 - binary_acc: 0.6865 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1801  | total loss: \u001b[1m\u001b[32m0.61304\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1801 | loss: 0.61304 - binary_acc: 0.6928 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1802  | total loss: \u001b[1m\u001b[32m0.65133\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1802 | loss: 0.65133 - binary_acc: 0.6486 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1803  | total loss: \u001b[1m\u001b[32m0.64493\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1803 | loss: 0.64493 - binary_acc: 0.6587 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1804  | total loss: \u001b[1m\u001b[32m0.63697\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1804 | loss: 0.63697 - binary_acc: 0.6678 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1805  | total loss: \u001b[1m\u001b[32m0.62925\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1805 | loss: 0.62925 - binary_acc: 0.6760 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1806  | total loss: \u001b[1m\u001b[32m0.62167\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1806 | loss: 0.62167 - binary_acc: 0.6834 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1807  | total loss: \u001b[1m\u001b[32m0.61363\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1807 | loss: 0.61363 - binary_acc: 0.6901 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1808  | total loss: \u001b[1m\u001b[32m0.60396\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1808 | loss: 0.60396 - binary_acc: 0.6961 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1809  | total loss: \u001b[1m\u001b[32m0.59116\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1809 | loss: 0.59116 - binary_acc: 0.7265 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1810  | total loss: \u001b[1m\u001b[32m0.57567\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1810 | loss: 0.57567 - binary_acc: 0.7538 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1811  | total loss: \u001b[1m\u001b[32m0.57071\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1811 | loss: 0.57071 - binary_acc: 0.7534 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1812  | total loss: \u001b[1m\u001b[32m0.58065\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1812 | loss: 0.58065 - binary_acc: 0.7281 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1813  | total loss: \u001b[1m\u001b[32m0.57949\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1813 | loss: 0.57949 - binary_acc: 0.7303 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1814  | total loss: \u001b[1m\u001b[32m0.57742\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1814 | loss: 0.57742 - binary_acc: 0.7323 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1815  | total loss: \u001b[1m\u001b[32m0.57428\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1815 | loss: 0.57428 - binary_acc: 0.7340 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1816  | total loss: \u001b[1m\u001b[32m0.62602\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1816 | loss: 0.62602 - binary_acc: 0.6856 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1817  | total loss: \u001b[1m\u001b[32m0.61905\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1817 | loss: 0.61905 - binary_acc: 0.6921 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1818  | total loss: \u001b[1m\u001b[32m0.61175\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1818 | loss: 0.61175 - binary_acc: 0.6979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1819  | total loss: \u001b[1m\u001b[32m0.60053\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1819 | loss: 0.60053 - binary_acc: 0.7031 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1820  | total loss: \u001b[1m\u001b[32m0.57907\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1820 | loss: 0.57907 - binary_acc: 0.7328 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1821  | total loss: \u001b[1m\u001b[32m0.55970\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1821 | loss: 0.55970 - binary_acc: 0.7595 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1822  | total loss: \u001b[1m\u001b[32m0.57906\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1822 | loss: 0.57906 - binary_acc: 0.7335 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1823  | total loss: \u001b[1m\u001b[32m0.59799\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1823 | loss: 0.59799 - binary_acc: 0.7102 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1824  | total loss: \u001b[1m\u001b[32m0.59626\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1824 | loss: 0.59626 - binary_acc: 0.7142 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1825  | total loss: \u001b[1m\u001b[32m0.59153\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1825 | loss: 0.59153 - binary_acc: 0.7178 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1826  | total loss: \u001b[1m\u001b[32m0.58224\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1826 | loss: 0.58224 - binary_acc: 0.7210 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1827  | total loss: \u001b[1m\u001b[32m0.56997\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1827 | loss: 0.56997 - binary_acc: 0.7239 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1828  | total loss: \u001b[1m\u001b[32m0.55309\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1828 | loss: 0.55309 - binary_acc: 0.7515 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1829  | total loss: \u001b[1m\u001b[32m0.55439\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1829 | loss: 0.55439 - binary_acc: 0.7513 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1830  | total loss: \u001b[1m\u001b[32m0.55480\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1830 | loss: 0.55480 - binary_acc: 0.7512 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1831  | total loss: \u001b[1m\u001b[32m0.55277\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1831 | loss: 0.55277 - binary_acc: 0.7511 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1832  | total loss: \u001b[1m\u001b[32m0.53169\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1832 | loss: 0.53169 - binary_acc: 0.7760 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1833  | total loss: \u001b[1m\u001b[32m0.51130\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1833 | loss: 0.51130 - binary_acc: 0.7984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1834  | total loss: \u001b[1m\u001b[32m0.49279\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1834 | loss: 0.49279 - binary_acc: 0.8185 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1835  | total loss: \u001b[1m\u001b[32m0.47602\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1835 | loss: 0.47602 - binary_acc: 0.8367 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1836  | total loss: \u001b[1m\u001b[32m0.46084\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1836 | loss: 0.46084 - binary_acc: 0.8530 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1837  | total loss: \u001b[1m\u001b[32m0.44711\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1837 | loss: 0.44711 - binary_acc: 0.8677 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1838  | total loss: \u001b[1m\u001b[32m0.48309\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1838 | loss: 0.48309 - binary_acc: 0.8309 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1839  | total loss: \u001b[1m\u001b[32m0.46715\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1839 | loss: 0.46715 - binary_acc: 0.8479 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1840  | total loss: \u001b[1m\u001b[32m0.45272\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1840 | loss: 0.45272 - binary_acc: 0.8631 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1841  | total loss: \u001b[1m\u001b[32m0.43967\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1841 | loss: 0.43967 - binary_acc: 0.8768 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1842  | total loss: \u001b[1m\u001b[32m0.42788\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1842 | loss: 0.42788 - binary_acc: 0.8891 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1843  | total loss: \u001b[1m\u001b[32m0.41722\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1843 | loss: 0.41722 - binary_acc: 0.9002 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1844  | total loss: \u001b[1m\u001b[32m0.40760\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1844 | loss: 0.40760 - binary_acc: 0.9102 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1845  | total loss: \u001b[1m\u001b[32m0.39890\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1845 | loss: 0.39890 - binary_acc: 0.9191 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1846  | total loss: \u001b[1m\u001b[32m0.39104\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1846 | loss: 0.39104 - binary_acc: 0.9272 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1847  | total loss: \u001b[1m\u001b[32m0.38393\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1847 | loss: 0.38393 - binary_acc: 0.9345 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1848  | total loss: \u001b[1m\u001b[32m0.42633\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1848 | loss: 0.42633 - binary_acc: 0.8911 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1849  | total loss: \u001b[1m\u001b[32m0.41572\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1849 | loss: 0.41572 - binary_acc: 0.9019 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1850  | total loss: \u001b[1m\u001b[32m0.40613\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1850 | loss: 0.40613 - binary_acc: 0.9118 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1851  | total loss: \u001b[1m\u001b[32m0.39747\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1851 | loss: 0.39747 - binary_acc: 0.9206 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1852  | total loss: \u001b[1m\u001b[32m0.43864\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1852 | loss: 0.43864 - binary_acc: 0.8785 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1853  | total loss: \u001b[1m\u001b[32m0.42671\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1853 | loss: 0.42671 - binary_acc: 0.8907 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1854  | total loss: \u001b[1m\u001b[32m0.46493\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1854 | loss: 0.46493 - binary_acc: 0.8516 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1855  | total loss: \u001b[1m\u001b[32m0.45038\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1855 | loss: 0.45038 - binary_acc: 0.8664 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1856  | total loss: \u001b[1m\u001b[32m0.43726\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1856 | loss: 0.43726 - binary_acc: 0.8798 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1857  | total loss: \u001b[1m\u001b[32m0.42542\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1857 | loss: 0.42542 - binary_acc: 0.8918 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1858  | total loss: \u001b[1m\u001b[32m0.41476\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1858 | loss: 0.41476 - binary_acc: 0.9026 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1859  | total loss: \u001b[1m\u001b[32m0.40514\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1859 | loss: 0.40514 - binary_acc: 0.9124 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1860  | total loss: \u001b[1m\u001b[32m0.44553\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1860 | loss: 0.44553 - binary_acc: 0.8711 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1861  | total loss: \u001b[1m\u001b[32m0.43284\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1861 | loss: 0.43284 - binary_acc: 0.8840 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1862  | total loss: \u001b[1m\u001b[32m0.42139\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1862 | loss: 0.42139 - binary_acc: 0.8956 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1863  | total loss: \u001b[1m\u001b[32m0.41108\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1863 | loss: 0.41108 - binary_acc: 0.9061 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1864  | total loss: \u001b[1m\u001b[32m0.40178\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1864 | loss: 0.40178 - binary_acc: 0.9155 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1865  | total loss: \u001b[1m\u001b[32m0.39340\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1865 | loss: 0.39340 - binary_acc: 0.9239 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1866  | total loss: \u001b[1m\u001b[32m0.43493\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1866 | loss: 0.43493 - binary_acc: 0.8815 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1867  | total loss: \u001b[1m\u001b[32m0.42325\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1867 | loss: 0.42325 - binary_acc: 0.8934 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1868  | total loss: \u001b[1m\u001b[32m0.41272\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1868 | loss: 0.41272 - binary_acc: 0.9040 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1869  | total loss: \u001b[1m\u001b[32m0.40322\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1869 | loss: 0.40322 - binary_acc: 0.9136 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1870  | total loss: \u001b[1m\u001b[32m0.39466\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1870 | loss: 0.39466 - binary_acc: 0.9223 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1871  | total loss: \u001b[1m\u001b[32m0.38695\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1871 | loss: 0.38695 - binary_acc: 0.9300 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1872  | total loss: \u001b[1m\u001b[32m0.38000\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1872 | loss: 0.38000 - binary_acc: 0.9370 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1873  | total loss: \u001b[1m\u001b[32m0.37373\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1873 | loss: 0.37373 - binary_acc: 0.9433 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1874  | total loss: \u001b[1m\u001b[32m0.36808\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1874 | loss: 0.36808 - binary_acc: 0.9490 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1875  | total loss: \u001b[1m\u001b[32m0.36298\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1875 | loss: 0.36298 - binary_acc: 0.9541 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1876  | total loss: \u001b[1m\u001b[32m0.35839\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1876 | loss: 0.35839 - binary_acc: 0.9587 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1877  | total loss: \u001b[1m\u001b[32m0.35424\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1877 | loss: 0.35424 - binary_acc: 0.9628 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1878  | total loss: \u001b[1m\u001b[32m0.35051\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1878 | loss: 0.35051 - binary_acc: 0.9665 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1879  | total loss: \u001b[1m\u001b[32m0.34714\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1879 | loss: 0.34714 - binary_acc: 0.9699 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1880  | total loss: \u001b[1m\u001b[32m0.34409\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1880 | loss: 0.34409 - binary_acc: 0.9729 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1881  | total loss: \u001b[1m\u001b[32m0.34135\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1881 | loss: 0.34135 - binary_acc: 0.9756 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1882  | total loss: \u001b[1m\u001b[32m0.33887\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1882 | loss: 0.33887 - binary_acc: 0.9780 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1883  | total loss: \u001b[1m\u001b[32m0.33664\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1883 | loss: 0.33664 - binary_acc: 0.9802 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1884  | total loss: \u001b[1m\u001b[32m0.33462\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1884 | loss: 0.33462 - binary_acc: 0.9822 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1885  | total loss: \u001b[1m\u001b[32m0.33280\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1885 | loss: 0.33280 - binary_acc: 0.9840 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1886  | total loss: \u001b[1m\u001b[32m0.33115\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1886 | loss: 0.33115 - binary_acc: 0.9856 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1887  | total loss: \u001b[1m\u001b[32m0.32967\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1887 | loss: 0.32967 - binary_acc: 0.9870 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1888  | total loss: \u001b[1m\u001b[32m0.32833\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1888 | loss: 0.32833 - binary_acc: 0.9883 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1889  | total loss: \u001b[1m\u001b[32m0.32711\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1889 | loss: 0.32711 - binary_acc: 0.9895 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1890  | total loss: \u001b[1m\u001b[32m0.32602\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1890 | loss: 0.32602 - binary_acc: 0.9905 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1891  | total loss: \u001b[1m\u001b[32m0.32502\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1891 | loss: 0.32502 - binary_acc: 0.9915 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1892  | total loss: \u001b[1m\u001b[32m0.37360\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1892 | loss: 0.37360 - binary_acc: 0.9423 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1893  | total loss: \u001b[1m\u001b[32m0.36786\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1893 | loss: 0.36786 - binary_acc: 0.9481 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1894  | total loss: \u001b[1m\u001b[32m0.41220\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1894 | loss: 0.41220 - binary_acc: 0.9033 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1895  | total loss: \u001b[1m\u001b[32m0.40259\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1895 | loss: 0.40259 - binary_acc: 0.9130 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1896  | total loss: \u001b[1m\u001b[32m0.39393\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1896 | loss: 0.39393 - binary_acc: 0.9217 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1897  | total loss: \u001b[1m\u001b[32m0.38614\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1897 | loss: 0.38614 - binary_acc: 0.9295 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1898  | total loss: \u001b[1m\u001b[32m0.37912\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1898 | loss: 0.37912 - binary_acc: 0.9366 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1899  | total loss: \u001b[1m\u001b[32m0.37280\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1899 | loss: 0.37280 - binary_acc: 0.9429 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1900  | total loss: \u001b[1m\u001b[32m0.36710\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1900 | loss: 0.36710 - binary_acc: 0.9486 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1901  | total loss: \u001b[1m\u001b[32m0.36197\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 1901 | loss: 0.36197 - binary_acc: 0.9537 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1902  | total loss: \u001b[1m\u001b[32m0.35736\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1902 | loss: 0.35736 - binary_acc: 0.9584 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1903  | total loss: \u001b[1m\u001b[32m0.35319\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1903 | loss: 0.35319 - binary_acc: 0.9625 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1904  | total loss: \u001b[1m\u001b[32m0.34945\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1904 | loss: 0.34945 - binary_acc: 0.9663 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1905  | total loss: \u001b[1m\u001b[32m0.34607\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1905 | loss: 0.34607 - binary_acc: 0.9697 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1906  | total loss: \u001b[1m\u001b[32m0.34303\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1906 | loss: 0.34303 - binary_acc: 0.9727 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1907  | total loss: \u001b[1m\u001b[32m0.34028\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1907 | loss: 0.34028 - binary_acc: 0.9754 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1908  | total loss: \u001b[1m\u001b[32m0.33781\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1908 | loss: 0.33781 - binary_acc: 0.9779 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1909  | total loss: \u001b[1m\u001b[32m0.33559\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1909 | loss: 0.33559 - binary_acc: 0.9801 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1910  | total loss: \u001b[1m\u001b[32m0.33358\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1910 | loss: 0.33358 - binary_acc: 0.9821 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1911  | total loss: \u001b[1m\u001b[32m0.33177\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1911 | loss: 0.33177 - binary_acc: 0.9839 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1912  | total loss: \u001b[1m\u001b[32m0.37972\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1912 | loss: 0.37972 - binary_acc: 0.9355 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1913  | total loss: \u001b[1m\u001b[32m0.37330\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1913 | loss: 0.37330 - binary_acc: 0.9419 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1914  | total loss: \u001b[1m\u001b[32m0.36751\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1914 | loss: 0.36751 - binary_acc: 0.9477 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1915  | total loss: \u001b[1m\u001b[32m0.36230\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1915 | loss: 0.36230 - binary_acc: 0.9530 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1916  | total loss: \u001b[1m\u001b[32m0.35762\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1916 | loss: 0.35762 - binary_acc: 0.9577 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1917  | total loss: \u001b[1m\u001b[32m0.35339\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1917 | loss: 0.35339 - binary_acc: 0.9619 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1918  | total loss: \u001b[1m\u001b[32m0.34959\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1918 | loss: 0.34959 - binary_acc: 0.9657 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1919  | total loss: \u001b[1m\u001b[32m0.34616\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 1919 | loss: 0.34616 - binary_acc: 0.9691 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1920  | total loss: \u001b[1m\u001b[32m0.34308\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1920 | loss: 0.34308 - binary_acc: 0.9722 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1921  | total loss: \u001b[1m\u001b[32m0.34030\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1921 | loss: 0.34030 - binary_acc: 0.9750 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1922  | total loss: \u001b[1m\u001b[32m0.33779\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1922 | loss: 0.33779 - binary_acc: 0.9775 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1923  | total loss: \u001b[1m\u001b[32m0.33554\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1923 | loss: 0.33554 - binary_acc: 0.9798 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1924  | total loss: \u001b[1m\u001b[32m0.33350\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1924 | loss: 0.33350 - binary_acc: 0.9818 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1925  | total loss: \u001b[1m\u001b[32m0.33167\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1925 | loss: 0.33167 - binary_acc: 0.9836 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1926  | total loss: \u001b[1m\u001b[32m0.33002\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1926 | loss: 0.33002 - binary_acc: 0.9852 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1927  | total loss: \u001b[1m\u001b[32m0.32853\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1927 | loss: 0.32853 - binary_acc: 0.9867 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1928  | total loss: \u001b[1m\u001b[32m0.32719\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1928 | loss: 0.32719 - binary_acc: 0.9880 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1929  | total loss: \u001b[1m\u001b[32m0.32598\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1929 | loss: 0.32598 - binary_acc: 0.9892 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1930  | total loss: \u001b[1m\u001b[32m0.32489\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1930 | loss: 0.32489 - binary_acc: 0.9903 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1931  | total loss: \u001b[1m\u001b[32m0.32391\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1931 | loss: 0.32391 - binary_acc: 0.9913 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1932  | total loss: \u001b[1m\u001b[32m0.32302\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1932 | loss: 0.32302 - binary_acc: 0.9922 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1933  | total loss: \u001b[1m\u001b[32m0.32222\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1933 | loss: 0.32222 - binary_acc: 0.9929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1934  | total loss: \u001b[1m\u001b[32m0.32150\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1934 | loss: 0.32150 - binary_acc: 0.9936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1935  | total loss: \u001b[1m\u001b[32m0.32085\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1935 | loss: 0.32085 - binary_acc: 0.9943 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1936  | total loss: \u001b[1m\u001b[32m0.32026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1936 | loss: 0.32026 - binary_acc: 0.9949 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1937  | total loss: \u001b[1m\u001b[32m0.31973\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1937 | loss: 0.31973 - binary_acc: 0.9954 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1938  | total loss: \u001b[1m\u001b[32m0.31925\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1938 | loss: 0.31925 - binary_acc: 0.9958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1939  | total loss: \u001b[1m\u001b[32m0.31882\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1939 | loss: 0.31882 - binary_acc: 0.9962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1940  | total loss: \u001b[1m\u001b[32m0.31843\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1940 | loss: 0.31843 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1941  | total loss: \u001b[1m\u001b[32m0.31807\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1941 | loss: 0.31807 - binary_acc: 0.9970 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1942  | total loss: \u001b[1m\u001b[32m0.36747\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1942 | loss: 0.36747 - binary_acc: 0.9473 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1943  | total loss: \u001b[1m\u001b[32m0.36221\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1943 | loss: 0.36221 - binary_acc: 0.9525 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1944  | total loss: \u001b[1m\u001b[32m0.35748\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1944 | loss: 0.35748 - binary_acc: 0.9573 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1945  | total loss: \u001b[1m\u001b[32m0.35322\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1945 | loss: 0.35322 - binary_acc: 0.9616 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1946  | total loss: \u001b[1m\u001b[32m0.34938\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1946 | loss: 0.34938 - binary_acc: 0.9654 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1947  | total loss: \u001b[1m\u001b[32m0.34592\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1947 | loss: 0.34592 - binary_acc: 0.9689 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1948  | total loss: \u001b[1m\u001b[32m0.34281\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1948 | loss: 0.34281 - binary_acc: 0.9720 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1949  | total loss: \u001b[1m\u001b[32m0.34001\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1949 | loss: 0.34001 - binary_acc: 0.9748 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1950  | total loss: \u001b[1m\u001b[32m0.33749\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1950 | loss: 0.33749 - binary_acc: 0.9773 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1951  | total loss: \u001b[1m\u001b[32m0.33522\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1951 | loss: 0.33522 - binary_acc: 0.9796 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1952  | total loss: \u001b[1m\u001b[32m0.33317\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1952 | loss: 0.33317 - binary_acc: 0.9816 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1953  | total loss: \u001b[1m\u001b[32m0.33133\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1953 | loss: 0.33133 - binary_acc: 0.9835 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1954  | total loss: \u001b[1m\u001b[32m0.32967\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1954 | loss: 0.32967 - binary_acc: 0.9851 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1955  | total loss: \u001b[1m\u001b[32m0.32817\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1955 | loss: 0.32817 - binary_acc: 0.9866 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1956  | total loss: \u001b[1m\u001b[32m0.32683\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1956 | loss: 0.32683 - binary_acc: 0.9879 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1957  | total loss: \u001b[1m\u001b[32m0.32561\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1957 | loss: 0.32561 - binary_acc: 0.9891 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1958  | total loss: \u001b[1m\u001b[32m0.32452\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1958 | loss: 0.32452 - binary_acc: 0.9902 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1959  | total loss: \u001b[1m\u001b[32m0.32354\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1959 | loss: 0.32354 - binary_acc: 0.9912 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1960  | total loss: \u001b[1m\u001b[32m0.32265\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1960 | loss: 0.32265 - binary_acc: 0.9921 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1961  | total loss: \u001b[1m\u001b[32m0.32185\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1961 | loss: 0.32185 - binary_acc: 0.9929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1962  | total loss: \u001b[1m\u001b[32m0.32113\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1962 | loss: 0.32113 - binary_acc: 0.9936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1963  | total loss: \u001b[1m\u001b[32m0.32048\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1963 | loss: 0.32048 - binary_acc: 0.9942 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1964  | total loss: \u001b[1m\u001b[32m0.31989\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1964 | loss: 0.31989 - binary_acc: 0.9948 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1965  | total loss: \u001b[1m\u001b[32m0.31936\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1965 | loss: 0.31936 - binary_acc: 0.9953 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1966  | total loss: \u001b[1m\u001b[32m0.31888\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1966 | loss: 0.31888 - binary_acc: 0.9958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1967  | total loss: \u001b[1m\u001b[32m0.31845\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1967 | loss: 0.31845 - binary_acc: 0.9962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1968  | total loss: \u001b[1m\u001b[32m0.31807\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1968 | loss: 0.31807 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1969  | total loss: \u001b[1m\u001b[32m0.31772\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1969 | loss: 0.31772 - binary_acc: 0.9969 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1970  | total loss: \u001b[1m\u001b[32m0.31740\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1970 | loss: 0.31740 - binary_acc: 0.9972 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1971  | total loss: \u001b[1m\u001b[32m0.31711\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1971 | loss: 0.31711 - binary_acc: 0.9975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1972  | total loss: \u001b[1m\u001b[32m0.31686\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1972 | loss: 0.31686 - binary_acc: 0.9978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1973  | total loss: \u001b[1m\u001b[32m0.31662\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1973 | loss: 0.31662 - binary_acc: 0.9980 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1974  | total loss: \u001b[1m\u001b[32m0.31641\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1974 | loss: 0.31641 - binary_acc: 0.9982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1975  | total loss: \u001b[1m\u001b[32m0.31622\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1975 | loss: 0.31622 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1976  | total loss: \u001b[1m\u001b[32m0.31605\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1976 | loss: 0.31605 - binary_acc: 0.9985 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1977  | total loss: \u001b[1m\u001b[32m0.31589\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1977 | loss: 0.31589 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1978  | total loss: \u001b[1m\u001b[32m0.31575\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1978 | loss: 0.31575 - binary_acc: 0.9988 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1979  | total loss: \u001b[1m\u001b[32m0.31562\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1979 | loss: 0.31562 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1980  | total loss: \u001b[1m\u001b[32m0.36528\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1980 | loss: 0.36528 - binary_acc: 0.9490 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1981  | total loss: \u001b[1m\u001b[32m0.36020\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1981 | loss: 0.36020 - binary_acc: 0.9541 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1982  | total loss: \u001b[1m\u001b[32m0.35562\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1982 | loss: 0.35562 - binary_acc: 0.9587 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1983  | total loss: \u001b[1m\u001b[32m0.35151\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1983 | loss: 0.35151 - binary_acc: 0.9628 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1984  | total loss: \u001b[1m\u001b[32m0.39759\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1984 | loss: 0.39759 - binary_acc: 0.9166 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1985  | total loss: \u001b[1m\u001b[32m0.38928\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1985 | loss: 0.38928 - binary_acc: 0.9249 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1986  | total loss: \u001b[1m\u001b[32m0.43158\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1986 | loss: 0.43158 - binary_acc: 0.8824 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1987  | total loss: \u001b[1m\u001b[32m0.41987\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1987 | loss: 0.41987 - binary_acc: 0.8942 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1988  | total loss: \u001b[1m\u001b[32m0.40933\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1988 | loss: 0.40933 - binary_acc: 0.9048 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1989  | total loss: \u001b[1m\u001b[32m0.39984\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1989 | loss: 0.39984 - binary_acc: 0.9143 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1990  | total loss: \u001b[1m\u001b[32m0.39130\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1990 | loss: 0.39130 - binary_acc: 0.9229 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1991  | total loss: \u001b[1m\u001b[32m0.38361\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1991 | loss: 0.38361 - binary_acc: 0.9306 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1992  | total loss: \u001b[1m\u001b[32m0.37669\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1992 | loss: 0.37669 - binary_acc: 0.9375 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1993  | total loss: \u001b[1m\u001b[32m0.37046\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1993 | loss: 0.37046 - binary_acc: 0.9438 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1994  | total loss: \u001b[1m\u001b[32m0.36485\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1994 | loss: 0.36485 - binary_acc: 0.9494 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1995  | total loss: \u001b[1m\u001b[32m0.35981\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1995 | loss: 0.35981 - binary_acc: 0.9544 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1996  | total loss: \u001b[1m\u001b[32m0.35526\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 1996 | loss: 0.35526 - binary_acc: 0.9590 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1997  | total loss: \u001b[1m\u001b[32m0.35117\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 1997 | loss: 0.35117 - binary_acc: 0.9631 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1998  | total loss: \u001b[1m\u001b[32m0.34749\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1998 | loss: 0.34749 - binary_acc: 0.9668 -- iter: 4/4\n",
            "--\n",
            "Training Step: 1999  | total loss: \u001b[1m\u001b[32m0.34418\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 1999 | loss: 0.34418 - binary_acc: 0.9701 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2000  | total loss: \u001b[1m\u001b[32m0.34120\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2000 | loss: 0.34120 - binary_acc: 0.9731 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2001  | total loss: \u001b[1m\u001b[32m0.33851\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2001 | loss: 0.33851 - binary_acc: 0.9758 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2002  | total loss: \u001b[1m\u001b[32m0.33609\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2002 | loss: 0.33609 - binary_acc: 0.9782 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2003  | total loss: \u001b[1m\u001b[32m0.33392\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2003 | loss: 0.33392 - binary_acc: 0.9804 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2004  | total loss: \u001b[1m\u001b[32m0.33196\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2004 | loss: 0.33196 - binary_acc: 0.9824 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2005  | total loss: \u001b[1m\u001b[32m0.33019\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2005 | loss: 0.33019 - binary_acc: 0.9841 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2006  | total loss: \u001b[1m\u001b[32m0.32860\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2006 | loss: 0.32860 - binary_acc: 0.9857 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2007  | total loss: \u001b[1m\u001b[32m0.32717\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2007 | loss: 0.32717 - binary_acc: 0.9871 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2008  | total loss: \u001b[1m\u001b[32m0.32589\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2008 | loss: 0.32589 - binary_acc: 0.9884 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2009  | total loss: \u001b[1m\u001b[32m0.32473\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2009 | loss: 0.32473 - binary_acc: 0.9896 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2010  | total loss: \u001b[1m\u001b[32m0.32368\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2010 | loss: 0.32368 - binary_acc: 0.9906 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2011  | total loss: \u001b[1m\u001b[32m0.32274\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2011 | loss: 0.32274 - binary_acc: 0.9916 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2012  | total loss: \u001b[1m\u001b[32m0.32189\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2012 | loss: 0.32189 - binary_acc: 0.9924 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2013  | total loss: \u001b[1m\u001b[32m0.32113\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2013 | loss: 0.32113 - binary_acc: 0.9932 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2014  | total loss: \u001b[1m\u001b[32m0.32044\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2014 | loss: 0.32044 - binary_acc: 0.9938 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2015  | total loss: \u001b[1m\u001b[32m0.31982\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2015 | loss: 0.31982 - binary_acc: 0.9945 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2016  | total loss: \u001b[1m\u001b[32m0.31927\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2016 | loss: 0.31927 - binary_acc: 0.9950 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2017  | total loss: \u001b[1m\u001b[32m0.31876\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2017 | loss: 0.31876 - binary_acc: 0.9955 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2018  | total loss: \u001b[1m\u001b[32m0.31831\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2018 | loss: 0.31831 - binary_acc: 0.9960 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2019  | total loss: \u001b[1m\u001b[32m0.31790\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2019 | loss: 0.31790 - binary_acc: 0.9964 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2020  | total loss: \u001b[1m\u001b[32m0.31753\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2020 | loss: 0.31753 - binary_acc: 0.9967 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2021  | total loss: \u001b[1m\u001b[32m0.31720\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2021 | loss: 0.31720 - binary_acc: 0.9971 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2022  | total loss: \u001b[1m\u001b[32m0.31690\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2022 | loss: 0.31690 - binary_acc: 0.9974 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2023  | total loss: \u001b[1m\u001b[32m0.31663\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2023 | loss: 0.31663 - binary_acc: 0.9976 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2024  | total loss: \u001b[1m\u001b[32m0.31639\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2024 | loss: 0.31639 - binary_acc: 0.9979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2025  | total loss: \u001b[1m\u001b[32m0.31617\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2025 | loss: 0.31617 - binary_acc: 0.9981 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2026  | total loss: \u001b[1m\u001b[32m0.31597\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2026 | loss: 0.31597 - binary_acc: 0.9983 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2027  | total loss: \u001b[1m\u001b[32m0.31579\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2027 | loss: 0.31579 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2028  | total loss: \u001b[1m\u001b[32m0.31563\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2028 | loss: 0.31563 - binary_acc: 0.9986 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2029  | total loss: \u001b[1m\u001b[32m0.31549\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2029 | loss: 0.31549 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2030  | total loss: \u001b[1m\u001b[32m0.31536\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2030 | loss: 0.31536 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2031  | total loss: \u001b[1m\u001b[32m0.31524\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2031 | loss: 0.31524 - binary_acc: 0.9990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2032  | total loss: \u001b[1m\u001b[32m0.31513\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2032 | loss: 0.31513 - binary_acc: 0.9991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2033  | total loss: \u001b[1m\u001b[32m0.31503\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2033 | loss: 0.31503 - binary_acc: 0.9992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2034  | total loss: \u001b[1m\u001b[32m0.31494\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2034 | loss: 0.31494 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2035  | total loss: \u001b[1m\u001b[32m0.31486\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2035 | loss: 0.31486 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2036  | total loss: \u001b[1m\u001b[32m0.41447\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2036 | loss: 0.41447 - binary_acc: 0.8994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2037  | total loss: \u001b[1m\u001b[32m0.40443\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2037 | loss: 0.40443 - binary_acc: 0.9095 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2038  | total loss: \u001b[1m\u001b[32m0.39541\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2038 | loss: 0.39541 - binary_acc: 0.9185 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2039  | total loss: \u001b[1m\u001b[32m0.38728\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2039 | loss: 0.38728 - binary_acc: 0.9267 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2040  | total loss: \u001b[1m\u001b[32m0.37997\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2040 | loss: 0.37997 - binary_acc: 0.9340 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2041  | total loss: \u001b[1m\u001b[32m0.37338\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2041 | loss: 0.37338 - binary_acc: 0.9406 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2042  | total loss: \u001b[1m\u001b[32m0.36746\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2042 | loss: 0.36746 - binary_acc: 0.9465 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2043  | total loss: \u001b[1m\u001b[32m0.36212\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2043 | loss: 0.36212 - binary_acc: 0.9519 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2044  | total loss: \u001b[1m\u001b[32m0.35732\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2044 | loss: 0.35732 - binary_acc: 0.9567 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2045  | total loss: \u001b[1m\u001b[32m0.35300\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2045 | loss: 0.35300 - binary_acc: 0.9610 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2046  | total loss: \u001b[1m\u001b[32m0.39895\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2046 | loss: 0.39895 - binary_acc: 0.9149 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2047  | total loss: \u001b[1m\u001b[32m0.39047\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2047 | loss: 0.39047 - binary_acc: 0.9234 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2048  | total loss: \u001b[1m\u001b[32m0.43268\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2048 | loss: 0.43268 - binary_acc: 0.8811 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2049  | total loss: \u001b[1m\u001b[32m0.42082\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2049 | loss: 0.42082 - binary_acc: 0.8930 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2050  | total loss: \u001b[1m\u001b[32m0.41015\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2050 | loss: 0.41015 - binary_acc: 0.9037 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2051  | total loss: \u001b[1m\u001b[32m0.40055\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2051 | loss: 0.40055 - binary_acc: 0.9133 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2052  | total loss: \u001b[1m\u001b[32m0.39190\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2052 | loss: 0.39190 - binary_acc: 0.9220 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2053  | total loss: \u001b[1m\u001b[32m0.38412\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2053 | loss: 0.38412 - binary_acc: 0.9298 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2054  | total loss: \u001b[1m\u001b[32m0.37712\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2054 | loss: 0.37712 - binary_acc: 0.9368 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2055  | total loss: \u001b[1m\u001b[32m0.37082\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2055 | loss: 0.37082 - binary_acc: 0.9431 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2056  | total loss: \u001b[1m\u001b[32m0.36514\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2056 | loss: 0.36514 - binary_acc: 0.9488 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2057  | total loss: \u001b[1m\u001b[32m0.36004\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2057 | loss: 0.36004 - binary_acc: 0.9539 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2058  | total loss: \u001b[1m\u001b[32m0.35544\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2058 | loss: 0.35544 - binary_acc: 0.9585 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2059  | total loss: \u001b[1m\u001b[32m0.35131\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2059 | loss: 0.35131 - binary_acc: 0.9627 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2060  | total loss: \u001b[1m\u001b[32m0.34758\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2060 | loss: 0.34758 - binary_acc: 0.9664 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2061  | total loss: \u001b[1m\u001b[32m0.34423\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2061 | loss: 0.34423 - binary_acc: 0.9698 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2062  | total loss: \u001b[1m\u001b[32m0.34121\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2062 | loss: 0.34121 - binary_acc: 0.9728 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2063  | total loss: \u001b[1m\u001b[32m0.33850\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2063 | loss: 0.33850 - binary_acc: 0.9755 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2064  | total loss: \u001b[1m\u001b[32m0.33605\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2064 | loss: 0.33605 - binary_acc: 0.9780 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2065  | total loss: \u001b[1m\u001b[32m0.33385\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2065 | loss: 0.33385 - binary_acc: 0.9802 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2066  | total loss: \u001b[1m\u001b[32m0.33187\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2066 | loss: 0.33187 - binary_acc: 0.9822 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2067  | total loss: \u001b[1m\u001b[32m0.33009\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2067 | loss: 0.33009 - binary_acc: 0.9839 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2068  | total loss: \u001b[1m\u001b[32m0.32849\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2068 | loss: 0.32849 - binary_acc: 0.9855 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2069  | total loss: \u001b[1m\u001b[32m0.32704\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2069 | loss: 0.32704 - binary_acc: 0.9870 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2070  | total loss: \u001b[1m\u001b[32m0.32574\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2070 | loss: 0.32574 - binary_acc: 0.9883 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2071  | total loss: \u001b[1m\u001b[32m0.32457\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2071 | loss: 0.32457 - binary_acc: 0.9895 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2072  | total loss: \u001b[1m\u001b[32m0.32352\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2072 | loss: 0.32352 - binary_acc: 0.9905 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2073  | total loss: \u001b[1m\u001b[32m0.32257\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2073 | loss: 0.32257 - binary_acc: 0.9915 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2074  | total loss: \u001b[1m\u001b[32m0.32171\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2074 | loss: 0.32171 - binary_acc: 0.9923 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2075  | total loss: \u001b[1m\u001b[32m0.32094\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2075 | loss: 0.32094 - binary_acc: 0.9931 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2076  | total loss: \u001b[1m\u001b[32m0.37011\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2076 | loss: 0.37011 - binary_acc: 0.9438 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2077  | total loss: \u001b[1m\u001b[32m0.36450\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2077 | loss: 0.36450 - binary_acc: 0.9494 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2078  | total loss: \u001b[1m\u001b[32m0.35945\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2078 | loss: 0.35945 - binary_acc: 0.9545 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2079  | total loss: \u001b[1m\u001b[32m0.35491\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2079 | loss: 0.35491 - binary_acc: 0.9590 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2080  | total loss: \u001b[1m\u001b[32m0.35082\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2080 | loss: 0.35082 - binary_acc: 0.9631 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2081  | total loss: \u001b[1m\u001b[32m0.34714\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2081 | loss: 0.34714 - binary_acc: 0.9668 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2082  | total loss: \u001b[1m\u001b[32m0.34382\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2082 | loss: 0.34382 - binary_acc: 0.9701 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2083  | total loss: \u001b[1m\u001b[32m0.34084\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2083 | loss: 0.34084 - binary_acc: 0.9731 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2084  | total loss: \u001b[1m\u001b[32m0.33816\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2084 | loss: 0.33816 - binary_acc: 0.9758 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2085  | total loss: \u001b[1m\u001b[32m0.33574\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2085 | loss: 0.33574 - binary_acc: 0.9782 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2086  | total loss: \u001b[1m\u001b[32m0.38343\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2086 | loss: 0.38343 - binary_acc: 0.9304 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2087  | total loss: \u001b[1m\u001b[32m0.37648\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2087 | loss: 0.37648 - binary_acc: 0.9374 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2088  | total loss: \u001b[1m\u001b[32m0.37023\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2088 | loss: 0.37023 - binary_acc: 0.9436 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2089  | total loss: \u001b[1m\u001b[32m0.36461\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2089 | loss: 0.36461 - binary_acc: 0.9493 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2090  | total loss: \u001b[1m\u001b[32m0.35955\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2090 | loss: 0.35955 - binary_acc: 0.9543 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2091  | total loss: \u001b[1m\u001b[32m0.35499\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2091 | loss: 0.35499 - binary_acc: 0.9589 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2092  | total loss: \u001b[1m\u001b[32m0.35089\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2092 | loss: 0.35089 - binary_acc: 0.9630 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2093  | total loss: \u001b[1m\u001b[32m0.34720\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2093 | loss: 0.34720 - binary_acc: 0.9667 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2094  | total loss: \u001b[1m\u001b[32m0.34387\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2094 | loss: 0.34387 - binary_acc: 0.9700 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2095  | total loss: \u001b[1m\u001b[32m0.34088\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2095 | loss: 0.34088 - binary_acc: 0.9730 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2096  | total loss: \u001b[1m\u001b[32m0.33819\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2096 | loss: 0.33819 - binary_acc: 0.9757 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2097  | total loss: \u001b[1m\u001b[32m0.33577\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2097 | loss: 0.33577 - binary_acc: 0.9782 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2098  | total loss: \u001b[1m\u001b[32m0.33359\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2098 | loss: 0.33359 - binary_acc: 0.9803 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2099  | total loss: \u001b[1m\u001b[32m0.33162\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2099 | loss: 0.33162 - binary_acc: 0.9823 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2100  | total loss: \u001b[1m\u001b[32m0.42960\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2100 | loss: 0.42960 - binary_acc: 0.8841 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2101  | total loss: \u001b[1m\u001b[32m0.41804\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2101 | loss: 0.41804 - binary_acc: 0.8957 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2102  | total loss: \u001b[1m\u001b[32m0.40763\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2102 | loss: 0.40763 - binary_acc: 0.9061 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2103  | total loss: \u001b[1m\u001b[32m0.39826\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2103 | loss: 0.39826 - binary_acc: 0.9155 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2104  | total loss: \u001b[1m\u001b[32m0.43971\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2104 | loss: 0.43971 - binary_acc: 0.8739 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2105  | total loss: \u001b[1m\u001b[32m0.42713\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2105 | loss: 0.42713 - binary_acc: 0.8865 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2106  | total loss: \u001b[1m\u001b[32m0.41581\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2106 | loss: 0.41581 - binary_acc: 0.8979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2107  | total loss: \u001b[1m\u001b[32m0.40563\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2107 | loss: 0.40563 - binary_acc: 0.9081 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2108  | total loss: \u001b[1m\u001b[32m0.39646\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2108 | loss: 0.39646 - binary_acc: 0.9173 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2109  | total loss: \u001b[1m\u001b[32m0.38821\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2109 | loss: 0.38821 - binary_acc: 0.9256 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2110  | total loss: \u001b[1m\u001b[32m0.38078\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2110 | loss: 0.38078 - binary_acc: 0.9330 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2111  | total loss: \u001b[1m\u001b[32m0.37409\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2111 | loss: 0.37409 - binary_acc: 0.9397 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2112  | total loss: \u001b[1m\u001b[32m0.36808\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2112 | loss: 0.36808 - binary_acc: 0.9457 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2113  | total loss: \u001b[1m\u001b[32m0.36266\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2113 | loss: 0.36266 - binary_acc: 0.9512 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2114  | total loss: \u001b[1m\u001b[32m0.35779\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2114 | loss: 0.35779 - binary_acc: 0.9560 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2115  | total loss: \u001b[1m\u001b[32m0.35340\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2115 | loss: 0.35340 - binary_acc: 0.9604 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2116  | total loss: \u001b[1m\u001b[32m0.44921\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2116 | loss: 0.44921 - binary_acc: 0.8644 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2117  | total loss: \u001b[1m\u001b[32m0.43568\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2117 | loss: 0.43568 - binary_acc: 0.8780 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2118  | total loss: \u001b[1m\u001b[32m0.42351\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2118 | loss: 0.42351 - binary_acc: 0.8902 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2119  | total loss: \u001b[1m\u001b[32m0.41255\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2119 | loss: 0.41255 - binary_acc: 0.9011 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2120  | total loss: \u001b[1m\u001b[32m0.40269\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2120 | loss: 0.40269 - binary_acc: 0.9110 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2121  | total loss: \u001b[1m\u001b[32m0.39381\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2121 | loss: 0.39381 - binary_acc: 0.9199 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2122  | total loss: \u001b[1m\u001b[32m0.38582\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2122 | loss: 0.38582 - binary_acc: 0.9279 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2123  | total loss: \u001b[1m\u001b[32m0.37863\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2123 | loss: 0.37863 - binary_acc: 0.9351 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2124  | total loss: \u001b[1m\u001b[32m0.37216\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2124 | loss: 0.37216 - binary_acc: 0.9416 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2125  | total loss: \u001b[1m\u001b[32m0.36633\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2125 | loss: 0.36633 - binary_acc: 0.9475 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2126  | total loss: \u001b[1m\u001b[32m0.36109\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2126 | loss: 0.36109 - binary_acc: 0.9527 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2127  | total loss: \u001b[1m\u001b[32m0.35637\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2127 | loss: 0.35637 - binary_acc: 0.9574 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2128  | total loss: \u001b[1m\u001b[32m0.35212\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2128 | loss: 0.35212 - binary_acc: 0.9617 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2129  | total loss: \u001b[1m\u001b[32m0.34830\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2129 | loss: 0.34830 - binary_acc: 0.9655 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2130  | total loss: \u001b[1m\u001b[32m0.34486\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2130 | loss: 0.34486 - binary_acc: 0.9690 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2131  | total loss: \u001b[1m\u001b[32m0.34176\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2131 | loss: 0.34176 - binary_acc: 0.9721 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2132  | total loss: \u001b[1m\u001b[32m0.33898\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2132 | loss: 0.33898 - binary_acc: 0.9749 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2133  | total loss: \u001b[1m\u001b[32m0.33647\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2133 | loss: 0.33647 - binary_acc: 0.9774 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2134  | total loss: \u001b[1m\u001b[32m0.33421\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2134 | loss: 0.33421 - binary_acc: 0.9796 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2135  | total loss: \u001b[1m\u001b[32m0.33218\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2135 | loss: 0.33218 - binary_acc: 0.9817 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2136  | total loss: \u001b[1m\u001b[32m0.33035\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2136 | loss: 0.33035 - binary_acc: 0.9835 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2137  | total loss: \u001b[1m\u001b[32m0.32870\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2137 | loss: 0.32870 - binary_acc: 0.9852 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2138  | total loss: \u001b[1m\u001b[32m0.32722\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2138 | loss: 0.32722 - binary_acc: 0.9866 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2139  | total loss: \u001b[1m\u001b[32m0.32588\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2139 | loss: 0.32588 - binary_acc: 0.9880 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2140  | total loss: \u001b[1m\u001b[32m0.32468\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2140 | loss: 0.32468 - binary_acc: 0.9892 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2141  | total loss: \u001b[1m\u001b[32m0.32360\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2141 | loss: 0.32360 - binary_acc: 0.9903 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2142  | total loss: \u001b[1m\u001b[32m0.32263\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2142 | loss: 0.32263 - binary_acc: 0.9912 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2143  | total loss: \u001b[1m\u001b[32m0.32175\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2143 | loss: 0.32175 - binary_acc: 0.9921 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2144  | total loss: \u001b[1m\u001b[32m0.32096\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2144 | loss: 0.32096 - binary_acc: 0.9929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2145  | total loss: \u001b[1m\u001b[32m0.32025\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2145 | loss: 0.32025 - binary_acc: 0.9936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2146  | total loss: \u001b[1m\u001b[32m0.31961\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2146 | loss: 0.31961 - binary_acc: 0.9943 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2147  | total loss: \u001b[1m\u001b[32m0.31904\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2147 | loss: 0.31904 - binary_acc: 0.9948 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2148  | total loss: \u001b[1m\u001b[32m0.31852\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2148 | loss: 0.31852 - binary_acc: 0.9953 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2149  | total loss: \u001b[1m\u001b[32m0.31805\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2149 | loss: 0.31805 - binary_acc: 0.9958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2150  | total loss: \u001b[1m\u001b[32m0.31763\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2150 | loss: 0.31763 - binary_acc: 0.9962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2151  | total loss: \u001b[1m\u001b[32m0.31725\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2151 | loss: 0.31725 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2152  | total loss: \u001b[1m\u001b[32m0.31691\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2152 | loss: 0.31691 - binary_acc: 0.9969 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2153  | total loss: \u001b[1m\u001b[32m0.31661\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2153 | loss: 0.31661 - binary_acc: 0.9973 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2154  | total loss: \u001b[1m\u001b[32m0.31633\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2154 | loss: 0.31633 - binary_acc: 0.9975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2155  | total loss: \u001b[1m\u001b[32m0.31608\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2155 | loss: 0.31608 - binary_acc: 0.9978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2156  | total loss: \u001b[1m\u001b[32m0.31586\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2156 | loss: 0.31586 - binary_acc: 0.9980 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2157  | total loss: \u001b[1m\u001b[32m0.31565\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2157 | loss: 0.31565 - binary_acc: 0.9982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2158  | total loss: \u001b[1m\u001b[32m0.31547\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2158 | loss: 0.31547 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2159  | total loss: \u001b[1m\u001b[32m0.31531\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2159 | loss: 0.31531 - binary_acc: 0.9985 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2160  | total loss: \u001b[1m\u001b[32m0.31516\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2160 | loss: 0.31516 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2161  | total loss: \u001b[1m\u001b[32m0.31503\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2161 | loss: 0.31503 - binary_acc: 0.9988 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2162  | total loss: \u001b[1m\u001b[32m0.31491\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2162 | loss: 0.31491 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2163  | total loss: \u001b[1m\u001b[32m0.31480\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2163 | loss: 0.31480 - binary_acc: 0.9990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2164  | total loss: \u001b[1m\u001b[32m0.31470\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2164 | loss: 0.31470 - binary_acc: 0.9991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2165  | total loss: \u001b[1m\u001b[32m0.31461\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2165 | loss: 0.31461 - binary_acc: 0.9992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2166  | total loss: \u001b[1m\u001b[32m0.31453\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2166 | loss: 0.31453 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2167  | total loss: \u001b[1m\u001b[32m0.31446\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2167 | loss: 0.31446 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2168  | total loss: \u001b[1m\u001b[32m0.31440\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2168 | loss: 0.31440 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2169  | total loss: \u001b[1m\u001b[32m0.31434\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2169 | loss: 0.31434 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2170  | total loss: \u001b[1m\u001b[32m0.31429\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2170 | loss: 0.31429 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2171  | total loss: \u001b[1m\u001b[32m0.31424\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2171 | loss: 0.31424 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2172  | total loss: \u001b[1m\u001b[32m0.36410\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2172 | loss: 0.36410 - binary_acc: 0.9496 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2173  | total loss: \u001b[1m\u001b[32m0.35907\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2173 | loss: 0.35907 - binary_acc: 0.9547 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2174  | total loss: \u001b[1m\u001b[32m0.40444\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2174 | loss: 0.40444 - binary_acc: 0.9092 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2175  | total loss: \u001b[1m\u001b[32m0.39538\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2175 | loss: 0.39538 - binary_acc: 0.9183 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2176  | total loss: \u001b[1m\u001b[32m0.48702\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2176 | loss: 0.48702 - binary_acc: 0.8265 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2177  | total loss: \u001b[1m\u001b[32m0.46970\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2177 | loss: 0.46970 - binary_acc: 0.8438 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2178  | total loss: \u001b[1m\u001b[32m0.45411\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2178 | loss: 0.45411 - binary_acc: 0.8594 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2179  | total loss: \u001b[1m\u001b[32m0.44008\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2179 | loss: 0.44008 - binary_acc: 0.8735 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2180  | total loss: \u001b[1m\u001b[32m0.42745\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2180 | loss: 0.42745 - binary_acc: 0.8861 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2181  | total loss: \u001b[1m\u001b[32m0.41609\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2181 | loss: 0.41609 - binary_acc: 0.8975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2182  | total loss: \u001b[1m\u001b[32m0.40586\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2182 | loss: 0.40586 - binary_acc: 0.9078 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2183  | total loss: \u001b[1m\u001b[32m0.39665\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2183 | loss: 0.39665 - binary_acc: 0.9170 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2184  | total loss: \u001b[1m\u001b[32m0.38837\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2184 | loss: 0.38837 - binary_acc: 0.9253 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2185  | total loss: \u001b[1m\u001b[32m0.38091\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2185 | loss: 0.38091 - binary_acc: 0.9328 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2186  | total loss: \u001b[1m\u001b[32m0.37420\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2186 | loss: 0.37420 - binary_acc: 0.9395 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2187  | total loss: \u001b[1m\u001b[32m0.36816\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2187 | loss: 0.36816 - binary_acc: 0.9455 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2188  | total loss: \u001b[1m\u001b[32m0.36272\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2188 | loss: 0.36272 - binary_acc: 0.9510 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2189  | total loss: \u001b[1m\u001b[32m0.35783\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2189 | loss: 0.35783 - binary_acc: 0.9559 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2190  | total loss: \u001b[1m\u001b[32m0.35343\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2190 | loss: 0.35343 - binary_acc: 0.9603 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2191  | total loss: \u001b[1m\u001b[32m0.34946\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2191 | loss: 0.34946 - binary_acc: 0.9643 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2192  | total loss: \u001b[1m\u001b[32m0.34589\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2192 | loss: 0.34589 - binary_acc: 0.9678 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2193  | total loss: \u001b[1m\u001b[32m0.34268\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2193 | loss: 0.34268 - binary_acc: 0.9711 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2194  | total loss: \u001b[1m\u001b[32m0.38970\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2194 | loss: 0.38970 - binary_acc: 0.9240 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2195  | total loss: \u001b[1m\u001b[32m0.38211\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2195 | loss: 0.38211 - binary_acc: 0.9316 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2196  | total loss: \u001b[1m\u001b[32m0.37527\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2196 | loss: 0.37527 - binary_acc: 0.9384 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2197  | total loss: \u001b[1m\u001b[32m0.36912\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2197 | loss: 0.36912 - binary_acc: 0.9446 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2198  | total loss: \u001b[1m\u001b[32m0.36359\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2198 | loss: 0.36359 - binary_acc: 0.9501 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2199  | total loss: \u001b[1m\u001b[32m0.35861\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2199 | loss: 0.35861 - binary_acc: 0.9551 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2200  | total loss: \u001b[1m\u001b[32m0.40403\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2200 | loss: 0.40403 - binary_acc: 0.9096 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2201  | total loss: \u001b[1m\u001b[32m0.39501\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2201 | loss: 0.39501 - binary_acc: 0.9186 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2202  | total loss: \u001b[1m\u001b[32m0.38688\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2202 | loss: 0.38688 - binary_acc: 0.9268 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2203  | total loss: \u001b[1m\u001b[32m0.37957\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2203 | loss: 0.37957 - binary_acc: 0.9341 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2204  | total loss: \u001b[1m\u001b[32m0.37299\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2204 | loss: 0.37299 - binary_acc: 0.9407 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2205  | total loss: \u001b[1m\u001b[32m0.36707\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2205 | loss: 0.36707 - binary_acc: 0.9466 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2206  | total loss: \u001b[1m\u001b[32m0.36174\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2206 | loss: 0.36174 - binary_acc: 0.9519 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2207  | total loss: \u001b[1m\u001b[32m0.35694\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2207 | loss: 0.35694 - binary_acc: 0.9568 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2208  | total loss: \u001b[1m\u001b[32m0.40253\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2208 | loss: 0.40253 - binary_acc: 0.9111 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2209  | total loss: \u001b[1m\u001b[32m0.39365\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2209 | loss: 0.39365 - binary_acc: 0.9200 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2210  | total loss: \u001b[1m\u001b[32m0.38567\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2210 | loss: 0.38567 - binary_acc: 0.9280 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2211  | total loss: \u001b[1m\u001b[32m0.37848\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2211 | loss: 0.37848 - binary_acc: 0.9352 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2212  | total loss: \u001b[1m\u001b[32m0.37200\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2212 | loss: 0.37200 - binary_acc: 0.9417 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2213  | total loss: \u001b[1m\u001b[32m0.36618\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2213 | loss: 0.36618 - binary_acc: 0.9475 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2214  | total loss: \u001b[1m\u001b[32m0.36094\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2214 | loss: 0.36094 - binary_acc: 0.9527 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2215  | total loss: \u001b[1m\u001b[32m0.35622\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2215 | loss: 0.35622 - binary_acc: 0.9575 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2216  | total loss: \u001b[1m\u001b[32m0.35197\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2216 | loss: 0.35197 - binary_acc: 0.9617 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2217  | total loss: \u001b[1m\u001b[32m0.34815\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2217 | loss: 0.34815 - binary_acc: 0.9656 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2218  | total loss: \u001b[1m\u001b[32m0.34471\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2218 | loss: 0.34471 - binary_acc: 0.9690 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2219  | total loss: \u001b[1m\u001b[32m0.34162\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2219 | loss: 0.34162 - binary_acc: 0.9721 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2220  | total loss: \u001b[1m\u001b[32m0.33883\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2220 | loss: 0.33883 - binary_acc: 0.9749 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2221  | total loss: \u001b[1m\u001b[32m0.33632\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2221 | loss: 0.33632 - binary_acc: 0.9774 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2222  | total loss: \u001b[1m\u001b[32m0.33406\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2222 | loss: 0.33406 - binary_acc: 0.9797 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2223  | total loss: \u001b[1m\u001b[32m0.33203\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2223 | loss: 0.33203 - binary_acc: 0.9817 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2224  | total loss: \u001b[1m\u001b[32m0.33020\u001b[0m\u001b[0m | time: 0.002s\n",
            "| SGD | epoch: 2224 | loss: 0.33020 - binary_acc: 0.9835 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2225  | total loss: \u001b[1m\u001b[32m0.32856\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2225 | loss: 0.32856 - binary_acc: 0.9852 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2226  | total loss: \u001b[1m\u001b[32m0.32708\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2226 | loss: 0.32708 - binary_acc: 0.9867 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2227  | total loss: \u001b[1m\u001b[32m0.32574\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2227 | loss: 0.32574 - binary_acc: 0.9880 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2228  | total loss: \u001b[1m\u001b[32m0.32454\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2228 | loss: 0.32454 - binary_acc: 0.9892 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2229  | total loss: \u001b[1m\u001b[32m0.32346\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2229 | loss: 0.32346 - binary_acc: 0.9903 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2230  | total loss: \u001b[1m\u001b[32m0.32249\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2230 | loss: 0.32249 - binary_acc: 0.9912 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2231  | total loss: \u001b[1m\u001b[32m0.32161\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2231 | loss: 0.32161 - binary_acc: 0.9921 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2232  | total loss: \u001b[1m\u001b[32m0.32083\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2232 | loss: 0.32083 - binary_acc: 0.9929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2233  | total loss: \u001b[1m\u001b[32m0.32012\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2233 | loss: 0.32012 - binary_acc: 0.9936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2234  | total loss: \u001b[1m\u001b[32m0.31948\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2234 | loss: 0.31948 - binary_acc: 0.9943 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2235  | total loss: \u001b[1m\u001b[32m0.31890\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2235 | loss: 0.31890 - binary_acc: 0.9948 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2236  | total loss: \u001b[1m\u001b[32m0.31839\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2236 | loss: 0.31839 - binary_acc: 0.9953 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2237  | total loss: \u001b[1m\u001b[32m0.31792\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2237 | loss: 0.31792 - binary_acc: 0.9958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2238  | total loss: \u001b[1m\u001b[32m0.31750\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2238 | loss: 0.31750 - binary_acc: 0.9962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2239  | total loss: \u001b[1m\u001b[32m0.31712\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2239 | loss: 0.31712 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2240  | total loss: \u001b[1m\u001b[32m0.31678\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2240 | loss: 0.31678 - binary_acc: 0.9969 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2241  | total loss: \u001b[1m\u001b[32m0.31648\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2241 | loss: 0.31648 - binary_acc: 0.9973 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2242  | total loss: \u001b[1m\u001b[32m0.31620\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2242 | loss: 0.31620 - binary_acc: 0.9975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2243  | total loss: \u001b[1m\u001b[32m0.31595\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2243 | loss: 0.31595 - binary_acc: 0.9978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2244  | total loss: \u001b[1m\u001b[32m0.31573\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2244 | loss: 0.31573 - binary_acc: 0.9980 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2245  | total loss: \u001b[1m\u001b[32m0.31553\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2245 | loss: 0.31553 - binary_acc: 0.9982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2246  | total loss: \u001b[1m\u001b[32m0.31535\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2246 | loss: 0.31535 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2247  | total loss: \u001b[1m\u001b[32m0.31518\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2247 | loss: 0.31518 - binary_acc: 0.9985 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2248  | total loss: \u001b[1m\u001b[32m0.31504\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2248 | loss: 0.31504 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2249  | total loss: \u001b[1m\u001b[32m0.31490\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2249 | loss: 0.31490 - binary_acc: 0.9988 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2250  | total loss: \u001b[1m\u001b[32m0.31479\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2250 | loss: 0.31479 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2251  | total loss: \u001b[1m\u001b[32m0.31468\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2251 | loss: 0.31468 - binary_acc: 0.9990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2252  | total loss: \u001b[1m\u001b[32m0.31458\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2252 | loss: 0.31458 - binary_acc: 0.9991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2253  | total loss: \u001b[1m\u001b[32m0.31449\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2253 | loss: 0.31449 - binary_acc: 0.9992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2254  | total loss: \u001b[1m\u001b[32m0.31441\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2254 | loss: 0.31441 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2255  | total loss: \u001b[1m\u001b[32m0.31434\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2255 | loss: 0.31434 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2256  | total loss: \u001b[1m\u001b[32m0.31428\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2256 | loss: 0.31428 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2257  | total loss: \u001b[1m\u001b[32m0.31422\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2257 | loss: 0.31422 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2258  | total loss: \u001b[1m\u001b[32m0.31417\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2258 | loss: 0.31417 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2259  | total loss: \u001b[1m\u001b[32m0.31412\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2259 | loss: 0.31412 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2260  | total loss: \u001b[1m\u001b[32m0.31408\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2260 | loss: 0.31408 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2261  | total loss: \u001b[1m\u001b[32m0.31404\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2261 | loss: 0.31404 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2262  | total loss: \u001b[1m\u001b[32m0.31401\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2262 | loss: 0.31401 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2263  | total loss: \u001b[1m\u001b[32m0.31398\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2263 | loss: 0.31398 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2264  | total loss: \u001b[1m\u001b[32m0.31395\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2264 | loss: 0.31395 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2265  | total loss: \u001b[1m\u001b[32m0.31392\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2265 | loss: 0.31392 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2266  | total loss: \u001b[1m\u001b[32m0.31390\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2266 | loss: 0.31390 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2267  | total loss: \u001b[1m\u001b[32m0.31388\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2267 | loss: 0.31388 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2268  | total loss: \u001b[1m\u001b[32m0.31386\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2268 | loss: 0.31386 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2269  | total loss: \u001b[1m\u001b[32m0.31384\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2269 | loss: 0.31384 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2270  | total loss: \u001b[1m\u001b[32m0.31383\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2270 | loss: 0.31383 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2271  | total loss: \u001b[1m\u001b[32m0.31381\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2271 | loss: 0.31381 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2272  | total loss: \u001b[1m\u001b[32m0.31380\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2272 | loss: 0.31380 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2273  | total loss: \u001b[1m\u001b[32m0.31379\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2273 | loss: 0.31379 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2274  | total loss: \u001b[1m\u001b[32m0.31378\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2274 | loss: 0.31378 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2275  | total loss: \u001b[1m\u001b[32m0.31377\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2275 | loss: 0.31377 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2276  | total loss: \u001b[1m\u001b[32m0.31376\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2276 | loss: 0.31376 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2277  | total loss: \u001b[1m\u001b[32m0.31375\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2277 | loss: 0.31375 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2278  | total loss: \u001b[1m\u001b[32m0.31374\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2278 | loss: 0.31374 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2279  | total loss: \u001b[1m\u001b[32m0.31374\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2279 | loss: 0.31374 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2280  | total loss: \u001b[1m\u001b[32m0.31373\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2280 | loss: 0.31373 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2281  | total loss: \u001b[1m\u001b[32m0.31373\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2281 | loss: 0.31373 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2282  | total loss: \u001b[1m\u001b[32m0.31372\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2282 | loss: 0.31372 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2283  | total loss: \u001b[1m\u001b[32m0.31372\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2283 | loss: 0.31372 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2284  | total loss: \u001b[1m\u001b[32m0.36364\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2284 | loss: 0.36364 - binary_acc: 0.9500 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2285  | total loss: \u001b[1m\u001b[32m0.35864\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2285 | loss: 0.35864 - binary_acc: 0.9550 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2286  | total loss: \u001b[1m\u001b[32m0.35414\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2286 | loss: 0.35414 - binary_acc: 0.9595 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2287  | total loss: \u001b[1m\u001b[32m0.35010\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2287 | loss: 0.35010 - binary_acc: 0.9635 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2288  | total loss: \u001b[1m\u001b[32m0.34645\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2288 | loss: 0.34645 - binary_acc: 0.9672 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2289  | total loss: \u001b[1m\u001b[32m0.34318\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2289 | loss: 0.34318 - binary_acc: 0.9705 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2290  | total loss: \u001b[1m\u001b[32m0.34023\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2290 | loss: 0.34023 - binary_acc: 0.9734 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2291  | total loss: \u001b[1m\u001b[32m0.33757\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2291 | loss: 0.33757 - binary_acc: 0.9761 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2292  | total loss: \u001b[1m\u001b[32m0.33518\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2292 | loss: 0.33518 - binary_acc: 0.9785 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2293  | total loss: \u001b[1m\u001b[32m0.33303\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2293 | loss: 0.33303 - binary_acc: 0.9806 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2294  | total loss: \u001b[1m\u001b[32m0.33109\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2294 | loss: 0.33109 - binary_acc: 0.9826 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2295  | total loss: \u001b[1m\u001b[32m0.32935\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2295 | loss: 0.32935 - binary_acc: 0.9843 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2296  | total loss: \u001b[1m\u001b[32m0.37770\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2296 | loss: 0.37770 - binary_acc: 0.9359 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2297  | total loss: \u001b[1m\u001b[32m0.37130\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2297 | loss: 0.37130 - binary_acc: 0.9423 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2298  | total loss: \u001b[1m\u001b[32m0.36554\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2298 | loss: 0.36554 - binary_acc: 0.9481 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2299  | total loss: \u001b[1m\u001b[32m0.36035\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2299 | loss: 0.36035 - binary_acc: 0.9532 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2300  | total loss: \u001b[1m\u001b[32m0.35568\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2300 | loss: 0.35568 - binary_acc: 0.9579 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2301  | total loss: \u001b[1m\u001b[32m0.35148\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2301 | loss: 0.35148 - binary_acc: 0.9621 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2302  | total loss: \u001b[1m\u001b[32m0.34770\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2302 | loss: 0.34770 - binary_acc: 0.9659 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2303  | total loss: \u001b[1m\u001b[32m0.34429\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2303 | loss: 0.34429 - binary_acc: 0.9693 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2304  | total loss: \u001b[1m\u001b[32m0.34123\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2304 | loss: 0.34123 - binary_acc: 0.9724 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2305  | total loss: \u001b[1m\u001b[32m0.33847\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2305 | loss: 0.33847 - binary_acc: 0.9752 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2306  | total loss: \u001b[1m\u001b[32m0.33599\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2306 | loss: 0.33599 - binary_acc: 0.9776 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2307  | total loss: \u001b[1m\u001b[32m0.33376\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2307 | loss: 0.33376 - binary_acc: 0.9799 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2308  | total loss: \u001b[1m\u001b[32m0.33175\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2308 | loss: 0.33175 - binary_acc: 0.9819 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2309  | total loss: \u001b[1m\u001b[32m0.32994\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2309 | loss: 0.32994 - binary_acc: 0.9837 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2310  | total loss: \u001b[1m\u001b[32m0.32831\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2310 | loss: 0.32831 - binary_acc: 0.9853 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2311  | total loss: \u001b[1m\u001b[32m0.32684\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2311 | loss: 0.32684 - binary_acc: 0.9868 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2312  | total loss: \u001b[1m\u001b[32m0.32552\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2312 | loss: 0.32552 - binary_acc: 0.9881 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2313  | total loss: \u001b[1m\u001b[32m0.32434\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2313 | loss: 0.32434 - binary_acc: 0.9893 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2314  | total loss: \u001b[1m\u001b[32m0.32327\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2314 | loss: 0.32327 - binary_acc: 0.9904 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2315  | total loss: \u001b[1m\u001b[32m0.32230\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2315 | loss: 0.32230 - binary_acc: 0.9913 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2316  | total loss: \u001b[1m\u001b[32m0.32144\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2316 | loss: 0.32144 - binary_acc: 0.9922 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2317  | total loss: \u001b[1m\u001b[32m0.32066\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2317 | loss: 0.32066 - binary_acc: 0.9930 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2318  | total loss: \u001b[1m\u001b[32m0.31996\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2318 | loss: 0.31996 - binary_acc: 0.9937 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2319  | total loss: \u001b[1m\u001b[32m0.31933\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2319 | loss: 0.31933 - binary_acc: 0.9943 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2320  | total loss: \u001b[1m\u001b[32m0.31876\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2320 | loss: 0.31876 - binary_acc: 0.9949 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2321  | total loss: \u001b[1m\u001b[32m0.31825\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2321 | loss: 0.31825 - binary_acc: 0.9954 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2322  | total loss: \u001b[1m\u001b[32m0.31779\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2322 | loss: 0.31779 - binary_acc: 0.9959 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2323  | total loss: \u001b[1m\u001b[32m0.31737\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2323 | loss: 0.31737 - binary_acc: 0.9963 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2324  | total loss: \u001b[1m\u001b[32m0.31700\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2324 | loss: 0.31700 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2325  | total loss: \u001b[1m\u001b[32m0.31666\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2325 | loss: 0.31666 - binary_acc: 0.9970 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2326  | total loss: \u001b[1m\u001b[32m0.31636\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2326 | loss: 0.31636 - binary_acc: 0.9973 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2327  | total loss: \u001b[1m\u001b[32m0.31609\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2327 | loss: 0.31609 - binary_acc: 0.9976 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2328  | total loss: \u001b[1m\u001b[32m0.31584\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2328 | loss: 0.31584 - binary_acc: 0.9978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2329  | total loss: \u001b[1m\u001b[32m0.31562\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2329 | loss: 0.31562 - binary_acc: 0.9980 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2330  | total loss: \u001b[1m\u001b[32m0.31542\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2330 | loss: 0.31542 - binary_acc: 0.9982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2331  | total loss: \u001b[1m\u001b[32m0.31524\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2331 | loss: 0.31524 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2332  | total loss: \u001b[1m\u001b[32m0.31508\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2332 | loss: 0.31508 - binary_acc: 0.9986 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2333  | total loss: \u001b[1m\u001b[32m0.31494\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2333 | loss: 0.31494 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2334  | total loss: \u001b[1m\u001b[32m0.36474\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2334 | loss: 0.36474 - binary_acc: 0.9488 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2335  | total loss: \u001b[1m\u001b[32m0.35962\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2335 | loss: 0.35962 - binary_acc: 0.9539 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2336  | total loss: \u001b[1m\u001b[32m0.35503\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2336 | loss: 0.35503 - binary_acc: 0.9586 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2337  | total loss: \u001b[1m\u001b[32m0.35089\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2337 | loss: 0.35089 - binary_acc: 0.9627 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2338  | total loss: \u001b[1m\u001b[32m0.34716\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2338 | loss: 0.34716 - binary_acc: 0.9664 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2339  | total loss: \u001b[1m\u001b[32m0.34381\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2339 | loss: 0.34381 - binary_acc: 0.9698 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2340  | total loss: \u001b[1m\u001b[32m0.34079\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2340 | loss: 0.34079 - binary_acc: 0.9728 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2341  | total loss: \u001b[1m\u001b[32m0.33807\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2341 | loss: 0.33807 - binary_acc: 0.9755 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2342  | total loss: \u001b[1m\u001b[32m0.33563\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2342 | loss: 0.33563 - binary_acc: 0.9780 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2343  | total loss: \u001b[1m\u001b[32m0.33343\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2343 | loss: 0.33343 - binary_acc: 0.9802 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2344  | total loss: \u001b[1m\u001b[32m0.33145\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2344 | loss: 0.33145 - binary_acc: 0.9822 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2345  | total loss: \u001b[1m\u001b[32m0.32966\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2345 | loss: 0.32966 - binary_acc: 0.9839 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2346  | total loss: \u001b[1m\u001b[32m0.32806\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2346 | loss: 0.32806 - binary_acc: 0.9855 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2347  | total loss: \u001b[1m\u001b[32m0.32662\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2347 | loss: 0.32662 - binary_acc: 0.9870 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2348  | total loss: \u001b[1m\u001b[32m0.32532\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2348 | loss: 0.32532 - binary_acc: 0.9883 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2349  | total loss: \u001b[1m\u001b[32m0.32415\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2349 | loss: 0.32415 - binary_acc: 0.9895 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2350  | total loss: \u001b[1m\u001b[32m0.32309\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2350 | loss: 0.32309 - binary_acc: 0.9905 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2351  | total loss: \u001b[1m\u001b[32m0.32215\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2351 | loss: 0.32215 - binary_acc: 0.9915 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2352  | total loss: \u001b[1m\u001b[32m0.32129\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2352 | loss: 0.32129 - binary_acc: 0.9923 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2353  | total loss: \u001b[1m\u001b[32m0.32053\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2353 | loss: 0.32053 - binary_acc: 0.9931 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2354  | total loss: \u001b[1m\u001b[32m0.31984\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2354 | loss: 0.31984 - binary_acc: 0.9938 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2355  | total loss: \u001b[1m\u001b[32m0.31921\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2355 | loss: 0.31921 - binary_acc: 0.9944 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2356  | total loss: \u001b[1m\u001b[32m0.31865\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2356 | loss: 0.31865 - binary_acc: 0.9950 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2357  | total loss: \u001b[1m\u001b[32m0.31815\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2357 | loss: 0.31815 - binary_acc: 0.9955 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2358  | total loss: \u001b[1m\u001b[32m0.31770\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2358 | loss: 0.31770 - binary_acc: 0.9959 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2359  | total loss: \u001b[1m\u001b[32m0.31729\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2359 | loss: 0.31729 - binary_acc: 0.9963 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2360  | total loss: \u001b[1m\u001b[32m0.36685\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2360 | loss: 0.36685 - binary_acc: 0.9467 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2361  | total loss: \u001b[1m\u001b[32m0.36153\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2361 | loss: 0.36153 - binary_acc: 0.9520 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2362  | total loss: \u001b[1m\u001b[32m0.35674\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2362 | loss: 0.35674 - binary_acc: 0.9568 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2363  | total loss: \u001b[1m\u001b[32m0.35242\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2363 | loss: 0.35242 - binary_acc: 0.9611 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2364  | total loss: \u001b[1m\u001b[32m0.34854\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2364 | loss: 0.34854 - binary_acc: 0.9650 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2365  | total loss: \u001b[1m\u001b[32m0.34505\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2365 | loss: 0.34505 - binary_acc: 0.9685 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2366  | total loss: \u001b[1m\u001b[32m0.34191\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2366 | loss: 0.34191 - binary_acc: 0.9717 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2367  | total loss: \u001b[1m\u001b[32m0.33908\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2367 | loss: 0.33908 - binary_acc: 0.9745 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2368  | total loss: \u001b[1m\u001b[32m0.33653\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2368 | loss: 0.33653 - binary_acc: 0.9771 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2369  | total loss: \u001b[1m\u001b[32m0.33424\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2369 | loss: 0.33424 - binary_acc: 0.9793 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2370  | total loss: \u001b[1m\u001b[32m0.38211\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2370 | loss: 0.38211 - binary_acc: 0.9314 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2371  | total loss: \u001b[1m\u001b[32m0.37526\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2371 | loss: 0.37526 - binary_acc: 0.9383 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2372  | total loss: \u001b[1m\u001b[32m0.36910\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2372 | loss: 0.36910 - binary_acc: 0.9444 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2373  | total loss: \u001b[1m\u001b[32m0.36355\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2373 | loss: 0.36355 - binary_acc: 0.9500 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2374  | total loss: \u001b[1m\u001b[32m0.40849\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2374 | loss: 0.40849 - binary_acc: 0.9050 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2375  | total loss: \u001b[1m\u001b[32m0.39900\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2375 | loss: 0.39900 - binary_acc: 0.9145 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2376  | total loss: \u001b[1m\u001b[32m0.39046\u001b[0m\u001b[0m | time: 0.009s\n",
            "| SGD | epoch: 2376 | loss: 0.39046 - binary_acc: 0.9231 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2377  | total loss: \u001b[1m\u001b[32m0.38278\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2377 | loss: 0.38278 - binary_acc: 0.9307 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2378  | total loss: \u001b[1m\u001b[32m0.37586\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2378 | loss: 0.37586 - binary_acc: 0.9377 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2379  | total loss: \u001b[1m\u001b[32m0.36963\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2379 | loss: 0.36963 - binary_acc: 0.9439 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2380  | total loss: \u001b[1m\u001b[32m0.36403\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2380 | loss: 0.36403 - binary_acc: 0.9495 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2381  | total loss: \u001b[1m\u001b[32m0.35899\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2381 | loss: 0.35899 - binary_acc: 0.9546 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2382  | total loss: \u001b[1m\u001b[32m0.35445\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2382 | loss: 0.35445 - binary_acc: 0.9591 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2383  | total loss: \u001b[1m\u001b[32m0.35036\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2383 | loss: 0.35036 - binary_acc: 0.9632 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2384  | total loss: \u001b[1m\u001b[32m0.34669\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2384 | loss: 0.34669 - binary_acc: 0.9669 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2385  | total loss: \u001b[1m\u001b[32m0.34338\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2385 | loss: 0.34338 - binary_acc: 0.9702 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2386  | total loss: \u001b[1m\u001b[32m0.34040\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2386 | loss: 0.34040 - binary_acc: 0.9732 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2387  | total loss: \u001b[1m\u001b[32m0.33772\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2387 | loss: 0.33772 - binary_acc: 0.9759 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2388  | total loss: \u001b[1m\u001b[32m0.33531\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2388 | loss: 0.33531 - binary_acc: 0.9783 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2389  | total loss: \u001b[1m\u001b[32m0.33314\u001b[0m\u001b[0m | time: 0.008s\n",
            "| SGD | epoch: 2389 | loss: 0.33314 - binary_acc: 0.9804 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2390  | total loss: \u001b[1m\u001b[32m0.33118\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2390 | loss: 0.33118 - binary_acc: 0.9824 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2391  | total loss: \u001b[1m\u001b[32m0.32942\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2391 | loss: 0.32942 - binary_acc: 0.9842 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2392  | total loss: \u001b[1m\u001b[32m0.32784\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2392 | loss: 0.32784 - binary_acc: 0.9857 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2393  | total loss: \u001b[1m\u001b[32m0.32641\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2393 | loss: 0.32641 - binary_acc: 0.9872 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2394  | total loss: \u001b[1m\u001b[32m0.32513\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2394 | loss: 0.32513 - binary_acc: 0.9885 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2395  | total loss: \u001b[1m\u001b[32m0.32398\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2395 | loss: 0.32398 - binary_acc: 0.9896 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2396  | total loss: \u001b[1m\u001b[32m0.37288\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2396 | loss: 0.37288 - binary_acc: 0.9406 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2397  | total loss: \u001b[1m\u001b[32m0.36695\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2397 | loss: 0.36695 - binary_acc: 0.9466 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2398  | total loss: \u001b[1m\u001b[32m0.36162\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2398 | loss: 0.36162 - binary_acc: 0.9519 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2399  | total loss: \u001b[1m\u001b[32m0.35681\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2399 | loss: 0.35681 - binary_acc: 0.9567 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2400  | total loss: \u001b[1m\u001b[32m0.35249\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2400 | loss: 0.35249 - binary_acc: 0.9611 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2401  | total loss: \u001b[1m\u001b[32m0.34860\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2401 | loss: 0.34860 - binary_acc: 0.9650 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2402  | total loss: \u001b[1m\u001b[32m0.34510\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2402 | loss: 0.34510 - binary_acc: 0.9685 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2403  | total loss: \u001b[1m\u001b[32m0.34195\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2403 | loss: 0.34195 - binary_acc: 0.9716 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2404  | total loss: \u001b[1m\u001b[32m0.38905\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2404 | loss: 0.38905 - binary_acc: 0.9244 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2405  | total loss: \u001b[1m\u001b[32m0.38151\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2405 | loss: 0.38151 - binary_acc: 0.9320 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2406  | total loss: \u001b[1m\u001b[32m0.37471\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2406 | loss: 0.37471 - binary_acc: 0.9388 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2407  | total loss: \u001b[1m\u001b[32m0.36860\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2407 | loss: 0.36860 - binary_acc: 0.9449 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2408  | total loss: \u001b[1m\u001b[32m0.36310\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2408 | loss: 0.36310 - binary_acc: 0.9504 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2409  | total loss: \u001b[1m\u001b[32m0.35815\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2409 | loss: 0.35815 - binary_acc: 0.9554 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2410  | total loss: \u001b[1m\u001b[32m0.35369\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2410 | loss: 0.35369 - binary_acc: 0.9598 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2411  | total loss: \u001b[1m\u001b[32m0.34968\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2411 | loss: 0.34968 - binary_acc: 0.9639 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2412  | total loss: \u001b[1m\u001b[32m0.34607\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2412 | loss: 0.34607 - binary_acc: 0.9675 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2413  | total loss: \u001b[1m\u001b[32m0.34282\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2413 | loss: 0.34282 - binary_acc: 0.9707 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2414  | total loss: \u001b[1m\u001b[32m0.33990\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2414 | loss: 0.33990 - binary_acc: 0.9737 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2415  | total loss: \u001b[1m\u001b[32m0.33727\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2415 | loss: 0.33727 - binary_acc: 0.9763 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2416  | total loss: \u001b[1m\u001b[32m0.33490\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2416 | loss: 0.33490 - binary_acc: 0.9787 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2417  | total loss: \u001b[1m\u001b[32m0.33277\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2417 | loss: 0.33277 - binary_acc: 0.9808 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2418  | total loss: \u001b[1m\u001b[32m0.33085\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2418 | loss: 0.33085 - binary_acc: 0.9827 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2419  | total loss: \u001b[1m\u001b[32m0.32912\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2419 | loss: 0.32912 - binary_acc: 0.9844 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2420  | total loss: \u001b[1m\u001b[32m0.32757\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2420 | loss: 0.32757 - binary_acc: 0.9860 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2421  | total loss: \u001b[1m\u001b[32m0.32617\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2421 | loss: 0.32617 - binary_acc: 0.9874 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2422  | total loss: \u001b[1m\u001b[32m0.32491\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2422 | loss: 0.32491 - binary_acc: 0.9887 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2423  | total loss: \u001b[1m\u001b[32m0.32377\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2423 | loss: 0.32377 - binary_acc: 0.9898 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2424  | total loss: \u001b[1m\u001b[32m0.32275\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2424 | loss: 0.32275 - binary_acc: 0.9908 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2425  | total loss: \u001b[1m\u001b[32m0.32184\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2425 | loss: 0.32184 - binary_acc: 0.9917 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2426  | total loss: \u001b[1m\u001b[32m0.32101\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2426 | loss: 0.32101 - binary_acc: 0.9926 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2427  | total loss: \u001b[1m\u001b[32m0.32027\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2427 | loss: 0.32027 - binary_acc: 0.9933 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2428  | total loss: \u001b[1m\u001b[32m0.31960\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2428 | loss: 0.31960 - binary_acc: 0.9940 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2429  | total loss: \u001b[1m\u001b[32m0.31899\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2429 | loss: 0.31899 - binary_acc: 0.9946 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2430  | total loss: \u001b[1m\u001b[32m0.31845\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2430 | loss: 0.31845 - binary_acc: 0.9951 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2431  | total loss: \u001b[1m\u001b[32m0.31796\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2431 | loss: 0.31796 - binary_acc: 0.9956 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2432  | total loss: \u001b[1m\u001b[32m0.31752\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2432 | loss: 0.31752 - binary_acc: 0.9960 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2433  | total loss: \u001b[1m\u001b[32m0.31713\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2433 | loss: 0.31713 - binary_acc: 0.9964 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2434  | total loss: \u001b[1m\u001b[32m0.31677\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2434 | loss: 0.31677 - binary_acc: 0.9968 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2435  | total loss: \u001b[1m\u001b[32m0.31645\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2435 | loss: 0.31645 - binary_acc: 0.9971 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2436  | total loss: \u001b[1m\u001b[32m0.31616\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2436 | loss: 0.31616 - binary_acc: 0.9974 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2437  | total loss: \u001b[1m\u001b[32m0.31590\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2437 | loss: 0.31590 - binary_acc: 0.9977 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2438  | total loss: \u001b[1m\u001b[32m0.31567\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2438 | loss: 0.31567 - binary_acc: 0.9979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2439  | total loss: \u001b[1m\u001b[32m0.31546\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2439 | loss: 0.31546 - binary_acc: 0.9981 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2440  | total loss: \u001b[1m\u001b[32m0.31527\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2440 | loss: 0.31527 - binary_acc: 0.9983 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2441  | total loss: \u001b[1m\u001b[32m0.31510\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2441 | loss: 0.31510 - binary_acc: 0.9985 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2442  | total loss: \u001b[1m\u001b[32m0.31495\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2442 | loss: 0.31495 - binary_acc: 0.9986 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2443  | total loss: \u001b[1m\u001b[32m0.31481\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2443 | loss: 0.31481 - binary_acc: 0.9988 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2444  | total loss: \u001b[1m\u001b[32m0.31468\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2444 | loss: 0.31468 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2445  | total loss: \u001b[1m\u001b[32m0.31457\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2445 | loss: 0.31457 - binary_acc: 0.9990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2446  | total loss: \u001b[1m\u001b[32m0.36441\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2446 | loss: 0.36441 - binary_acc: 0.9491 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2447  | total loss: \u001b[1m\u001b[32m0.35933\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2447 | loss: 0.35933 - binary_acc: 0.9542 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2448  | total loss: \u001b[1m\u001b[32m0.35475\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2448 | loss: 0.35475 - binary_acc: 0.9588 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2449  | total loss: \u001b[1m\u001b[32m0.35063\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2449 | loss: 0.35063 - binary_acc: 0.9629 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2450  | total loss: \u001b[1m\u001b[32m0.34693\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2450 | loss: 0.34693 - binary_acc: 0.9666 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2451  | total loss: \u001b[1m\u001b[32m0.34359\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2451 | loss: 0.34359 - binary_acc: 0.9699 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2452  | total loss: \u001b[1m\u001b[32m0.34059\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2452 | loss: 0.34059 - binary_acc: 0.9729 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2453  | total loss: \u001b[1m\u001b[32m0.33788\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2453 | loss: 0.33788 - binary_acc: 0.9757 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2454  | total loss: \u001b[1m\u001b[32m0.38539\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2454 | loss: 0.38539 - binary_acc: 0.9281 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2455  | total loss: \u001b[1m\u001b[32m0.37821\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2455 | loss: 0.37821 - binary_acc: 0.9353 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2456  | total loss: \u001b[1m\u001b[32m0.37175\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2456 | loss: 0.37175 - binary_acc: 0.9418 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2457  | total loss: \u001b[1m\u001b[32m0.36593\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2457 | loss: 0.36593 - binary_acc: 0.9476 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2458  | total loss: \u001b[1m\u001b[32m0.36069\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2458 | loss: 0.36069 - binary_acc: 0.9528 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2459  | total loss: \u001b[1m\u001b[32m0.35598\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2459 | loss: 0.35598 - binary_acc: 0.9575 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2460  | total loss: \u001b[1m\u001b[32m0.35173\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2460 | loss: 0.35173 - binary_acc: 0.9618 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2461  | total loss: \u001b[1m\u001b[32m0.34792\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2461 | loss: 0.34792 - binary_acc: 0.9656 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2462  | total loss: \u001b[1m\u001b[32m0.34448\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2462 | loss: 0.34448 - binary_acc: 0.9690 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2463  | total loss: \u001b[1m\u001b[32m0.34139\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2463 | loss: 0.34139 - binary_acc: 0.9721 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2464  | total loss: \u001b[1m\u001b[32m0.38855\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2464 | loss: 0.38855 - binary_acc: 0.9249 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2465  | total loss: \u001b[1m\u001b[32m0.38105\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2465 | loss: 0.38105 - binary_acc: 0.9324 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2466  | total loss: \u001b[1m\u001b[32m0.37430\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2466 | loss: 0.37430 - binary_acc: 0.9392 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2467  | total loss: \u001b[1m\u001b[32m0.36823\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2467 | loss: 0.36823 - binary_acc: 0.9453 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2468  | total loss: \u001b[1m\u001b[32m0.36276\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2468 | loss: 0.36276 - binary_acc: 0.9507 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2469  | total loss: \u001b[1m\u001b[32m0.35784\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2469 | loss: 0.35784 - binary_acc: 0.9557 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2470  | total loss: \u001b[1m\u001b[32m0.35341\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2470 | loss: 0.35341 - binary_acc: 0.9601 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2471  | total loss: \u001b[1m\u001b[32m0.34942\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2471 | loss: 0.34942 - binary_acc: 0.9641 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2472  | total loss: \u001b[1m\u001b[32m0.34584\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2472 | loss: 0.34584 - binary_acc: 0.9677 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2473  | total loss: \u001b[1m\u001b[32m0.34261\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2473 | loss: 0.34261 - binary_acc: 0.9709 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2474  | total loss: \u001b[1m\u001b[32m0.33970\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2474 | loss: 0.33970 - binary_acc: 0.9738 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2475  | total loss: \u001b[1m\u001b[32m0.33709\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2475 | loss: 0.33709 - binary_acc: 0.9764 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2476  | total loss: \u001b[1m\u001b[32m0.38468\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2476 | loss: 0.38468 - binary_acc: 0.9288 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2477  | total loss: \u001b[1m\u001b[32m0.37757\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2477 | loss: 0.37757 - binary_acc: 0.9359 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2478  | total loss: \u001b[1m\u001b[32m0.37117\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2478 | loss: 0.37117 - binary_acc: 0.9423 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2479  | total loss: \u001b[1m\u001b[32m0.36540\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2479 | loss: 0.36540 - binary_acc: 0.9481 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2480  | total loss: \u001b[1m\u001b[32m0.36022\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2480 | loss: 0.36022 - binary_acc: 0.9533 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2481  | total loss: \u001b[1m\u001b[32m0.35555\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2481 | loss: 0.35555 - binary_acc: 0.9580 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2482  | total loss: \u001b[1m\u001b[32m0.35135\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2482 | loss: 0.35135 - binary_acc: 0.9622 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2483  | total loss: \u001b[1m\u001b[32m0.34757\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2483 | loss: 0.34757 - binary_acc: 0.9659 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2484  | total loss: \u001b[1m\u001b[32m0.34417\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2484 | loss: 0.34417 - binary_acc: 0.9693 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2485  | total loss: \u001b[1m\u001b[32m0.34111\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2485 | loss: 0.34111 - binary_acc: 0.9724 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2486  | total loss: \u001b[1m\u001b[32m0.33835\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2486 | loss: 0.33835 - binary_acc: 0.9752 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2487  | total loss: \u001b[1m\u001b[32m0.33587\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2487 | loss: 0.33587 - binary_acc: 0.9777 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2488  | total loss: \u001b[1m\u001b[32m0.33364\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2488 | loss: 0.33364 - binary_acc: 0.9799 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2489  | total loss: \u001b[1m\u001b[32m0.33163\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2489 | loss: 0.33163 - binary_acc: 0.9819 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2490  | total loss: \u001b[1m\u001b[32m0.32982\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2490 | loss: 0.32982 - binary_acc: 0.9837 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2491  | total loss: \u001b[1m\u001b[32m0.32819\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2491 | loss: 0.32819 - binary_acc: 0.9853 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2492  | total loss: \u001b[1m\u001b[32m0.37668\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2492 | loss: 0.37668 - binary_acc: 0.9368 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2493  | total loss: \u001b[1m\u001b[32m0.37036\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2493 | loss: 0.37036 - binary_acc: 0.9431 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2494  | total loss: \u001b[1m\u001b[32m0.41463\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2494 | loss: 0.41463 - binary_acc: 0.8988 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2495  | total loss: \u001b[1m\u001b[32m0.40452\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2495 | loss: 0.40452 - binary_acc: 0.9089 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2496  | total loss: \u001b[1m\u001b[32m0.39542\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2496 | loss: 0.39542 - binary_acc: 0.9180 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2497  | total loss: \u001b[1m\u001b[32m0.38723\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2497 | loss: 0.38723 - binary_acc: 0.9262 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2498  | total loss: \u001b[1m\u001b[32m0.37986\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2498 | loss: 0.37986 - binary_acc: 0.9336 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2499  | total loss: \u001b[1m\u001b[32m0.37323\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2499 | loss: 0.37323 - binary_acc: 0.9403 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2500  | total loss: \u001b[1m\u001b[32m0.36726\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2500 | loss: 0.36726 - binary_acc: 0.9462 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2501  | total loss: \u001b[1m\u001b[32m0.36189\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2501 | loss: 0.36189 - binary_acc: 0.9516 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2502  | total loss: \u001b[1m\u001b[32m0.35706\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2502 | loss: 0.35706 - binary_acc: 0.9564 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2503  | total loss: \u001b[1m\u001b[32m0.35270\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2503 | loss: 0.35270 - binary_acc: 0.9608 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2504  | total loss: \u001b[1m\u001b[32m0.34879\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2504 | loss: 0.34879 - binary_acc: 0.9647 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2505  | total loss: \u001b[1m\u001b[32m0.34526\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2505 | loss: 0.34526 - binary_acc: 0.9682 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2506  | total loss: \u001b[1m\u001b[32m0.34209\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2506 | loss: 0.34209 - binary_acc: 0.9714 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2507  | total loss: \u001b[1m\u001b[32m0.33923\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2507 | loss: 0.33923 - binary_acc: 0.9743 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2508  | total loss: \u001b[1m\u001b[32m0.33666\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2508 | loss: 0.33666 - binary_acc: 0.9769 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2509  | total loss: \u001b[1m\u001b[32m0.33435\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2509 | loss: 0.33435 - binary_acc: 0.9792 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2510  | total loss: \u001b[1m\u001b[32m0.33227\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2510 | loss: 0.33227 - binary_acc: 0.9812 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2511  | total loss: \u001b[1m\u001b[32m0.33040\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2511 | loss: 0.33040 - binary_acc: 0.9831 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2512  | total loss: \u001b[1m\u001b[32m0.32871\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2512 | loss: 0.32871 - binary_acc: 0.9848 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2513  | total loss: \u001b[1m\u001b[32m0.32719\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2513 | loss: 0.32719 - binary_acc: 0.9863 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2514  | total loss: \u001b[1m\u001b[32m0.32583\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2514 | loss: 0.32583 - binary_acc: 0.9877 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2515  | total loss: \u001b[1m\u001b[32m0.32460\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2515 | loss: 0.32460 - binary_acc: 0.9889 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2516  | total loss: \u001b[1m\u001b[32m0.32349\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2516 | loss: 0.32349 - binary_acc: 0.9900 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2517  | total loss: \u001b[1m\u001b[32m0.32250\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2517 | loss: 0.32250 - binary_acc: 0.9910 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2518  | total loss: \u001b[1m\u001b[32m0.32160\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2518 | loss: 0.32160 - binary_acc: 0.9919 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2519  | total loss: \u001b[1m\u001b[32m0.32079\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2519 | loss: 0.32079 - binary_acc: 0.9927 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2520  | total loss: \u001b[1m\u001b[32m0.32007\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2520 | loss: 0.32007 - binary_acc: 0.9935 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2521  | total loss: \u001b[1m\u001b[32m0.31941\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2521 | loss: 0.31941 - binary_acc: 0.9941 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2522  | total loss: \u001b[1m\u001b[32m0.31882\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2522 | loss: 0.31882 - binary_acc: 0.9947 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2523  | total loss: \u001b[1m\u001b[32m0.31829\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2523 | loss: 0.31829 - binary_acc: 0.9952 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2524  | total loss: \u001b[1m\u001b[32m0.31782\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2524 | loss: 0.31782 - binary_acc: 0.9957 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2525  | total loss: \u001b[1m\u001b[32m0.31739\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2525 | loss: 0.31739 - binary_acc: 0.9961 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2526  | total loss: \u001b[1m\u001b[32m0.31700\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2526 | loss: 0.31700 - binary_acc: 0.9965 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2527  | total loss: \u001b[1m\u001b[32m0.31666\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2527 | loss: 0.31666 - binary_acc: 0.9969 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2528  | total loss: \u001b[1m\u001b[32m0.31634\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2528 | loss: 0.31634 - binary_acc: 0.9972 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2529  | total loss: \u001b[1m\u001b[32m0.31606\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2529 | loss: 0.31606 - binary_acc: 0.9975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2530  | total loss: \u001b[1m\u001b[32m0.36576\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2530 | loss: 0.36576 - binary_acc: 0.9477 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2531  | total loss: \u001b[1m\u001b[32m0.36053\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2531 | loss: 0.36053 - binary_acc: 0.9529 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2532  | total loss: \u001b[1m\u001b[32m0.35583\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2532 | loss: 0.35583 - binary_acc: 0.9577 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2533  | total loss: \u001b[1m\u001b[32m0.35160\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2533 | loss: 0.35160 - binary_acc: 0.9619 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2534  | total loss: \u001b[1m\u001b[32m0.34780\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2534 | loss: 0.34780 - binary_acc: 0.9657 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2535  | total loss: \u001b[1m\u001b[32m0.34437\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2535 | loss: 0.34437 - binary_acc: 0.9691 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2536  | total loss: \u001b[1m\u001b[32m0.39123\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2536 | loss: 0.39123 - binary_acc: 0.9222 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2537  | total loss: \u001b[1m\u001b[32m0.38346\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2537 | loss: 0.38346 - binary_acc: 0.9300 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2538  | total loss: \u001b[1m\u001b[32m0.37647\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2538 | loss: 0.37647 - binary_acc: 0.9370 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2539  | total loss: \u001b[1m\u001b[32m0.37017\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2539 | loss: 0.37017 - binary_acc: 0.9433 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2540  | total loss: \u001b[1m\u001b[32m0.36451\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2540 | loss: 0.36451 - binary_acc: 0.9490 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2541  | total loss: \u001b[1m\u001b[32m0.35941\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2541 | loss: 0.35941 - binary_acc: 0.9541 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2542  | total loss: \u001b[1m\u001b[32m0.35482\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2542 | loss: 0.35482 - binary_acc: 0.9587 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2543  | total loss: \u001b[1m\u001b[32m0.35069\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2543 | loss: 0.35069 - binary_acc: 0.9628 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2544  | total loss: \u001b[1m\u001b[32m0.34698\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2544 | loss: 0.34698 - binary_acc: 0.9665 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2545  | total loss: \u001b[1m\u001b[32m0.34363\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2545 | loss: 0.34363 - binary_acc: 0.9699 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2546  | total loss: \u001b[1m\u001b[32m0.34062\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2546 | loss: 0.34062 - binary_acc: 0.9729 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2547  | total loss: \u001b[1m\u001b[32m0.33791\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2547 | loss: 0.33791 - binary_acc: 0.9756 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2548  | total loss: \u001b[1m\u001b[32m0.33547\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2548 | loss: 0.33547 - binary_acc: 0.9780 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2549  | total loss: \u001b[1m\u001b[32m0.33328\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2549 | loss: 0.33328 - binary_acc: 0.9802 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2550  | total loss: \u001b[1m\u001b[32m0.33130\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2550 | loss: 0.33130 - binary_acc: 0.9822 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2551  | total loss: \u001b[1m\u001b[32m0.32952\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2551 | loss: 0.32952 - binary_acc: 0.9840 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2552  | total loss: \u001b[1m\u001b[32m0.32792\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2552 | loss: 0.32792 - binary_acc: 0.9856 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2553  | total loss: \u001b[1m\u001b[32m0.32648\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2553 | loss: 0.32648 - binary_acc: 0.9870 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2554  | total loss: \u001b[1m\u001b[32m0.32518\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2554 | loss: 0.32518 - binary_acc: 0.9883 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2555  | total loss: \u001b[1m\u001b[32m0.32402\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2555 | loss: 0.32402 - binary_acc: 0.9895 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2556  | total loss: \u001b[1m\u001b[32m0.32297\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2556 | loss: 0.32297 - binary_acc: 0.9905 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2557  | total loss: \u001b[1m\u001b[32m0.32202\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2557 | loss: 0.32202 - binary_acc: 0.9915 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2558  | total loss: \u001b[1m\u001b[32m0.32117\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2558 | loss: 0.32117 - binary_acc: 0.9923 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2559  | total loss: \u001b[1m\u001b[32m0.32041\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2559 | loss: 0.32041 - binary_acc: 0.9931 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2560  | total loss: \u001b[1m\u001b[32m0.31972\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2560 | loss: 0.31972 - binary_acc: 0.9938 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2561  | total loss: \u001b[1m\u001b[32m0.31910\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2561 | loss: 0.31910 - binary_acc: 0.9944 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2562  | total loss: \u001b[1m\u001b[32m0.31854\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2562 | loss: 0.31854 - binary_acc: 0.9950 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2563  | total loss: \u001b[1m\u001b[32m0.31804\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2563 | loss: 0.31804 - binary_acc: 0.9955 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2564  | total loss: \u001b[1m\u001b[32m0.31758\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2564 | loss: 0.31758 - binary_acc: 0.9959 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2565  | total loss: \u001b[1m\u001b[32m0.31718\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2565 | loss: 0.31718 - binary_acc: 0.9963 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2566  | total loss: \u001b[1m\u001b[32m0.31681\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2566 | loss: 0.31681 - binary_acc: 0.9967 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2567  | total loss: \u001b[1m\u001b[32m0.31648\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2567 | loss: 0.31648 - binary_acc: 0.9970 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2568  | total loss: \u001b[1m\u001b[32m0.31618\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2568 | loss: 0.31618 - binary_acc: 0.9973 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2569  | total loss: \u001b[1m\u001b[32m0.31592\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2569 | loss: 0.31592 - binary_acc: 0.9976 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2570  | total loss: \u001b[1m\u001b[32m0.31568\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2570 | loss: 0.31568 - binary_acc: 0.9978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2571  | total loss: \u001b[1m\u001b[32m0.31546\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2571 | loss: 0.31546 - binary_acc: 0.9981 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2572  | total loss: \u001b[1m\u001b[32m0.31527\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2572 | loss: 0.31527 - binary_acc: 0.9982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2573  | total loss: \u001b[1m\u001b[32m0.31509\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2573 | loss: 0.31509 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2574  | total loss: \u001b[1m\u001b[32m0.31493\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2574 | loss: 0.31493 - binary_acc: 0.9986 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2575  | total loss: \u001b[1m\u001b[32m0.31479\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2575 | loss: 0.31479 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2576  | total loss: \u001b[1m\u001b[32m0.31466\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2576 | loss: 0.31466 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2577  | total loss: \u001b[1m\u001b[32m0.31455\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2577 | loss: 0.31455 - binary_acc: 0.9990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2578  | total loss: \u001b[1m\u001b[32m0.31444\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2578 | loss: 0.31444 - binary_acc: 0.9991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2579  | total loss: \u001b[1m\u001b[32m0.31435\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2579 | loss: 0.31435 - binary_acc: 0.9992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2580  | total loss: \u001b[1m\u001b[32m0.31427\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2580 | loss: 0.31427 - binary_acc: 0.9992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2581  | total loss: \u001b[1m\u001b[32m0.31419\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2581 | loss: 0.31419 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2582  | total loss: \u001b[1m\u001b[32m0.31412\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2582 | loss: 0.31412 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2583  | total loss: \u001b[1m\u001b[32m0.31406\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2583 | loss: 0.31406 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2584  | total loss: \u001b[1m\u001b[32m0.31400\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2584 | loss: 0.31400 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2585  | total loss: \u001b[1m\u001b[32m0.31395\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2585 | loss: 0.31395 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2586  | total loss: \u001b[1m\u001b[32m0.31391\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2586 | loss: 0.31391 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2587  | total loss: \u001b[1m\u001b[32m0.31387\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2587 | loss: 0.31387 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2588  | total loss: \u001b[1m\u001b[32m0.31383\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2588 | loss: 0.31383 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2589  | total loss: \u001b[1m\u001b[32m0.31380\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2589 | loss: 0.31380 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2590  | total loss: \u001b[1m\u001b[32m0.31377\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2590 | loss: 0.31377 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2591  | total loss: \u001b[1m\u001b[32m0.31374\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2591 | loss: 0.31374 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2592  | total loss: \u001b[1m\u001b[32m0.31372\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2592 | loss: 0.31372 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2593  | total loss: \u001b[1m\u001b[32m0.31370\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2593 | loss: 0.31370 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2594  | total loss: \u001b[1m\u001b[32m0.31368\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2594 | loss: 0.31368 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2595  | total loss: \u001b[1m\u001b[32m0.31366\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2595 | loss: 0.31366 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2596  | total loss: \u001b[1m\u001b[32m0.31365\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2596 | loss: 0.31365 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2597  | total loss: \u001b[1m\u001b[32m0.31363\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2597 | loss: 0.31363 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2598  | total loss: \u001b[1m\u001b[32m0.31362\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2598 | loss: 0.31362 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2599  | total loss: \u001b[1m\u001b[32m0.31361\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2599 | loss: 0.31361 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2600  | total loss: \u001b[1m\u001b[32m0.31360\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2600 | loss: 0.31360 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2601  | total loss: \u001b[1m\u001b[32m0.31359\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2601 | loss: 0.31359 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2602  | total loss: \u001b[1m\u001b[32m0.31358\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2602 | loss: 0.31358 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2603  | total loss: \u001b[1m\u001b[32m0.31357\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2603 | loss: 0.31357 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2604  | total loss: \u001b[1m\u001b[32m0.31356\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2604 | loss: 0.31356 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2605  | total loss: \u001b[1m\u001b[32m0.31356\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2605 | loss: 0.31356 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2606  | total loss: \u001b[1m\u001b[32m0.31355\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2606 | loss: 0.31355 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2607  | total loss: \u001b[1m\u001b[32m0.31355\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2607 | loss: 0.31355 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2608  | total loss: \u001b[1m\u001b[32m0.31354\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2608 | loss: 0.31354 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2609  | total loss: \u001b[1m\u001b[32m0.31354\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2609 | loss: 0.31354 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2610  | total loss: \u001b[1m\u001b[32m0.31353\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2610 | loss: 0.31353 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2611  | total loss: \u001b[1m\u001b[32m0.31353\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2611 | loss: 0.31353 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2612  | total loss: \u001b[1m\u001b[32m0.31353\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2612 | loss: 0.31353 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2613  | total loss: \u001b[1m\u001b[32m0.31352\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2613 | loss: 0.31352 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2614  | total loss: \u001b[1m\u001b[32m0.31352\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2614 | loss: 0.31352 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2615  | total loss: \u001b[1m\u001b[32m0.31352\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2615 | loss: 0.31352 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2616  | total loss: \u001b[1m\u001b[32m0.31352\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2616 | loss: 0.31352 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2617  | total loss: \u001b[1m\u001b[32m0.31351\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2617 | loss: 0.31351 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2618  | total loss: \u001b[1m\u001b[32m0.31351\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2618 | loss: 0.31351 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2619  | total loss: \u001b[1m\u001b[32m0.31351\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2619 | loss: 0.31351 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2620  | total loss: \u001b[1m\u001b[32m0.31351\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2620 | loss: 0.31351 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2621  | total loss: \u001b[1m\u001b[32m0.31351\u001b[0m\u001b[0m | time: 0.008s\n",
            "| SGD | epoch: 2621 | loss: 0.31351 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2622  | total loss: \u001b[1m\u001b[32m0.36346\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2622 | loss: 0.36346 - binary_acc: 0.9500 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2623  | total loss: \u001b[1m\u001b[32m0.35847\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2623 | loss: 0.35847 - binary_acc: 0.9550 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2624  | total loss: \u001b[1m\u001b[32m0.35397\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2624 | loss: 0.35397 - binary_acc: 0.9595 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2625  | total loss: \u001b[1m\u001b[32m0.34992\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2625 | loss: 0.34992 - binary_acc: 0.9635 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2626  | total loss: \u001b[1m\u001b[32m0.34628\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2626 | loss: 0.34628 - binary_acc: 0.9672 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2627  | total loss: \u001b[1m\u001b[32m0.34300\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2627 | loss: 0.34300 - binary_acc: 0.9705 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2628  | total loss: \u001b[1m\u001b[32m0.34005\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2628 | loss: 0.34005 - binary_acc: 0.9734 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2629  | total loss: \u001b[1m\u001b[32m0.33739\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2629 | loss: 0.33739 - binary_acc: 0.9761 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2630  | total loss: \u001b[1m\u001b[32m0.33500\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2630 | loss: 0.33500 - binary_acc: 0.9785 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2631  | total loss: \u001b[1m\u001b[32m0.33285\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2631 | loss: 0.33285 - binary_acc: 0.9806 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2632  | total loss: \u001b[1m\u001b[32m0.33092\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2632 | loss: 0.33092 - binary_acc: 0.9826 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2633  | total loss: \u001b[1m\u001b[32m0.32917\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2633 | loss: 0.32917 - binary_acc: 0.9843 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2634  | total loss: \u001b[1m\u001b[32m0.32760\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2634 | loss: 0.32760 - binary_acc: 0.9859 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2635  | total loss: \u001b[1m\u001b[32m0.32619\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2635 | loss: 0.32619 - binary_acc: 0.9873 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2636  | total loss: \u001b[1m\u001b[32m0.32492\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2636 | loss: 0.32492 - binary_acc: 0.9886 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2637  | total loss: \u001b[1m\u001b[32m0.32378\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2637 | loss: 0.32378 - binary_acc: 0.9897 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2638  | total loss: \u001b[1m\u001b[32m0.32275\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2638 | loss: 0.32275 - binary_acc: 0.9907 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2639  | total loss: \u001b[1m\u001b[32m0.32182\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2639 | loss: 0.32182 - binary_acc: 0.9917 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2640  | total loss: \u001b[1m\u001b[32m0.32099\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2640 | loss: 0.32099 - binary_acc: 0.9925 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2641  | total loss: \u001b[1m\u001b[32m0.32024\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2641 | loss: 0.32024 - binary_acc: 0.9932 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2642  | total loss: \u001b[1m\u001b[32m0.31957\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2642 | loss: 0.31957 - binary_acc: 0.9939 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2643  | total loss: \u001b[1m\u001b[32m0.31896\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2643 | loss: 0.31896 - binary_acc: 0.9945 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2644  | total loss: \u001b[1m\u001b[32m0.41833\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2644 | loss: 0.41833 - binary_acc: 0.8951 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2645  | total loss: \u001b[1m\u001b[32m0.40784\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2645 | loss: 0.40784 - binary_acc: 0.9056 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2646  | total loss: \u001b[1m\u001b[32m0.39841\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2646 | loss: 0.39841 - binary_acc: 0.9150 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2647  | total loss: \u001b[1m\u001b[32m0.38992\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2647 | loss: 0.38992 - binary_acc: 0.9235 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2648  | total loss: \u001b[1m\u001b[32m0.38227\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2648 | loss: 0.38227 - binary_acc: 0.9312 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2649  | total loss: \u001b[1m\u001b[32m0.37539\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2649 | loss: 0.37539 - binary_acc: 0.9380 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2650  | total loss: \u001b[1m\u001b[32m0.36920\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2650 | loss: 0.36920 - binary_acc: 0.9442 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2651  | total loss: \u001b[1m\u001b[32m0.36363\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2651 | loss: 0.36363 - binary_acc: 0.9498 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2652  | total loss: \u001b[1m\u001b[32m0.35862\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2652 | loss: 0.35862 - binary_acc: 0.9548 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2653  | total loss: \u001b[1m\u001b[32m0.35410\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2653 | loss: 0.35410 - binary_acc: 0.9593 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2654  | total loss: \u001b[1m\u001b[32m0.35004\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2654 | loss: 0.35004 - binary_acc: 0.9634 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2655  | total loss: \u001b[1m\u001b[32m0.34639\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2655 | loss: 0.34639 - binary_acc: 0.9671 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2656  | total loss: \u001b[1m\u001b[32m0.34310\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2656 | loss: 0.34310 - binary_acc: 0.9704 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2657  | total loss: \u001b[1m\u001b[32m0.34013\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2657 | loss: 0.34013 - binary_acc: 0.9733 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2658  | total loss: \u001b[1m\u001b[32m0.33747\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2658 | loss: 0.33747 - binary_acc: 0.9760 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2659  | total loss: \u001b[1m\u001b[32m0.33507\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2659 | loss: 0.33507 - binary_acc: 0.9784 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2660  | total loss: \u001b[1m\u001b[32m0.33291\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2660 | loss: 0.33291 - binary_acc: 0.9806 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2661  | total loss: \u001b[1m\u001b[32m0.33097\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2661 | loss: 0.33097 - binary_acc: 0.9825 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2662  | total loss: \u001b[1m\u001b[32m0.32922\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2662 | loss: 0.32922 - binary_acc: 0.9843 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2663  | total loss: \u001b[1m\u001b[32m0.32765\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2663 | loss: 0.32765 - binary_acc: 0.9858 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2664  | total loss: \u001b[1m\u001b[32m0.32623\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2664 | loss: 0.32623 - binary_acc: 0.9872 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2665  | total loss: \u001b[1m\u001b[32m0.32496\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2665 | loss: 0.32496 - binary_acc: 0.9885 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2666  | total loss: \u001b[1m\u001b[32m0.32381\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2666 | loss: 0.32381 - binary_acc: 0.9897 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2667  | total loss: \u001b[1m\u001b[32m0.32278\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2667 | loss: 0.32278 - binary_acc: 0.9907 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2668  | total loss: \u001b[1m\u001b[32m0.32185\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2668 | loss: 0.32185 - binary_acc: 0.9916 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2669  | total loss: \u001b[1m\u001b[32m0.32101\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2669 | loss: 0.32101 - binary_acc: 0.9925 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2670  | total loss: \u001b[1m\u001b[32m0.32026\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2670 | loss: 0.32026 - binary_acc: 0.9932 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2671  | total loss: \u001b[1m\u001b[32m0.31958\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2671 | loss: 0.31958 - binary_acc: 0.9939 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2672  | total loss: \u001b[1m\u001b[32m0.31897\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2672 | loss: 0.31897 - binary_acc: 0.9945 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2673  | total loss: \u001b[1m\u001b[32m0.31842\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2673 | loss: 0.31842 - binary_acc: 0.9951 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2674  | total loss: \u001b[1m\u001b[32m0.31793\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2674 | loss: 0.31793 - binary_acc: 0.9956 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2675  | total loss: \u001b[1m\u001b[32m0.31748\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2675 | loss: 0.31748 - binary_acc: 0.9960 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2676  | total loss: \u001b[1m\u001b[32m0.31708\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2676 | loss: 0.31708 - binary_acc: 0.9964 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2677  | total loss: \u001b[1m\u001b[32m0.31672\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2677 | loss: 0.31672 - binary_acc: 0.9968 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2678  | total loss: \u001b[1m\u001b[32m0.31640\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2678 | loss: 0.31640 - binary_acc: 0.9971 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2679  | total loss: \u001b[1m\u001b[32m0.31610\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2679 | loss: 0.31610 - binary_acc: 0.9974 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2680  | total loss: \u001b[1m\u001b[32m0.31584\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2680 | loss: 0.31584 - binary_acc: 0.9976 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2681  | total loss: \u001b[1m\u001b[32m0.31561\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2681 | loss: 0.31561 - binary_acc: 0.9979 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2682  | total loss: \u001b[1m\u001b[32m0.31539\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2682 | loss: 0.31539 - binary_acc: 0.9981 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2683  | total loss: \u001b[1m\u001b[32m0.31520\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2683 | loss: 0.31520 - binary_acc: 0.9983 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2684  | total loss: \u001b[1m\u001b[32m0.31503\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2684 | loss: 0.31503 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2685  | total loss: \u001b[1m\u001b[32m0.31487\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2685 | loss: 0.31487 - binary_acc: 0.9986 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2686  | total loss: \u001b[1m\u001b[32m0.31473\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2686 | loss: 0.31473 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2687  | total loss: \u001b[1m\u001b[32m0.31461\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2687 | loss: 0.31461 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2688  | total loss: \u001b[1m\u001b[32m0.31449\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2688 | loss: 0.31449 - binary_acc: 0.9990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2689  | total loss: \u001b[1m\u001b[32m0.31439\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2689 | loss: 0.31439 - binary_acc: 0.9991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2690  | total loss: \u001b[1m\u001b[32m0.31430\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2690 | loss: 0.31430 - binary_acc: 0.9992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2691  | total loss: \u001b[1m\u001b[32m0.31422\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2691 | loss: 0.31422 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2692  | total loss: \u001b[1m\u001b[32m0.31414\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2692 | loss: 0.31414 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2693  | total loss: \u001b[1m\u001b[32m0.31408\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2693 | loss: 0.31408 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2694  | total loss: \u001b[1m\u001b[32m0.31402\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2694 | loss: 0.31402 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2695  | total loss: \u001b[1m\u001b[32m0.31396\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2695 | loss: 0.31396 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2696  | total loss: \u001b[1m\u001b[32m0.31391\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2696 | loss: 0.31391 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2697  | total loss: \u001b[1m\u001b[32m0.31387\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2697 | loss: 0.31387 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2698  | total loss: \u001b[1m\u001b[32m0.31383\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2698 | loss: 0.31383 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2699  | total loss: \u001b[1m\u001b[32m0.31379\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2699 | loss: 0.31379 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2700  | total loss: \u001b[1m\u001b[32m0.31376\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2700 | loss: 0.31376 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2701  | total loss: \u001b[1m\u001b[32m0.31373\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2701 | loss: 0.31373 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2702  | total loss: \u001b[1m\u001b[32m0.31371\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2702 | loss: 0.31371 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2703  | total loss: \u001b[1m\u001b[32m0.31368\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2703 | loss: 0.31368 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2704  | total loss: \u001b[1m\u001b[32m0.31366\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2704 | loss: 0.31366 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2705  | total loss: \u001b[1m\u001b[32m0.31364\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2705 | loss: 0.31364 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2706  | total loss: \u001b[1m\u001b[32m0.31362\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2706 | loss: 0.31362 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2707  | total loss: \u001b[1m\u001b[32m0.31361\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2707 | loss: 0.31361 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2708  | total loss: \u001b[1m\u001b[32m0.31360\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2708 | loss: 0.31360 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2709  | total loss: \u001b[1m\u001b[32m0.31358\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2709 | loss: 0.31358 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2710  | total loss: \u001b[1m\u001b[32m0.31357\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2710 | loss: 0.31357 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2711  | total loss: \u001b[1m\u001b[32m0.31356\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2711 | loss: 0.31356 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2712  | total loss: \u001b[1m\u001b[32m0.31355\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2712 | loss: 0.31355 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2713  | total loss: \u001b[1m\u001b[32m0.31354\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2713 | loss: 0.31354 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2714  | total loss: \u001b[1m\u001b[32m0.31354\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2714 | loss: 0.31354 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2715  | total loss: \u001b[1m\u001b[32m0.31353\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2715 | loss: 0.31353 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2716  | total loss: \u001b[1m\u001b[32m0.31352\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2716 | loss: 0.31352 - binary_acc: 0.9999 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2717  | total loss: \u001b[1m\u001b[32m0.31352\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2717 | loss: 0.31352 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2718  | total loss: \u001b[1m\u001b[32m0.31351\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2718 | loss: 0.31351 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2719  | total loss: \u001b[1m\u001b[32m0.31351\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2719 | loss: 0.31351 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2720  | total loss: \u001b[1m\u001b[32m0.31350\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2720 | loss: 0.31350 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2721  | total loss: \u001b[1m\u001b[32m0.31350\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2721 | loss: 0.31350 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2722  | total loss: \u001b[1m\u001b[32m0.31350\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2722 | loss: 0.31350 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2723  | total loss: \u001b[1m\u001b[32m0.31349\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2723 | loss: 0.31349 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2724  | total loss: \u001b[1m\u001b[32m0.31349\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2724 | loss: 0.31349 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2725  | total loss: \u001b[1m\u001b[32m0.31349\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2725 | loss: 0.31349 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2726  | total loss: \u001b[1m\u001b[32m0.31349\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2726 | loss: 0.31349 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2727  | total loss: \u001b[1m\u001b[32m0.31348\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2727 | loss: 0.31348 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2728  | total loss: \u001b[1m\u001b[32m0.31348\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2728 | loss: 0.31348 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2729  | total loss: \u001b[1m\u001b[32m0.31348\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2729 | loss: 0.31348 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2730  | total loss: \u001b[1m\u001b[32m0.31348\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2730 | loss: 0.31348 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2731  | total loss: \u001b[1m\u001b[32m0.31348\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2731 | loss: 0.31348 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2732  | total loss: \u001b[1m\u001b[32m0.31348\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2732 | loss: 0.31348 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2733  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2733 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2734  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2734 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2735  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2735 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2736  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2736 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2737  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.011s\n",
            "| SGD | epoch: 2737 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2738  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2738 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2739  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2739 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2740  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2740 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2741  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2741 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2742  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2742 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2743  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2743 | loss: 0.31347 - binary_acc: 1.0000 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2744  | total loss: \u001b[1m\u001b[32m0.36343\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2744 | loss: 0.36343 - binary_acc: 0.9500 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2745  | total loss: \u001b[1m\u001b[32m0.35843\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2745 | loss: 0.35843 - binary_acc: 0.9550 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2746  | total loss: \u001b[1m\u001b[32m0.35393\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2746 | loss: 0.35393 - binary_acc: 0.9595 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2747  | total loss: \u001b[1m\u001b[32m0.34989\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2747 | loss: 0.34989 - binary_acc: 0.9635 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2748  | total loss: \u001b[1m\u001b[32m0.34624\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2748 | loss: 0.34624 - binary_acc: 0.9672 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2749  | total loss: \u001b[1m\u001b[32m0.34297\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2749 | loss: 0.34297 - binary_acc: 0.9705 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2750  | total loss: \u001b[1m\u001b[32m0.38998\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2750 | loss: 0.38998 - binary_acc: 0.9234 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2751  | total loss: \u001b[1m\u001b[32m0.38233\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2751 | loss: 0.38233 - binary_acc: 0.9311 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2752  | total loss: \u001b[1m\u001b[32m0.42540\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2752 | loss: 0.42540 - binary_acc: 0.8880 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2753  | total loss: \u001b[1m\u001b[32m0.41421\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2753 | loss: 0.41421 - binary_acc: 0.8992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2754  | total loss: \u001b[1m\u001b[32m0.40413\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2754 | loss: 0.40413 - binary_acc: 0.9093 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2755  | total loss: \u001b[1m\u001b[32m0.39506\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2755 | loss: 0.39506 - binary_acc: 0.9183 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2756  | total loss: \u001b[1m\u001b[32m0.43687\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2756 | loss: 0.43687 - binary_acc: 0.8765 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2757  | total loss: \u001b[1m\u001b[32m0.42453\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2757 | loss: 0.42453 - binary_acc: 0.8889 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2758  | total loss: \u001b[1m\u001b[32m0.46338\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2758 | loss: 0.46338 - binary_acc: 0.8500 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2759  | total loss: \u001b[1m\u001b[32m0.44839\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2759 | loss: 0.44839 - binary_acc: 0.8650 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2760  | total loss: \u001b[1m\u001b[32m0.43490\u001b[0m\u001b[0m | time: 0.006s\n",
            "| SGD | epoch: 2760 | loss: 0.43490 - binary_acc: 0.8785 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2761  | total loss: \u001b[1m\u001b[32m0.42275\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2761 | loss: 0.42275 - binary_acc: 0.8906 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2762  | total loss: \u001b[1m\u001b[32m0.41182\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2762 | loss: 0.41182 - binary_acc: 0.9016 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2763  | total loss: \u001b[1m\u001b[32m0.40199\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2763 | loss: 0.40199 - binary_acc: 0.9114 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2764  | total loss: \u001b[1m\u001b[32m0.39314\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2764 | loss: 0.39314 - binary_acc: 0.9203 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2765  | total loss: \u001b[1m\u001b[32m0.38517\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2765 | loss: 0.38517 - binary_acc: 0.9282 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2766  | total loss: \u001b[1m\u001b[32m0.37800\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2766 | loss: 0.37800 - binary_acc: 0.9354 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2767  | total loss: \u001b[1m\u001b[32m0.37154\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2767 | loss: 0.37154 - binary_acc: 0.9419 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2768  | total loss: \u001b[1m\u001b[32m0.36573\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2768 | loss: 0.36573 - binary_acc: 0.9477 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2769  | total loss: \u001b[1m\u001b[32m0.36051\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2769 | loss: 0.36051 - binary_acc: 0.9529 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2770  | total loss: \u001b[1m\u001b[32m0.35580\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2770 | loss: 0.35580 - binary_acc: 0.9576 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2771  | total loss: \u001b[1m\u001b[32m0.35157\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2771 | loss: 0.35157 - binary_acc: 0.9619 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2772  | total loss: \u001b[1m\u001b[32m0.34776\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2772 | loss: 0.34776 - binary_acc: 0.9657 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2773  | total loss: \u001b[1m\u001b[32m0.34433\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2773 | loss: 0.34433 - binary_acc: 0.9691 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2774  | total loss: \u001b[1m\u001b[32m0.34124\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2774 | loss: 0.34124 - binary_acc: 0.9722 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2775  | total loss: \u001b[1m\u001b[32m0.33846\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2775 | loss: 0.33846 - binary_acc: 0.9750 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2776  | total loss: \u001b[1m\u001b[32m0.33596\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2776 | loss: 0.33596 - binary_acc: 0.9775 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2777  | total loss: \u001b[1m\u001b[32m0.33371\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2777 | loss: 0.33371 - binary_acc: 0.9797 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2778  | total loss: \u001b[1m\u001b[32m0.33168\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2778 | loss: 0.33168 - binary_acc: 0.9818 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2779  | total loss: \u001b[1m\u001b[32m0.32986\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2779 | loss: 0.32986 - binary_acc: 0.9836 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2780  | total loss: \u001b[1m\u001b[32m0.32822\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2780 | loss: 0.32822 - binary_acc: 0.9852 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2781  | total loss: \u001b[1m\u001b[32m0.32674\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2781 | loss: 0.32674 - binary_acc: 0.9867 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2782  | total loss: \u001b[1m\u001b[32m0.32541\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2782 | loss: 0.32541 - binary_acc: 0.9880 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2783  | total loss: \u001b[1m\u001b[32m0.32422\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2783 | loss: 0.32422 - binary_acc: 0.9892 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2784  | total loss: \u001b[1m\u001b[32m0.32314\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2784 | loss: 0.32314 - binary_acc: 0.9903 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2785  | total loss: \u001b[1m\u001b[32m0.32217\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2785 | loss: 0.32217 - binary_acc: 0.9913 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2786  | total loss: \u001b[1m\u001b[32m0.32130\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2786 | loss: 0.32130 - binary_acc: 0.9921 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2787  | total loss: \u001b[1m\u001b[32m0.32052\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2787 | loss: 0.32052 - binary_acc: 0.9929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2788  | total loss: \u001b[1m\u001b[32m0.31981\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2788 | loss: 0.31981 - binary_acc: 0.9936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2789  | total loss: \u001b[1m\u001b[32m0.31917\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2789 | loss: 0.31917 - binary_acc: 0.9943 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2790  | total loss: \u001b[1m\u001b[32m0.31860\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2790 | loss: 0.31860 - binary_acc: 0.9948 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2791  | total loss: \u001b[1m\u001b[32m0.31809\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2791 | loss: 0.31809 - binary_acc: 0.9954 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2792  | total loss: \u001b[1m\u001b[32m0.31762\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2792 | loss: 0.31762 - binary_acc: 0.9958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2793  | total loss: \u001b[1m\u001b[32m0.31721\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2793 | loss: 0.31721 - binary_acc: 0.9962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2794  | total loss: \u001b[1m\u001b[32m0.31683\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2794 | loss: 0.31683 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2795  | total loss: \u001b[1m\u001b[32m0.31649\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2795 | loss: 0.31649 - binary_acc: 0.9970 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2796  | total loss: \u001b[1m\u001b[32m0.31619\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2796 | loss: 0.31619 - binary_acc: 0.9973 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2797  | total loss: \u001b[1m\u001b[32m0.31591\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2797 | loss: 0.31591 - binary_acc: 0.9975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2798  | total loss: \u001b[1m\u001b[32m0.36563\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2798 | loss: 0.36563 - binary_acc: 0.9478 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2799  | total loss: \u001b[1m\u001b[32m0.36042\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2799 | loss: 0.36042 - binary_acc: 0.9530 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2800  | total loss: \u001b[1m\u001b[32m0.35572\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2800 | loss: 0.35572 - binary_acc: 0.9577 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2801  | total loss: \u001b[1m\u001b[32m0.35149\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2801 | loss: 0.35149 - binary_acc: 0.9619 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2802  | total loss: \u001b[1m\u001b[32m0.39765\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2802 | loss: 0.39765 - binary_acc: 0.9157 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2803  | total loss: \u001b[1m\u001b[32m0.38923\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2803 | loss: 0.38923 - binary_acc: 0.9242 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2804  | total loss: \u001b[1m\u001b[32m0.38166\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2804 | loss: 0.38166 - binary_acc: 0.9317 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2805  | total loss: \u001b[1m\u001b[32m0.37483\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2805 | loss: 0.37483 - binary_acc: 0.9386 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2806  | total loss: \u001b[1m\u001b[32m0.36870\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2806 | loss: 0.36870 - binary_acc: 0.9447 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2807  | total loss: \u001b[1m\u001b[32m0.36317\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2807 | loss: 0.36317 - binary_acc: 0.9502 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2808  | total loss: \u001b[1m\u001b[32m0.35820\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2808 | loss: 0.35820 - binary_acc: 0.9552 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2809  | total loss: \u001b[1m\u001b[32m0.35372\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2809 | loss: 0.35372 - binary_acc: 0.9597 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2810  | total loss: \u001b[1m\u001b[32m0.34970\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2810 | loss: 0.34970 - binary_acc: 0.9637 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2811  | total loss: \u001b[1m\u001b[32m0.34607\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2811 | loss: 0.34607 - binary_acc: 0.9674 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2812  | total loss: \u001b[1m\u001b[32m0.34281\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2812 | loss: 0.34281 - binary_acc: 0.9706 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2813  | total loss: \u001b[1m\u001b[32m0.33987\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2813 | loss: 0.33987 - binary_acc: 0.9736 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2814  | total loss: \u001b[1m\u001b[32m0.33723\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2814 | loss: 0.33723 - binary_acc: 0.9762 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2815  | total loss: \u001b[1m\u001b[32m0.33485\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2815 | loss: 0.33485 - binary_acc: 0.9786 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2816  | total loss: \u001b[1m\u001b[32m0.33271\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2816 | loss: 0.33271 - binary_acc: 0.9807 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2817  | total loss: \u001b[1m\u001b[32m0.33079\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2817 | loss: 0.33079 - binary_acc: 0.9827 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2818  | total loss: \u001b[1m\u001b[32m0.32905\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2818 | loss: 0.32905 - binary_acc: 0.9844 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2819  | total loss: \u001b[1m\u001b[32m0.32749\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2819 | loss: 0.32749 - binary_acc: 0.9859 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2820  | total loss: \u001b[1m\u001b[32m0.32609\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2820 | loss: 0.32609 - binary_acc: 0.9874 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2821  | total loss: \u001b[1m\u001b[32m0.32482\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2821 | loss: 0.32482 - binary_acc: 0.9886 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2822  | total loss: \u001b[1m\u001b[32m0.32368\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2822 | loss: 0.32368 - binary_acc: 0.9898 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2823  | total loss: \u001b[1m\u001b[32m0.32266\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2823 | loss: 0.32266 - binary_acc: 0.9908 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2824  | total loss: \u001b[1m\u001b[32m0.32174\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2824 | loss: 0.32174 - binary_acc: 0.9917 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2825  | total loss: \u001b[1m\u001b[32m0.32091\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2825 | loss: 0.32091 - binary_acc: 0.9925 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2826  | total loss: \u001b[1m\u001b[32m0.32016\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2826 | loss: 0.32016 - binary_acc: 0.9933 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2827  | total loss: \u001b[1m\u001b[32m0.31949\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2827 | loss: 0.31949 - binary_acc: 0.9940 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2828  | total loss: \u001b[1m\u001b[32m0.31889\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2828 | loss: 0.31889 - binary_acc: 0.9946 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2829  | total loss: \u001b[1m\u001b[32m0.31834\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2829 | loss: 0.31834 - binary_acc: 0.9951 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2830  | total loss: \u001b[1m\u001b[32m0.31785\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2830 | loss: 0.31785 - binary_acc: 0.9956 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2831  | total loss: \u001b[1m\u001b[32m0.31741\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2831 | loss: 0.31741 - binary_acc: 0.9960 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2832  | total loss: \u001b[1m\u001b[32m0.31701\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2832 | loss: 0.31701 - binary_acc: 0.9964 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2833  | total loss: \u001b[1m\u001b[32m0.31666\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2833 | loss: 0.31666 - binary_acc: 0.9968 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2834  | total loss: \u001b[1m\u001b[32m0.36630\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2834 | loss: 0.36630 - binary_acc: 0.9471 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2835  | total loss: \u001b[1m\u001b[32m0.36102\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2835 | loss: 0.36102 - binary_acc: 0.9524 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2836  | total loss: \u001b[1m\u001b[32m0.35626\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2836 | loss: 0.35626 - binary_acc: 0.9572 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2837  | total loss: \u001b[1m\u001b[32m0.35198\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2837 | loss: 0.35198 - binary_acc: 0.9614 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2838  | total loss: \u001b[1m\u001b[32m0.34812\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2838 | loss: 0.34812 - binary_acc: 0.9653 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2839  | total loss: \u001b[1m\u001b[32m0.34466\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2839 | loss: 0.34466 - binary_acc: 0.9688 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2840  | total loss: \u001b[1m\u001b[32m0.34153\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2840 | loss: 0.34153 - binary_acc: 0.9719 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2841  | total loss: \u001b[1m\u001b[32m0.33872\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2841 | loss: 0.33872 - binary_acc: 0.9747 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2842  | total loss: \u001b[1m\u001b[32m0.33620\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2842 | loss: 0.33620 - binary_acc: 0.9772 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2843  | total loss: \u001b[1m\u001b[32m0.33392\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2843 | loss: 0.33392 - binary_acc: 0.9795 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2844  | total loss: \u001b[1m\u001b[32m0.33187\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2844 | loss: 0.33187 - binary_acc: 0.9816 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2845  | total loss: \u001b[1m\u001b[32m0.33003\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2845 | loss: 0.33003 - binary_acc: 0.9834 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2846  | total loss: \u001b[1m\u001b[32m0.32837\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2846 | loss: 0.32837 - binary_acc: 0.9851 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2847  | total loss: \u001b[1m\u001b[32m0.32688\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2847 | loss: 0.32688 - binary_acc: 0.9866 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2848  | total loss: \u001b[1m\u001b[32m0.32553\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2848 | loss: 0.32553 - binary_acc: 0.9879 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2849  | total loss: \u001b[1m\u001b[32m0.32432\u001b[0m\u001b[0m | time: 0.009s\n",
            "| SGD | epoch: 2849 | loss: 0.32432 - binary_acc: 0.9891 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2850  | total loss: \u001b[1m\u001b[32m0.32324\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2850 | loss: 0.32324 - binary_acc: 0.9902 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2851  | total loss: \u001b[1m\u001b[32m0.32226\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2851 | loss: 0.32226 - binary_acc: 0.9912 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2852  | total loss: \u001b[1m\u001b[32m0.32138\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2852 | loss: 0.32138 - binary_acc: 0.9921 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2853  | total loss: \u001b[1m\u001b[32m0.32058\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2853 | loss: 0.32058 - binary_acc: 0.9929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2854  | total loss: \u001b[1m\u001b[32m0.31987\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2854 | loss: 0.31987 - binary_acc: 0.9936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2855  | total loss: \u001b[1m\u001b[32m0.31922\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2855 | loss: 0.31922 - binary_acc: 0.9942 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2856  | total loss: \u001b[1m\u001b[32m0.31865\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2856 | loss: 0.31865 - binary_acc: 0.9948 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2857  | total loss: \u001b[1m\u001b[32m0.31813\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2857 | loss: 0.31813 - binary_acc: 0.9953 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2858  | total loss: \u001b[1m\u001b[32m0.31766\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2858 | loss: 0.31766 - binary_acc: 0.9958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2859  | total loss: \u001b[1m\u001b[32m0.31723\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2859 | loss: 0.31723 - binary_acc: 0.9962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2860  | total loss: \u001b[1m\u001b[32m0.31686\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2860 | loss: 0.31686 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2861  | total loss: \u001b[1m\u001b[32m0.31651\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2861 | loss: 0.31651 - binary_acc: 0.9969 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2862  | total loss: \u001b[1m\u001b[32m0.31621\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2862 | loss: 0.31621 - binary_acc: 0.9972 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2863  | total loss: \u001b[1m\u001b[32m0.31593\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2863 | loss: 0.31593 - binary_acc: 0.9975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2864  | total loss: \u001b[1m\u001b[32m0.31568\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2864 | loss: 0.31568 - binary_acc: 0.9978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2865  | total loss: \u001b[1m\u001b[32m0.31546\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2865 | loss: 0.31546 - binary_acc: 0.9980 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2866  | total loss: \u001b[1m\u001b[32m0.31525\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2866 | loss: 0.31525 - binary_acc: 0.9982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2867  | total loss: \u001b[1m\u001b[32m0.31507\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2867 | loss: 0.31507 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2868  | total loss: \u001b[1m\u001b[32m0.41484\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2868 | loss: 0.41484 - binary_acc: 0.8985 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2869  | total loss: \u001b[1m\u001b[32m0.40470\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2869 | loss: 0.40470 - binary_acc: 0.9087 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2870  | total loss: \u001b[1m\u001b[32m0.39558\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2870 | loss: 0.39558 - binary_acc: 0.9178 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2871  | total loss: \u001b[1m\u001b[32m0.38736\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2871 | loss: 0.38736 - binary_acc: 0.9260 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2872  | total loss: \u001b[1m\u001b[32m0.47990\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2872 | loss: 0.47990 - binary_acc: 0.8334 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2873  | total loss: \u001b[1m\u001b[32m0.46326\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2873 | loss: 0.46326 - binary_acc: 0.8501 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2874  | total loss: \u001b[1m\u001b[32m0.54821\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2874 | loss: 0.54821 - binary_acc: 0.7651 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2875  | total loss: \u001b[1m\u001b[32m0.52473\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2875 | loss: 0.52473 - binary_acc: 0.7886 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2876  | total loss: \u001b[1m\u001b[32m0.50360\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2876 | loss: 0.50360 - binary_acc: 0.8097 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2877  | total loss: \u001b[1m\u001b[32m0.48459\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2877 | loss: 0.48459 - binary_acc: 0.8287 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2878  | total loss: \u001b[1m\u001b[32m0.46747\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2878 | loss: 0.46747 - binary_acc: 0.8459 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2879  | total loss: \u001b[1m\u001b[32m0.45207\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2879 | loss: 0.45207 - binary_acc: 0.8613 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2880  | total loss: \u001b[1m\u001b[32m0.43821\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2880 | loss: 0.43821 - binary_acc: 0.8752 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2881  | total loss: \u001b[1m\u001b[32m0.42573\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2881 | loss: 0.42573 - binary_acc: 0.8876 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2882  | total loss: \u001b[1m\u001b[32m0.46447\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2882 | loss: 0.46447 - binary_acc: 0.8489 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2883  | total loss: \u001b[1m\u001b[32m0.44936\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2883 | loss: 0.44936 - binary_acc: 0.8640 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2884  | total loss: \u001b[1m\u001b[32m0.43577\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2884 | loss: 0.43577 - binary_acc: 0.8776 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2885  | total loss: \u001b[1m\u001b[32m0.42354\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2885 | loss: 0.42354 - binary_acc: 0.8898 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2886  | total loss: \u001b[1m\u001b[32m0.41253\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2886 | loss: 0.41253 - binary_acc: 0.9008 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2887  | total loss: \u001b[1m\u001b[32m0.40262\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2887 | loss: 0.40262 - binary_acc: 0.9108 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2888  | total loss: \u001b[1m\u001b[32m0.39370\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2888 | loss: 0.39370 - binary_acc: 0.9197 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2889  | total loss: \u001b[1m\u001b[32m0.38567\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2889 | loss: 0.38567 - binary_acc: 0.9277 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2890  | total loss: \u001b[1m\u001b[32m0.37845\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2890 | loss: 0.37845 - binary_acc: 0.9349 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2891  | total loss: \u001b[1m\u001b[32m0.37195\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2891 | loss: 0.37195 - binary_acc: 0.9414 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2892  | total loss: \u001b[1m\u001b[32m0.36610\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2892 | loss: 0.36610 - binary_acc: 0.9473 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2893  | total loss: \u001b[1m\u001b[32m0.36083\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2893 | loss: 0.36083 - binary_acc: 0.9526 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2894  | total loss: \u001b[1m\u001b[32m0.35609\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2894 | loss: 0.35609 - binary_acc: 0.9573 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2895  | total loss: \u001b[1m\u001b[32m0.35183\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2895 | loss: 0.35183 - binary_acc: 0.9616 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2896  | total loss: \u001b[1m\u001b[32m0.34799\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2896 | loss: 0.34799 - binary_acc: 0.9654 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2897  | total loss: \u001b[1m\u001b[32m0.34453\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2897 | loss: 0.34453 - binary_acc: 0.9689 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2898  | total loss: \u001b[1m\u001b[32m0.34142\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2898 | loss: 0.34142 - binary_acc: 0.9720 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2899  | total loss: \u001b[1m\u001b[32m0.33862\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2899 | loss: 0.33862 - binary_acc: 0.9748 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2900  | total loss: \u001b[1m\u001b[32m0.33610\u001b[0m\u001b[0m | time: 0.007s\n",
            "| SGD | epoch: 2900 | loss: 0.33610 - binary_acc: 0.9773 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2901  | total loss: \u001b[1m\u001b[32m0.33384\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2901 | loss: 0.33384 - binary_acc: 0.9796 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2902  | total loss: \u001b[1m\u001b[32m0.33180\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2902 | loss: 0.33180 - binary_acc: 0.9816 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2903  | total loss: \u001b[1m\u001b[32m0.32996\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2903 | loss: 0.32996 - binary_acc: 0.9835 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2904  | total loss: \u001b[1m\u001b[32m0.32831\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2904 | loss: 0.32831 - binary_acc: 0.9851 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2905  | total loss: \u001b[1m\u001b[32m0.32682\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2905 | loss: 0.32682 - binary_acc: 0.9866 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2906  | total loss: \u001b[1m\u001b[32m0.32548\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2906 | loss: 0.32548 - binary_acc: 0.9879 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2907  | total loss: \u001b[1m\u001b[32m0.32428\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2907 | loss: 0.32428 - binary_acc: 0.9892 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2908  | total loss: \u001b[1m\u001b[32m0.32319\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2908 | loss: 0.32319 - binary_acc: 0.9902 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2909  | total loss: \u001b[1m\u001b[32m0.32222\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2909 | loss: 0.32222 - binary_acc: 0.9912 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2910  | total loss: \u001b[1m\u001b[32m0.32134\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2910 | loss: 0.32134 - binary_acc: 0.9921 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2911  | total loss: \u001b[1m\u001b[32m0.32055\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2911 | loss: 0.32055 - binary_acc: 0.9929 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2912  | total loss: \u001b[1m\u001b[32m0.31984\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2912 | loss: 0.31984 - binary_acc: 0.9936 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2913  | total loss: \u001b[1m\u001b[32m0.31919\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2913 | loss: 0.31919 - binary_acc: 0.9942 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2914  | total loss: \u001b[1m\u001b[32m0.31862\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2914 | loss: 0.31862 - binary_acc: 0.9948 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2915  | total loss: \u001b[1m\u001b[32m0.31810\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2915 | loss: 0.31810 - binary_acc: 0.9953 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2916  | total loss: \u001b[1m\u001b[32m0.31763\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2916 | loss: 0.31763 - binary_acc: 0.9958 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2917  | total loss: \u001b[1m\u001b[32m0.31721\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2917 | loss: 0.31721 - binary_acc: 0.9962 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2918  | total loss: \u001b[1m\u001b[32m0.31683\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2918 | loss: 0.31683 - binary_acc: 0.9966 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2919  | total loss: \u001b[1m\u001b[32m0.31649\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2919 | loss: 0.31649 - binary_acc: 0.9969 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2920  | total loss: \u001b[1m\u001b[32m0.31619\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2920 | loss: 0.31619 - binary_acc: 0.9972 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2921  | total loss: \u001b[1m\u001b[32m0.31591\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2921 | loss: 0.31591 - binary_acc: 0.9975 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2922  | total loss: \u001b[1m\u001b[32m0.31566\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2922 | loss: 0.31566 - binary_acc: 0.9978 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2923  | total loss: \u001b[1m\u001b[32m0.31544\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2923 | loss: 0.31544 - binary_acc: 0.9980 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2924  | total loss: \u001b[1m\u001b[32m0.31524\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2924 | loss: 0.31524 - binary_acc: 0.9982 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2925  | total loss: \u001b[1m\u001b[32m0.31506\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2925 | loss: 0.31506 - binary_acc: 0.9984 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2926  | total loss: \u001b[1m\u001b[32m0.31489\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2926 | loss: 0.31489 - binary_acc: 0.9985 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2927  | total loss: \u001b[1m\u001b[32m0.31475\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2927 | loss: 0.31475 - binary_acc: 0.9987 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2928  | total loss: \u001b[1m\u001b[32m0.31462\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2928 | loss: 0.31462 - binary_acc: 0.9988 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2929  | total loss: \u001b[1m\u001b[32m0.31450\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2929 | loss: 0.31450 - binary_acc: 0.9989 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2930  | total loss: \u001b[1m\u001b[32m0.31439\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2930 | loss: 0.31439 - binary_acc: 0.9990 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2931  | total loss: \u001b[1m\u001b[32m0.31429\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2931 | loss: 0.31429 - binary_acc: 0.9991 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2932  | total loss: \u001b[1m\u001b[32m0.31421\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2932 | loss: 0.31421 - binary_acc: 0.9992 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2933  | total loss: \u001b[1m\u001b[32m0.31413\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2933 | loss: 0.31413 - binary_acc: 0.9993 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2934  | total loss: \u001b[1m\u001b[32m0.31406\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2934 | loss: 0.31406 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2935  | total loss: \u001b[1m\u001b[32m0.31400\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2935 | loss: 0.31400 - binary_acc: 0.9994 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2936  | total loss: \u001b[1m\u001b[32m0.31394\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2936 | loss: 0.31394 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2937  | total loss: \u001b[1m\u001b[32m0.31389\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2937 | loss: 0.31389 - binary_acc: 0.9995 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2938  | total loss: \u001b[1m\u001b[32m0.31384\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2938 | loss: 0.31384 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2939  | total loss: \u001b[1m\u001b[32m0.31380\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2939 | loss: 0.31380 - binary_acc: 0.9996 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2940  | total loss: \u001b[1m\u001b[32m0.31376\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2940 | loss: 0.31376 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2941  | total loss: \u001b[1m\u001b[32m0.31373\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2941 | loss: 0.31373 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2942  | total loss: \u001b[1m\u001b[32m0.31370\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2942 | loss: 0.31370 - binary_acc: 0.9997 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2943  | total loss: \u001b[1m\u001b[32m0.31367\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2943 | loss: 0.31367 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2944  | total loss: \u001b[1m\u001b[32m0.31365\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2944 | loss: 0.31365 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2945  | total loss: \u001b[1m\u001b[32m0.31362\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2945 | loss: 0.31362 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2946  | total loss: \u001b[1m\u001b[32m0.31360\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2946 | loss: 0.31360 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2947  | total loss: \u001b[1m\u001b[32m0.31359\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2947 | loss: 0.31359 - binary_acc: 0.9998 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2948  | total loss: \u001b[1m\u001b[32m0.36354\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2948 | loss: 0.36354 - binary_acc: 0.9499 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2949  | total loss: \u001b[1m\u001b[32m0.35853\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2949 | loss: 0.35853 - binary_acc: 0.9549 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2950  | total loss: \u001b[1m\u001b[32m0.35402\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2950 | loss: 0.35402 - binary_acc: 0.9594 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2951  | total loss: \u001b[1m\u001b[32m0.34996\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2951 | loss: 0.34996 - binary_acc: 0.9634 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2952  | total loss: \u001b[1m\u001b[32m0.34631\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2952 | loss: 0.34631 - binary_acc: 0.9671 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2953  | total loss: \u001b[1m\u001b[32m0.34302\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2953 | loss: 0.34302 - binary_acc: 0.9704 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2954  | total loss: \u001b[1m\u001b[32m0.34006\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2954 | loss: 0.34006 - binary_acc: 0.9734 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2955  | total loss: \u001b[1m\u001b[32m0.33740\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2955 | loss: 0.33740 - binary_acc: 0.9760 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2956  | total loss: \u001b[1m\u001b[32m0.33500\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2956 | loss: 0.33500 - binary_acc: 0.9784 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2957  | total loss: \u001b[1m\u001b[32m0.33284\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2957 | loss: 0.33284 - binary_acc: 0.9806 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2958  | total loss: \u001b[1m\u001b[32m0.33090\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2958 | loss: 0.33090 - binary_acc: 0.9825 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2959  | total loss: \u001b[1m\u001b[32m0.32915\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2959 | loss: 0.32915 - binary_acc: 0.9843 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2960  | total loss: \u001b[1m\u001b[32m0.37755\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2960 | loss: 0.37755 - binary_acc: 0.9358 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2961  | total loss: \u001b[1m\u001b[32m0.37114\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2961 | loss: 0.37114 - binary_acc: 0.9423 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2962  | total loss: \u001b[1m\u001b[32m0.36537\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2962 | loss: 0.36537 - binary_acc: 0.9480 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2963  | total loss: \u001b[1m\u001b[32m0.36017\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2963 | loss: 0.36017 - binary_acc: 0.9532 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2964  | total loss: \u001b[1m\u001b[32m0.35550\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2964 | loss: 0.35550 - binary_acc: 0.9579 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2965  | total loss: \u001b[1m\u001b[32m0.35129\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2965 | loss: 0.35129 - binary_acc: 0.9621 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2966  | total loss: \u001b[1m\u001b[32m0.39747\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2966 | loss: 0.39747 - binary_acc: 0.9159 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2967  | total loss: \u001b[1m\u001b[32m0.38907\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2967 | loss: 0.38907 - binary_acc: 0.9243 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2968  | total loss: \u001b[1m\u001b[32m0.38150\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2968 | loss: 0.38150 - binary_acc: 0.9319 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2969  | total loss: \u001b[1m\u001b[32m0.37470\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2969 | loss: 0.37470 - binary_acc: 0.9387 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2970  | total loss: \u001b[1m\u001b[32m0.36857\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2970 | loss: 0.36857 - binary_acc: 0.9448 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2971  | total loss: \u001b[1m\u001b[32m0.36305\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2971 | loss: 0.36305 - binary_acc: 0.9503 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2972  | total loss: \u001b[1m\u001b[32m0.35809\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2972 | loss: 0.35809 - binary_acc: 0.9553 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2973  | total loss: \u001b[1m\u001b[32m0.35362\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2973 | loss: 0.35362 - binary_acc: 0.9598 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2974  | total loss: \u001b[1m\u001b[32m0.34960\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2974 | loss: 0.34960 - binary_acc: 0.9638 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2975  | total loss: \u001b[1m\u001b[32m0.34599\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2975 | loss: 0.34599 - binary_acc: 0.9674 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2976  | total loss: \u001b[1m\u001b[32m0.34273\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2976 | loss: 0.34273 - binary_acc: 0.9707 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2977  | total loss: \u001b[1m\u001b[32m0.33980\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2977 | loss: 0.33980 - binary_acc: 0.9736 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2978  | total loss: \u001b[1m\u001b[32m0.33716\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2978 | loss: 0.33716 - binary_acc: 0.9762 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2979  | total loss: \u001b[1m\u001b[32m0.33479\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2979 | loss: 0.33479 - binary_acc: 0.9786 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2980  | total loss: \u001b[1m\u001b[32m0.33265\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2980 | loss: 0.33265 - binary_acc: 0.9808 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2981  | total loss: \u001b[1m\u001b[32m0.33073\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2981 | loss: 0.33073 - binary_acc: 0.9827 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2982  | total loss: \u001b[1m\u001b[32m0.32900\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2982 | loss: 0.32900 - binary_acc: 0.9844 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2983  | total loss: \u001b[1m\u001b[32m0.32744\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2983 | loss: 0.32744 - binary_acc: 0.9860 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2984  | total loss: \u001b[1m\u001b[32m0.32604\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2984 | loss: 0.32604 - binary_acc: 0.9874 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2985  | total loss: \u001b[1m\u001b[32m0.32478\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2985 | loss: 0.32478 - binary_acc: 0.9886 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2986  | total loss: \u001b[1m\u001b[32m0.32364\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2986 | loss: 0.32364 - binary_acc: 0.9898 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2987  | total loss: \u001b[1m\u001b[32m0.32262\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2987 | loss: 0.32262 - binary_acc: 0.9908 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2988  | total loss: \u001b[1m\u001b[32m0.32170\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2988 | loss: 0.32170 - binary_acc: 0.9917 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2989  | total loss: \u001b[1m\u001b[32m0.32087\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2989 | loss: 0.32087 - binary_acc: 0.9925 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2990  | total loss: \u001b[1m\u001b[32m0.42007\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2990 | loss: 0.42007 - binary_acc: 0.8933 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2991  | total loss: \u001b[1m\u001b[32m0.40940\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2991 | loss: 0.40940 - binary_acc: 0.9040 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2992  | total loss: \u001b[1m\u001b[32m0.39980\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2992 | loss: 0.39980 - binary_acc: 0.9136 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2993  | total loss: \u001b[1m\u001b[32m0.39117\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2993 | loss: 0.39117 - binary_acc: 0.9222 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2994  | total loss: \u001b[1m\u001b[32m0.43336\u001b[0m\u001b[0m | time: 0.003s\n",
            "| SGD | epoch: 2994 | loss: 0.43336 - binary_acc: 0.8800 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2995  | total loss: \u001b[1m\u001b[32m0.42137\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2995 | loss: 0.42137 - binary_acc: 0.8920 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2996  | total loss: \u001b[1m\u001b[32m0.46054\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2996 | loss: 0.46054 - binary_acc: 0.8528 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2997  | total loss: \u001b[1m\u001b[32m0.44583\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2997 | loss: 0.44583 - binary_acc: 0.8675 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2998  | total loss: \u001b[1m\u001b[32m0.43259\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 2998 | loss: 0.43259 - binary_acc: 0.8808 -- iter: 4/4\n",
            "--\n",
            "Training Step: 2999  | total loss: \u001b[1m\u001b[32m0.42067\u001b[0m\u001b[0m | time: 0.005s\n",
            "| SGD | epoch: 2999 | loss: 0.42067 - binary_acc: 0.8927 -- iter: 4/4\n",
            "--\n",
            "Training Step: 3000  | total loss: \u001b[1m\u001b[32m0.40995\u001b[0m\u001b[0m | time: 0.004s\n",
            "| SGD | epoch: 3000 | loss: 0.40995 - binary_acc: 0.9034 -- iter: 4/4\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdQCB7HU4ATH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28470977-c813-4786-aa22-c3021ade67b9"
      },
      "source": [
        "[i[0] > 0 for i in model.predict(X)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True, True, False, False]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "carbH-j54qkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}